---
title: "Model parameter EwE Lake Champlain"
author: "Rosalie Bruel"
date: "created on 2019-07-11 -- last update: `r Sys.Date()`"
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
  html_document:
    df_print: paged
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
fontsize: 11pt
editor_options:
  chunk_output_type: console
  df_print: paged
always_allow_html: yes
---

_Last update: `r Sys.Date()`_

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = dirname(getwd()))
knitr::opts_chunk$set(echo = TRUE)
# tmp <- lessismore(packages = .packages(), path2file = "R/EwE_model_param_LakeChamplain.Rmd", plot_output = T)
# cat(tmp$summary)
# tmp$functions_non_matched
# tmp$packages_used
# tmp$packages_non_used
# tmp$summary_functions_plot
library(plyr) #for ddply
library(dplyr)
library(tidyr)
library(forcats)
library(ggplot2)
library(patchwork) # to easily arrange plot
#devtools::install_github("rensa/stickylabeller")
library(stickylabeller) # to get a, b, c, or fancy names in facet_wrap
library(plotly)
library(lubridate) # for date time
library(changepoint) #changepoint analysis
library(ecp) #changepoints
library(reshape2) # for melt
library(Hmisc) # for err bar plot
library(FSA);library(FSAdata) # Fisheries stock assessment methods and data
library(leaflet)
library(janitor)
library(rgdal)
#library(raster)
# db <- available.packages()
# deps <- tools::package_dependencies("raster", db)$raster
# install.packages(deps)
library(rnaturalearth)
library(RColorBrewer)
library(grid)
library(gridExtra) # get two plots side by side
library(knitr) # for kable
library(stringr) # for str_replace()
library(wesanderson) # colors
library(ggraph) # for nodes plot
library(igraph) # probably better for nodes graph because can also assign weigth
library(tidygraph) # to transform dataframe in node datasets
library(scales) # Get full number in x/y scales with scale_x_continuous(labels = comma)/scale_y_continuous(labels = comma) instead of 1.00e09 for example
library(concurve) # plot p-value and s-value, see recommandations in Chow and Sander, 2019
library(psych) # for pairs-panels (scaterplot matrix)
library(TTR) # for moving average 
library(matrixStats) # for sd per row - states of matrix in general

# model library
library(mgcv)

# For cute fish icons
library(fishualize)
#Overview of all fish shapes available
# fishapes()
# ggplot() + add_fishape(family = "Salmonidae", 
#                        option = "Oncorhynchus_nerka") +
#   theme_void()

# Captions with library captioner
# https://community.rstudio.com/t/avoiding-repetitive-latex-codes-in-r-markdown/7834/12
# https://cran.r-project.org/web/packages/captioner/vignettes/using_captioner.html 
fig_cap <- captioner::captioner()
tab_cap <- captioner::captioner("Table")

getpath4data <- function() {
  if(Sys.getenv("USER")=="Rosalie") return("/Volumes/-/Script R/LCM_GitHub_Data_LCM/")
  if(Sys.getenv("USER")=="alexnaccarato") return("~/Desktop/Food-Web 2018-2019/LCM_GitHub_Data/")
    if(Sys.getenv("USER")=="YOUR USER NAME") return("YOUR PATH")
  if(Sys.getenv("USER")!="Rosalie"|Sys.getenv("USER")!="alexnaccarato") stop("You need to get the data.")
}

# Source functions for fulton cond factor, relative condition, and relative weight
# Compute_FultonK
source("https://raw.githubusercontent.com/rosalieb/miscellaneous/master/R/Compute_FultonK.R")
# RelCond_Fisheries 
source("https://raw.githubusercontent.com/rosalieb/miscellaneous/master/R/RelCond_Fisheries.R")
# RelWeight_Fisheries
source("https://raw.githubusercontent.com/rosalieb/miscellaneous/master/R/RelWeight_Fisheries.R")

# turn this to true so some stuffs are not run when I'm knitting (and vice versa)
R_U_KNITTING = TRUE 

```

The objective of this document is to gather all in one place the decisions made for the parameters of the model.
I'm starting this document on July 16th, 2019, having entered some parameters over the past 4 months and realizing I already forgot where I got them from... Hopefully I'll find my notes back, otherwise, having everything in one place might be easier.

The model and connection we're assuming in a first place are represented below.

```{r plot foodweb with nodes, echo=FALSE, message=FALSE, warning=FALSE}
foodweb <- data.frame(
  "predator" = c("Sea Lamprey","Sea Lamprey","Sea Lamprey","AtSalmon","AtSalmon","LT",  "LT",  "LT",  "LT",     "Cisco","Cisco","Cisco","Cisco","Whitefish","Whitefish", "Trout Perch","ALW", "ALW", "ALW", "Smelt", "Smelt", "Smelt","Sculpin",           "Sculpin",  "MYS", "MYS", "ZOO"),
  "prey"     = c("Burbot", "LT",     "AtSalmon","ALW",     "Smelt",   "MYS","ALW", "Smelt","Sculpin","ALW","Smelt","ZOO","BcCp",   "BcCp","Benthic Invertebrates", "ZOO"  , "MYS", "ZOO", "BcCp", "MYS", "ZOO", "BcCp",    "Benthic Invertebrates", "MYS","PHY", "Detritus","PHY")
)

foodweb$level <- rep(1, nrow(foodweb))
foodweb$level <- rep(NA, nrow(foodweb))
for (i in 1:nrow(foodweb)) {
  if (foodweb$predator[i] %in% c("Detritus")) foodweb$level[i] = 0.5
  if (foodweb$predator[i] %in% c("PHY","Benthic Invertebrates")) foodweb$level[i] = 1
  if (foodweb$predator[i] %in% c("ZOO","MYS")) foodweb$level[i] = 2
  if (foodweb$predator[i] %in% c("BcCp")) foodweb$level[i] = 3
  if (foodweb$predator[i] %in% c("Sculpin","Trout Perch", "Alewife","Smelt")) foodweb$level[i] = 4
  if (foodweb$predator[i] %in% c("Burbot","AtSalmon", "LT","Cisco","Whitefish")) foodweb$level[i] = 5
  if (foodweb$predator[i] %in% c("Sea Lamprey")) foodweb$level[i] = 6
}

# graph <- as_tbl_graph(foodweb)
# ggraph(graph, "grid") + 
#   geom_edge_link() + 
#   geom_node_point() +
#   geom_node_label(aes(label = names(graph[1])), repel = TRUE)

```


```{r plot food web with igraph, echo=FALSE, message=FALSE, warning=FALSE}
ewediet <- read.delim(paste0(getpath4data(),"EwE_params/EwE_diet.txt"))
colnames(ewediet)[-c(1:2)] <- as.character(ewediet$predator[1:c(ncol(ewediet)-2)])
rownames(ewediet) <- as.character(ewediet$predator)
ewediet <- ewediet[1:c(ncol(ewediet)),-c(1)]

ewediet2 <- melt(ewediet)
colnames(ewediet2) <- c("prey","predator","weigth")
#ewediet2 <- ewediet2[,c("predator","prey","weigth")]
ewediet2 <- rbind(ewediet2,c("Smelt","Smelt",0.1))

ewediet2 <- ewediet2[ewediet2[,3]>0,]

ewediet2$prey <- as.character(ewediet2$prey)
ewediet2$predator <- as.character(ewediet2$predator)

ewediet_nodes <- data.frame(
  "id"=as.character(rownames(ewediet)),
  "data_source"=as.character(c("VTFWS", "VTFWS/UVM","VTFWS/UVM","NA","NA","NA","UVM","UVM","UVM","UVM","UVM","UVM","VTDEC","VTDEC","VTDEC","UVM","VTDEC","calculated")),
  "level"=c(-2,0,3,0,0,0,1,0,5,4,2,5,7,6,7,6.5,8,9)
)

ewediet_nodes <- ewediet_nodes[order(ewediet_nodes$level),]

net <- graph_from_data_frame(d=ewediet2, vertices=ewediet_nodes, directed=T) 

#set colors
colrs <- wes_palette("Darjeeling1", n=length(unique(V(net)$level)), type="continuous")
V(net)$color <- colrs[V(net)$level+6]
colrs <- wes_palette("Darjeeling1", n=length(V(net)$name), type="continuous")
#colrs<- c("grey",colrs[2],rep("grey", length(V(net)$name)-2))
V(net)$color <- colrs

edge.start <- ends(net, es=E(net), names=F)[,2]
edge.col <- V(net)$color[edge.start]

E(net)$weight <- as.numeric(paste(ewediet2$weigth))
E(net)$width <- as.numeric(paste(E(net)$weight))*10


# par(mfrow=c(1,1), mar=c(1,12,1,1))
# plot(net, edge.color=edge.col, edge.curved=.1, layout=do.call("layout_in_circle", list(net))) 
# par(xpd=T)
# legend(x=-2, y=1.1, c(V(net)$name), pch=21,col="#777777", pt.bg=colrs, pt.cex=2, cex=.8, bty="n", ncol=1)
# par(xpd=F)


# mylayout should have 2 columns, x and y, and number of rows of the number of groups: length(V(net)$name) == 18

mylayout <- ewediet_nodes %>% mutate(
  # x positionning 
  x = case_when(id == "Sea lamprey"      ~ 0,
                id == "Adult lake trout" ~ 0,
                id == "Atlantic salmon"  ~ 2,
                id == "Burbot"           ~ 4,
                id == "Walleye"          ~ -4,
                id == "Whitefish"        ~ -2,
                id == "Cisco"            ~ -1,
                id == "Alewife"          ~ 1,
                id == "Smelt"            ~ 4,
                id == "Juvenile lake trout" ~ -3,
                id == "Trout-perch"      ~  2,
                id == "Sculpin"          ~  4,
                id == "Zooplankton (predacious)"    ~  -1,
                id == "Mysis"            ~  -3,
                id == "Benthic invertebrates" ~ 2,
                id == "Zooplankton (grazers)"      ~ 0,
                id == "Phytoplankton"    ~ -2,
                id == "Detritus"         ~ 0),
  # Label positioning (1= bottom, 2=left, 3=top, 4= right) 
  x2 = case_when(id == "Sea lamprey"     ~ 3,
                id == "Adult lake trout" ~ 3,
                id == "Atlantic salmon"  ~ 3,
                id == "Burbot"           ~ 3,
                id == "Walleye"          ~ 3,
                id == "Whitefish"        ~ 3,
                id == "Cisco"            ~ 3,
                id == "Alewife"          ~ 3,
                id == "Smelt"            ~ 2,
                id == "Juvenile lake trout" ~ 3,
                id == "Trout-perch"      ~  3,
                id == "Sculpin"          ~  2,
                id == "Zooplankton (predacious)"    ~  3,
                id == "Mysis"            ~  4,
                id == "Benthic invertebrates" ~ 2,
                id == "Zooplankton (grazers)"      ~ 1,
                id == "Phytoplankton"    ~ 4,
                id == "Detritus"         ~ 1))
mylayout <- matrix(c(mylayout$x,mylayout$level,mylayout$x2),ncol=3)

E(net)$label <- paste0(round(as.numeric(paste(E(net)$weight)),2), "\n")
E(net)$label <- NA

V(net)$label <- paste0(ewediet_nodes$id,"\n")
V(net)$label <- NA

if(!R_U_KNITTING) pdf(paste0(getwd(),"/Output/Figures/5-Summary/summary_interaction4.pdf"),width = 8, height = 8)
par(mar=c(0,4,0,7))
plot.igraph(net,edge.color=adjustcolor(edge.col,alpha.f = .8), edge.curved=.1,
                  layout=-as.matrix(mylayout)[,1:2])
par(xpd=T)
TeachingDemos::shadowtext(-norm_coords(mylayout[,1:2], -1, 1, -1, 1), label=ewediet_nodes$id,pos=mylayout[,3], offset=1.3, col="black",bg = "white",  theta = (1:8/4)*pi, r1 = 0.06, r2 = 0.04)
par(xpd=F)
if(!R_U_KNITTING) dev.off()

```
<br>`r fig_cap("node plot1", caption="Lake Champlain food web – species of interest")`

For the Lake Champlain monitoring data, I'm using the data I processed for the Stats-a-thon. The idea was to get something a bit homogeneous in term of depths (hypolimnion and epilimnion data when lake stratified, and hypolimnion=epilimnion when lake mixed).

```{r read data from LTM}
dtlcm <- read.delim(paste0(getpath4data(),"LCM_unique_param_step4.txt"))
names(dtlcm)
dtlcm$Year <- as.numeric(paste(year(as.Date(dtlcm$VisitDate, format="%d/%m/%Y"))))

dtlcm_metadata <- read.delim(paste0(getpath4data(),"LCM_station_metadata.txt"))

```

```{r gradient of conditions, echo=FALSE}

dtlcm_summ <-
  dtlcm %>% 
  group_by(StationID) %>% 
  summarise(    Temperature_E  = mean(Temperature_E, na.rm=T),
            Total.Phosphorus_E = mean(Total.Phosphorus_E,na.rm=T))

# Basic density
p1 <- ggplot(dtlcm_summ, aes(x=Temperature_E)) + 
  geom_density(fill="grey") + 
  geom_vline(aes(xintercept=mean(Temperature_E)),
            color="blue", linetype="dashed", size=1) +
  theme_bw() + labs(x="Mean water temperature (epilimnion)", subtitle=paste0(min(dtlcm$Year[is.na(dtlcm$Temperature_E)]), " - ", max(dtlcm$Year[is.na(dtlcm$Temperature_E)])," (April-November)"))

p2 <- ggplot(dtlcm_summ, aes(x=Total.Phosphorus_E)) + 
  geom_density(fill="grey") + 
  geom_vline(aes(xintercept=mean(Total.Phosphorus_E)),
            color="blue", linetype="dashed", size=1) +
  theme_bw() + labs(x="Mean total phosphorus (epilimnion) ", subtitle=paste0(min(dtlcm$Year[is.na(dtlcm$Total.Phosphorus_E)]), " - ", max(dtlcm$Year[is.na(dtlcm$Total.Phosphorus_E)])," (April-November)"))

#grid.arrange(p1,p2, nrow=1)

p3 <- ggplot(dtlcm_metadata[dtlcm_metadata$Station %in% unique(dtlcm$StationID),], aes(x=Total.Depth)) + 
  geom_density(fill="grey") + 
  geom_vline(aes(xintercept=mean(Total.Depth)),
            color="blue", linetype="dashed", size=1) +
  theme_bw() + labs(x="Max depth (m)")

grid.arrange(p3,p1,p2, nrow=1)

ggplot(dtlcm_summ, aes(x=Temperature_E,y=Total.Phosphorus_E)) +
  geom_point()

# Violin plot
ggplot(dtlcm_summ, aes(x=StationID,y=Temperature_E)) + 
  geom_violin(fill="grey", trim = F) +
  theme_bw()

ggplot(dtlcm_summ, aes(x=StationID,y=Total.Phosphorus_E)) + 
  geom_violin(fill="grey", trim = F) +
  theme_bw()



```



```{r read detailed plankton database, message=FALSE, warning=FALSE, include=FALSE}
plktn_pre2010  <- read.delim(paste0(getpath4data(),"LCM_bio_PeteStangel/Plankton data pre 2010.txt"))
plktn_post2010 <- read.delim(paste0(getpath4data(),"LCM_bio_PeteStangel/Plankton data after 2010.txt"))
sites_raw      <- read.delim(paste0(getpath4data(),"LCM_bio_PeteStangel/Plankton data stations.txt"))
sites          <- sites_raw[sites_raw$LocationID %in% as.factor(plktn_pre2010$LocationID),]

plktn <- rbind(plktn_pre2010,plktn_post2010)

plktn$VisitDate <- parse_date_time(x = plktn$PlanktonData.VisitDate, orders = c("d-b-y","d/m/Y"))

plktn$StationID  <- sites[match(plktn$LocationID, sites$LocationID), "StationID"]

names(plktn)
plktn$PlanktonType[plktn$PlanktonType=="phyto"] <- "Phyto"
summary(plktn$PlanktonType)

summary(plktn$ResultType[plktn$PlanktonType=="Phyto"])
summary(plktn$ResultType[plktn$PlanktonType=="Zoo"])
summary(plktn$SampleType[plktn$PlanktonType=="Zoo"])

# Reshape the dataframe with the type of plankton+name as column name
plktn$Type_SpeciesID <- paste(plktn$PlanktonType, plktn$SpeciesID, sep="_")
plktn2 <- dcast(plktn,  VisitDate + StationID ~ Type_SpeciesID,value.var = "Result",fun.aggregate = sum, na.rm = TRUE )
head( plktn2)
dim(plktn2)
names(plktn2)

phyto <- plktn2[,c(1, 2, grep("Phyto_", names(plktn2)))]
  zoo <- plktn2[,c(1, 2, grep("Zoo_",   names(plktn2)))]

dim(zoo)
dim(phyto)

names(zoo)
rowSums(phyto[,-c(1:2)])

# Often, when we get 0 for zoo, we get value for phyto, and vice versa.
# no overlap of sampling? Are zoo and phyto samples taken on different days?
# There are only 69 days for which we got values both for zoo and phyto.
summary(which(rowSums(zoo[,-c(1,2)])!=0) %in% which(rowSums(phyto[,-c(1,2)])!=0))
summary(which(rowSums(phyto[,-c(1,2)])!=0) %in% which(rowSums(zoo[,-c(1,2)])!=0))


```


```{r read target and bycatch data here because they could be used at several steps, message=FALSE, warning=FALSE, include=FALSE}
tg <- read.delim(paste0(getpath4data(),"data_from_Pascal/target_catch_2016-2018.txt"))
#head(tg)
byc <- read.delim(paste0(getpath4data(),"data_from_Pascal/bycatch_2016-2018.txt"))
#head(byc)

# Convert date format to something we'll use more easily
tg$date <- as.Date(tg$date, format = "%d/%m/%Y")
byc$date <- as.Date(byc$date, format = "%d/%m/%Y")

```
Here are also the number of observations collected for different species during the trawls (`r min(tg$year,na.rm=T)`-`r max(tg$year,na.rm=T)`).

```{r summary target/bycatch, message=FALSE, warning=FALSE, include=FALSE}
summ_tg <- with(tg, tapply(rep(1,nrow(tg)),list("species#"=species,"Year#"=year), sum))
summ_by <- with(byc, tapply(rep(1,nrow(byc)),list("species#"=species,"Year#"=year), sum))
summ_tgby <- as.data.frame(rbind(summ_tg,summ_by))
summ_tgby$df_origin <- c(rep("targetcatch",nrow(summ_tg)),rep("bycatch",nrow(summ_by)))
summ_tgby <- summ_tgby[order(rownames(summ_tgby)),]
summ_tgby
```


# Detritus

We use Pauly et al (1993) equation to calculate the biomass of detritus:  
$Log10(D) = 0.954 * log10(PP) + 0.863 * log10(E) – 2.41$,

with E= depth of the euphotic zone.
I'm calculating the depth of the euphotic zone based on the secchi depth.

## Secchi Depth

__Data__:  
* Long-term monitoring dataset

`r fig_cap("secchi", caption = "Secchi depths across all sites and years", display=FALSE)`

The secchi depth across all sites and years is ploted below (`r fig_cap("secchi", display="cite")`).

```{r get secchi depth from LTM, echo=FALSE, message=FALSE, warning=FALSE}
secchi_depth_p <- dtlcm %>% ggplot(mapping = aes(x = as.factor(StationID), y = -Secchi.Depth, fill = as.factor(StationID))) +
  geom_boxplot() +
  xlab("Station ID") +
  ylab("Secchi depth (m)") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle(paste0("Secchi depths across all sites and years")) +
  scale_fill_discrete(name = "Stations")
secchi_depth_p
```
<br> `r fig_cap("secchi", display="full")`

It would seems like years 2000 have generally deeper secchi depths. There's also some kind of oscillations: ± 2 m in secchi depth. Teleconnections with some ocean cycles?
```{r plot secchi depth per sites with facet wrap, echo=FALSE, message=FALSE, warning=FALSE}
secchi_depth_p2 <- dtlcm %>% ggplot( mapping = aes(x = as.factor(year(as.Date(dtlcm$VisitDate, format="%d/%m/%Y"))), y = -Secchi.Depth, fill = as.factor(year(as.Date(dtlcm$VisitDate, format="%d/%m/%Y")))), show.legend = F) +
  stat_smooth(show.legend = F) + 
  geom_boxplot() +
  facet_wrap(~as.factor(StationID), ncol = 3) + 
  xlab("Year") +
  ylab("Secchi depth (m)") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "none") +
  ggtitle(paste0("Secchi depths across site and years (",min(year(as.Date(dtlcm$VisitDate, format="%d/%m/%Y"))),"-",max(year(as.Date(dtlcm$VisitDate, format="%d/%m/%Y"))),")")) +
  scale_fill_discrete(name = "Stations") 
secchi_depth_p2

#ggsave(paste0(getwd(),"/Output/Figures/12-Secchi/Secchi_depth.png"), width=10, height=10)
```
<br>`r fig_cap("secchi2", caption = "Evolution of sechi depths across all sites and years (see Hilt et al 2010 were secchi depths suddenly change).")`

The study of Gaiser _et al_ (2009, _Limnology and Oceanography_) shows some teleconnection between Lake Annie transparency and AMO index. Does Lake Champlain also exhibit teleconnection with AMO or ENSO?

Multivariate ENSO Index version 2 (MEI) data retrieved from NOAA (<a href="https://www.esrl.noaa.gov/psd/enso/mei/">Source for MEI.v2 Values</a>), and compare them with our secchi depths (i.e., reproduce Fig. 3 in Gaiser _et al_, 2009).

```{r meiv index with secchi, echo=FALSE, message=FALSE, warning=FALSE}
meiv <- read.delim(paste0(getpath4data(),"meiv2.data.txt"))
dtlcm_secchi <- dtlcm[,c("StationID", "VisitDate", "Secchi.Depth","Total.Phosphorus_E")]
dtlcm_secchi$VisitDate <- as.Date(dtlcm_secchi$VisitDate, format="%d/%m/%Y")
dtlcm_secchi <- dtlcm_secchi[complete.cases(dtlcm_secchi),]
dtlcm_secchi$Year <- year(dtlcm_secchi$VisitDate)

dtlcm_secchi_summ <- as.data.frame(
  with(dtlcm_secchi, tapply(dtlcm_secchi$Secchi.Depth
  ,list("Year"=as.factor(Year),"StationID"=as.factor(StationID)), mean, na.rm=T))
  )

dtlcm_TP_summ <- as.data.frame(
  with(dtlcm_secchi, tapply(dtlcm_secchi$Total.Phosphorus_E
  ,list("Year"=as.factor(Year),"StationID"=as.factor(StationID)), mean, na.rm=T))
  )

pairs.panels(cbind(as.numeric(paste(rownames(dtlcm_secchi_summ))),dtlcm_secchi_summ[,c("2","4","7","9")]), 
             method = "pearson", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses
             )
pairs.panels(cbind(as.numeric(paste(rownames(dtlcm_secchi_summ))),dtlcm_secchi_summ[,c("16","21","19","25","33","36","46")]), 
             method = "pearson", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses
             )
pairs.panels(cbind(as.numeric(paste(rownames(dtlcm_secchi_summ))),dtlcm_secchi_summ[,c("34","40","50","51")]), 
             method = "pearson", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses
             )

dtlcm_secchi_summ2 <- data.frame(melt(dtlcm_secchi_summ), "Year"=as.numeric(paste(rep(rownames(dtlcm_secchi_summ), times=ncol(dtlcm_secchi_summ)))))

dtlcm_TP_summ2 <- data.frame(melt(dtlcm_TP_summ), "Year"=as.numeric(paste(rep(rownames(dtlcm_TP_summ), times=ncol(dtlcm_TP_summ)))))

dtlcm_secchi_summ2$TP <- dtlcm_TP_summ2$value
dtlcm_secchi_summ2$meiv_summer <- rep(NA, nrow(dtlcm_secchi_summ2))
dtlcm_secchi_summ2$meiv_winter <- rep(NA, nrow(dtlcm_secchi_summ2))

for (i in min(dtlcm_secchi_summ2$Year):max(dtlcm_secchi_summ2$Year)) {
  dtlcm_secchi_summ2$meiv_summer[dtlcm_secchi_summ2$Year==i] <- rowMeans(meiv[meiv$YEAR==i,7:11])
  dtlcm_secchi_summ2$meiv_winter[dtlcm_secchi_summ2$Year==i] <- rowMeans(meiv[meiv$YEAR==i,2:5])
}

# dtlcm_secchi <- dtlcm_secchi %>%
#   mutate(meiv = case_when(VisitDate == 2000 ~ rowMeans(meiv[,-1])[meiv$YEAR==2000]))

```

```{r plot meiv index with secchi, echo=FALSE, message=FALSE, warning=FALSE}
p1 <- ggplot(dtlcm_secchi_summ2[dtlcm_secchi_summ2$Year!=2015,],aes(x=meiv_summer, y=value/log(TP), col=Year)) +
  geom_point() + stat_smooth(method = "lm") +
  #geom_point(aes(x=meiv_min, y=value, col="min meiv"))+
  #geom_point(aes(x=meiv_max, y=value, col="max meiv"))+
  facet_wrap(~as.factor(variable)) + ggtitle("Summer ENSO index (direct)")

p2 <- ggplot(dtlcm_secchi_summ2[dtlcm_secchi_summ2$Year!=2015,],aes(x=meiv_winter, y=value, col=Year)) +
  geom_point() + stat_smooth(method = "lm") +
  facet_wrap(~as.factor(variable)) + ggtitle("Winter ENSO index (legacy)")

grid.arrange(p1,p2,nrow=1)
```
<br>`r fig_cap("secchi3", caption = "Secchi depth against Multivariate ENSO Index for each monitoring station.")`

Same but with the Atlantic Multidecadal Oscillation (AMO, <a href="https://www.esrl.noaa.gov/psd/data/timeseries/AMO/"> data source NOAA</a>).

```{r AMO index}
amo <- read.delim(paste0(getpath4data(),"AMO_index.txt"))

dtlcm_secchi_summ2$amo_summer <- rep(NA, nrow(dtlcm_secchi_summ2))
dtlcm_secchi_summ2$amo_winter <- rep(NA, nrow(dtlcm_secchi_summ2))

for (i in min(dtlcm_secchi_summ2$Year):max(dtlcm_secchi_summ2$Year[dtlcm_secchi_summ2$Year %in% amo$YEAR])) {
  dtlcm_secchi_summ2$amo_summer[dtlcm_secchi_summ2$Year==i] <- rowMeans(amo[amo$YEAR==i,6:10])
  dtlcm_secchi_summ2$amo_winter[dtlcm_secchi_summ2$Year==i] <- rowMeans(amo[amo$YEAR==i,2:5])
}

p3 <- ggplot(dtlcm_secchi_summ2[dtlcm_secchi_summ2$Year!=2015,],aes(x=amo_summer, y=value, col=Year)) +
  geom_point() + stat_smooth(method = "lm") +
  facet_wrap(~as.factor(variable)) + ggtitle("Summer AMO index (direct)")

p4 <- ggplot(dtlcm_secchi_summ2[dtlcm_secchi_summ2$Year!=2015,],aes(x=amo_winter, y=value, col=Year)) +
  geom_point() + stat_smooth(method = "lm") +
  facet_wrap(~as.factor(variable)) + ggtitle("Winter AMO index (legacy)")

grid.arrange(p3,p4,nrow=1)
```
<br>`r fig_cap("secchi4", caption = "Secchi depth against AMO (summer and winter).")`

```{r gam for secchi depth against meiv, echo=FALSE}
head(dtlcm_secchi_summ2)
gam1 <- gam(value ~ s(meiv_summer) + variable, data=dtlcm_secchi_summ2)
summary(gam1)
plot(gam1);abline(h=0,lty=2)
gam2 <- gam(value ~ s(meiv_winter) + variable, data=dtlcm_secchi_summ2)
summary(gam2)
plot(gam2)
gam3 <- gam(value ~ s(amo_winter) + variable, data=dtlcm_secchi_summ2)
summary(gam3)
plot(gam3)
gam4 <- gam(value ~ s(amo_winter) + variable, data=dtlcm_secchi_summ2)
summary(gam4)
plot(gam4)
# Alternatively, we could fit a smoother to each station, as below
gam5 <- gam(value ~ s(meiv_summer, by = as.numeric(variable==2)) +
              s(meiv_summer, by = as.numeric(variable==4)) +
              s(meiv_summer, by = as.numeric(variable==7)) +
              s(meiv_summer, by = as.numeric(variable==9)) +
              s(meiv_summer, by = as.numeric(variable==16)) +
              s(meiv_summer, by = as.numeric(variable==19)) +
              s(meiv_summer, by = as.numeric(variable==21)) +
              s(meiv_summer, by = as.numeric(variable==25)) +
              s(meiv_summer, by = as.numeric(variable==33)) +
              s(meiv_summer, by = as.numeric(variable==34)) +
              s(meiv_summer, by = as.numeric(variable==36)) +
              s(meiv_summer, by = as.numeric(variable==40)) +
              s(meiv_summer, by = as.numeric(variable==46)) +
              s(meiv_summer, by = as.numeric(variable==50)) +
              s(meiv_summer, by = as.numeric(variable==51)), data=dtlcm_secchi_summ2)
summary(gam5)
# Good R2, but looking at the plot, there is no crossing of the intercept, except for 9 and 46.
#plot(gam5)
```

With GLS:

Residuals are not normally distributed.

```{r gls secchi depth agains amo, echo=FALSE}
library(nlme)
M0 <- gls(value ~ amo_winter + variable + Year, data=dtlcm_secchi_summ2, na.action = na.omit)
summary(M0)

#plot the standardized residuals vs. fitted
plot(M0)

```


**Compound symmetry** covariance matrix assumes that whatever the distance in time between two observations, their residual correaltion is the same (i.e., it doesn't change with increasing/decreasing time between observations). Constant covariance.
+ Often too simplistic for time series data.
```{r compound symmetry gls for secchi depth against amo, echo=FALSE}

M1<-gls(value ~ amo_winter + variable + Year, na.action = na.omit, correlation = corCompSymm(form=~Year|variable), data=dtlcm_secchi_summ2)


#look at the model output
summary(M1)
```

**AR1: Auto-regressive model of order 1** Models the residual at time s as a function of the residual of time s-1 along with noise.

The parameter for this correlation function, $\rho$, is unknown and has to be estimated from the data. The further away two residuals are separated in time, the lower their correlation. 
```{r ar1 for secchi-depth agains amo, echo=FALSE}
#fit the model with AR-1 correlation function, corAR1
M2<-gls(value ~ amo_winter + variable + Year, na.action = na.omit, correlation = corAR1(form=~Year|variable), data=dtlcm_secchi_summ2)

#look at the output
summary(M2)
#the parameter estimate is much higher. Residuals separated by one year have a correlation of 0.31. Residuals separated by two years have a correlation of 0.31^2=.10. Residuals separated by two years have a correlation of 0.77^3=.02, etc. 

#compare the three models with AIC
AIC(M0,M1,M2)

```

**ARMA Error Structures**
More complex structures based on the AR-1, using an auto-regressive moving average (ARMA) model for residuals. ARMA has two parameters defining it's order: the number of auto-regressive parameters (p) and the number of moving average parameters (q). So, ARMA(1,0) refers to AR-1. 

Realize that the p and q parameters have to be estimated from the data - using values of p or q larger than 2 or 3 tend to give error messages related to convergence problems (i.e., the larger p and/or q are, the more parameters there will be to estimate, which can give you convergence problems). 

```{r ARMA secchi depth against amo, echo=FALSE}
#here, we'll define a bunch of ARMA(p,q) structures
#Zuur says that it's kind of a black box. We're starting with these values, but we don't really know why.
cs1 <- corARMA(c(0.2), p = 1, q = 0) #0.2 is a chosen starting value for p
cs2 <- corARMA(c(0.3, -0.3), p = 2, q = 0) #0.3 and -0.3 are chosen starting values for 2 p's 
cs3 <- corARMA(c(0.3, -0.3, -0.3), p = 3, q = 0) #starting values for 3 p's

#fit models using all of the correlation structures above
M3arma1<-gls(value ~ amo_winter + variable + Year, correlation = cs1, na.action = na.omit, data=dtlcm_secchi_summ2) #equivalent to AR1
M3arma2<-gls(value ~ amo_winter + variable + Year, correlation = cs2, na.action = na.omit, data=dtlcm_secchi_summ2)


M3arma3<-gls(value ~ amo_winter + variable + Year,na.action=na.omit,
            correlation=cs3,data=dtlcm_secchi_summ2)

AIC(M0,M1,M2,M3arma1,M3arma2,M3arma3)


```

These models are not all nested, so we need to compare them using AIC (we cannot use likelihood ratio tests).
Model below not working (no convergence) -- not run.

```{r gamm secchi depth against amo, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
BM1<-gamm(value ~ amo_winter +  variable + s(Year, by=variable),
          weights = varIdent(form = ~1|variable), data=dtlcm_secchi_summ2)
```

The `varIdent(form=~1|variable)` should in theory allows each time series (i.e., each station) to have a different variance. The `s(Year, by=variable)` is here to ensure that the smoother is applied over each station's time series.

The problem with this model is that the p-values assume independence, and because thet data are time series, this assumption may be violated. Adding an AR-1 residual auto-correlation structure can help with that.

```{r gamm secchi depth against amo with AR1, echo=FALSE}

#fit the same model with AR-1 temporal correlation
BM2<-gamm(value ~ s(amo_winter) + variable,
          correlation = corAR1(form=~Year|variable),
          data=dtlcm_secchi_summ2)



#Use AIC to compare the two models
#AIC(BM1$lme,BM2$lme)
#look at output for the best model
summary(BM2$gam)
summary(BM2$lme)

anova(BM2$gam)

plot(BM2$gam)



```

The `anova()` output is the most straightforward. Only the Oahu time series have signifcant long-term trends and rainfall effects. The Maui time series are only affected by rainfall. 


## Setting the euphotic zone
```{r set euphtotic zone}
eu_z = 4.9
```
<br>
We set the euphotic zone for the main lake (StationID= 16 & 19) at `r eu_z` m.

The following code is not run yet, we need a value for the primary production.

```{r calculate detritus, eval=FALSE}
D = 10^(0.954 * log10(PP) + 0.863 * log10(eu_z) - 2.41)
D
```


# Phytoplankton

__Data__:  
* Long-term monitoring dataset

Phytoplankton data are collected since 2006. The field methodology described by the program says: 2x secchi by integrated hose or by 63 um net tow, lugols preserved samples, and are then counted on settling chambers or Sedgewick Rafter cells.

Biovolume are given in µm<sup>3</sup>/l.

We need: <br>
* The dimensions of the net <br>
* The depth sampled (use the secchi depth) <br>

```{r set diameter phytoplankton net}
diameter_net <- .8 #in meter
```

Create a special dataframe for phytoplankton.

```{r create a special dataframe for phytoplankton, echo=FALSE, message=FALSE, warning=FALSE}
phyto <- dtlcm[,c("StationID", "VisitDate","Secchi.Depth", "Net.phytoplankton..total.biovolume")]

n1 = nrow(phyto)
phyto <- phyto[!is.na(phyto$Secchi.Depth),]
n2 = nrow(phyto)
phyto <- phyto[!is.na(phyto$Net.phytoplankton..total.biovolume),]
n3 = nrow(phyto)
head(phyto)

phyto$Volume.sampled <- pi*(diameter_net/2)^2*(2*phyto$Secchi.Depth)

head(phyto)

```

`r n1-n2` rows deleted because Secchi.Depth=NA. <br>
`r n2-n3` rows deleted because Net.phytoplankton..total.biovolume=NA<br>

Conversion of µm<sup>3</sup>/l in t/km<sup>2</sup>:<br>
<center>
1 µm<sup>3</sup> = 1*10<sup>-15</sup> l    <br>
1 l = 1*10<sup>-6</sup> t
</center>

# Zooplankton

See script 'plankton_data.Rmd'.

Organisms density available (#/m<sup>3</sup>). To convert them to biomass, we use McCauley (1984), Chapter 7. The Estimation of the Abundance and Biomass of Zooplankton in Samples.
He established Weight/Length relationships for zooplankton.
We used average length of organisms collected from pictures found online, use the equations in McCauley (1984) to get an estimation of the weight, and converted #/m<sup>3</sup> to g/<sup>3</sup> that way.

```{r calculate weight from size, echo=FALSE, message=FALSE, warning=FALSE}
# Size data, from McCauley 1984 (Chapter 7)
size_zoop      <- read.delim(paste0(getpath4data(),"plankton/Zoop_size.txt"))
# Calculate average weight to get biomass
size_zoop$weight <- exp(size_zoop$a +  size_zoop$b*log(size_zoop$Average_Size))
size_zoop
```

Rotifers are not listed in the McCauley chapter, so we used a multiplying factor from <a href= "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.595.698&rep=rep1&type=pdf"> </a>.
> Dry Weights of the Zooplankton of Lake Mikri Prespa (Macedonia, Greece), Evangelia Michaloudi (2005)

But first, we need to group the species into larger group.

## Group zoop in larger groups

```{r grouping zoop species, message=FALSE, warning=FALSE}
# Group the data by at least genus

#names(zoo)
whatsleft <- 
  names(zoo[,-c(grep("aphni",     names(zoo)),
              grep("osmin",       names(zoo)),
              grep("epto",        names(zoo)),
              grep("otifer|Anuraeopsis|Ascomorpha|Asplanchna|Brachi|Collotheca|Conochilus|Cupelopagis|Euchlanis|Filinia|Kellicottia|Keratella|Lecane|Monostyla|Nothalca|Ploesoma|Polyarthra|Synchaeta|Trichocerca",    names(zoo)),
              grep("iaphanoso",               names(zoo)),
              grep("yclop",                   names(zoo)),
              grep("alanoid|Limnocalanus",    names(zoo)),
              grep("opepo|Epischura|Harpacticoid",names(zoo)))])
zoo$BOSMINA      <- rowSums(zoo[,grep("osmin",names(zoo))])     # small grazer
zoo$DAPHNIA      <- rowSums(zoo[,grep("aphni",names(zoo))])     # medium grazer
zoo$DIAPHANOSOMA <- rowSums(zoo[,grep("iaphanoso",names(zoo))]) # medium grazer
zoo$LEPTO        <- rowSums(zoo[,grep("epto", names(zoo))])      # predator
zoo$CYCLOP       <- rowSums(zoo[,grep("yclop",names(zoo))])     # copepod
zoo$CALANOID     <- rowSums(zoo[,grep("alanoid|Limnocalanus",
                                              names(zoo))])   # copepod
zoo$ROTIFER      <- rowSums(zoo[,grep("otifer|Anuraeopsis|Ascomorpha|Asplanchna|Brachi|Collotheca|Conochilus|Cupelopagis|Euchlanis|Filinia|Kellicottia|Keratella|Lecane|Monostyla|Nothalca|Ploesoma|Polyarthra|Synchaeta|Trichocerca",names(zoo))])    # small grazer
zoo$COPEPOD      <- rowSums(zoo[,grep("opepo|Epischura|Harpacticoid",names(zoo))])    # large grazer


# Group by very large groups (i.e. grazers, predators)
zoo$PREDATOR    <- rowSums(zoo[,grep("Polyphemus|LEPTO|Holopedium",names(zoo))])   
zoo$GRAZER_sm   <- rowSums(zoo[,grep("BOSMINA|Alon|Chyd|ROTIF|leurox|ladocer",names(zoo))])  
zoo$GRAZER_lr   <- rowSums(zoo[,grep("DAPHNIA|Sida|DIAPHA|CYCLOP|CALANO|opep|Eurycercus|aupl",names(zoo))])  
zoo$PARASITIC   <- zoo[,grep("Ergasilus",names(zoo))]
  
# There should be no species left here if we selected all species (only VisitDate and StationID)
whatsleft[-c(grep("Polyphemus|LEPTO|Holopedium",whatsleft),
            grep("BOSMINA|Sida|Alon|Chyd|ROTIF|leurox|ladocer",whatsleft),
            grep("DAPHNIA|DIAPHA|CYCLOP|CALANO|COPEPOD|Eurycercus|aupl",whatsleft),
            grep("Ergasilus",whatsleft))]

# Add explanatory variables to my dataframe
zoo$Year         <- as.numeric(format(as.Date(zoo$VisitDate, "%Y-%m-%d"),"%Y"))
zoo$Month        <- as.numeric(format(as.Date(zoo$VisitDate, "%Y-%m-%d"),"%m"))
zoo$yday         <- as.numeric(format(as.Date(zoo$VisitDate, "%Y-%m-%d"),"%j"))

```

## Number of organisms per groups over the years

This is the number of organisms per group over the years:

```{r visualize abundance over years, echo=FALSE, message=FALSE, warning=FALSE}
zoo_summ <- melt(zoo[,c("VisitDate", "StationID","LEPTO", "DAPHNIA", "BOSMINA", "PARASITIC")], id.vars = c("VisitDate", "StationID"))
pzoo <- ggplot(zoo_summ, aes(VisitDate,value,color=variable)) + geom_point() +
  stat_smooth() +
  xlab("Visit Date") + ylab("# organisms per m3")

ggplotly(pzoo)
```
`r fig_cap("zoop_evol", caption = "Evolution of zooplankton abundance in Lake Champlain")`

```{r View abundance per station, fig.cap = c(cap1,cap2,cap3, cap4),echo=FALSE, message=FALSE, warning=FALSE}
cap1 = fig_cap("zoop_pred", caption = "Evolution of predators zooplankton abundance in Lake Champlain")
ggplot(data = zoo, aes(x = VisitDate, y = PREDATOR)) + geom_point() +
  facet_wrap(~as.factor(zoo$StationID)) + ylim(0,20000)

cap2=fig_cap("zoop_lrgraz", caption = "Evolution of large grazers zooplankton abundance in Lake Champlain")
ggplot(data = zoo, aes(x = VisitDate, y = GRAZER_lr)) + geom_point() +
  facet_wrap(~as.factor(zoo$StationID)) + ylim(0,100000)

cap3=fig_cap("zoop_smgraz", caption = "Evolution of small grazers zooplankton abundance in Lake Champlain")
ggplot(data = zoo, aes(x = VisitDate, y = GRAZER_sm)) + geom_point() +
  facet_wrap(~as.factor(zoo$StationID)) + ylim(0,250000)


#
cap4=fig_cap("zoop_proportion", caption = "Relative change in zooplankton species")
zoo_clean <- zoo[,c("Year" ,"Month", "StationID", "BOSMINA","DAPHNIA","DIAPHANOSOMA", "CYCLOP" ,"CALANOID" , "ROTIFER"   ,"COPEPOD" ,"PREDATOR", "GRAZER_lr", "GRAZER_sm")]
zoo_clean <- zoo[,c("Year" ,"Month", "StationID","PREDATOR", "GRAZER_lr", "GRAZER_sm")]

zoo_clean <- cbind("Year"= rep(zoo$Year,3),
                   "Month"=rep(zoo$Month,3),
                   melt(zoo_clean[,3:6]))

zoo_clean <- cbind("Year"= rep(zoo$Year,81),
                   "Month"=rep(zoo$Month,81),
                   melt(zoo[,2:83]))

ggplot(zoo_clean, aes(fill=variable, y=value, x=Year)) + 
    geom_bar(position="fill", stat="identity", show.legend = F) + facet_wrap(~StationID) +
  scale_fill_manual(values = wes_palette("Darjeeling1", length(unique(zoo_clean$variable)), type = "continuous")) + theme_classic()

#ggsave(paste0(getwd(),"/Output/Figures/10-Zooplankton/Zooplankton_Community_composition_change.pdf"), width=8, height=7)

if(!R_U_KNITTING) {
  for (i in seq_along(unique(zoo_clean$StationID))) {
    p <- 
      ggplot(zoo_clean[zoo_clean$StationID==unique(zoo_clean$StationID)[i],], aes(fill=variable, y=value, x=Year)) + 
    geom_bar(position="fill", stat="identity") + 
      xlim(min(zoo_clean$Year), max(zoo_clean$Year)) +
    scale_fill_manual(values = wes_palette("Darjeeling1", length(unique(zoo_clean$variable)), type = "continuous")) + theme_classic()

 ggsave(plot = p, filename = paste0(getwd(),"/Output/Figures/10-Zooplankton/Zooplankton_Community_composition_change_Station",unique(zoo_clean$StationID)[i],".pdf"), width=18, height=7)
 
 p <- ggplotly(p)
 htmlwidgets::saveWidget(p, paste0(getwd(),"/Output/Figures/10-Zooplankton/Zooplankton_Community_composition_change_Station",unique(zoo_clean$StationID)[i],".html"))
  }
}

```

## Zooplankton biomass

Calculate biomass.
Potential paper for Calanoid? <a href="https://www.sciencedirect.com/science/article/pii/S0380133015000453">Improved estimates of calanoid copepod biomass in the St. Lawrence Great Lakes (Burgess et al, 2015)</a>.

```{r get biomass, message=FALSE, warning=FALSE}
# Biomass values were obtained from the size_zoop table
# When multiplier = 0, we're still working on collecting the data
# Convert from µg/m3 to t/km3
#           ug/m3   g/m3      g/km3        t/km3
conversion =  1  / 1000000 * 1000000000 / 1000000
# Work Alex Naccarato did over summer 2019. Values converted using average weight for different groups (e.g., several values in size_zoop for Daphnia).
# Biomass values      <- old zoop counts    ug/m3  
zoo$BOSMINA_biom      <- zoo$BOSMINA      * 1.76   * conversion
zoo$DAPHNIA_biom      <- zoo$DAPHNIA      * 32.15  * conversion
zoo$DIAPHANOSOMA_biom <- zoo$DIAPHANOSOMA * 6.32   * conversion
zoo$LEPTO_biom        <- zoo$LEPTO        * 113.31 * conversion
zoo$Polyphemus_biom <- 
         zoo$`Zoo_Polyphemus pediculus`   * 12.84  * conversion
zoo$Holopedium_biom <- 
         zoo$`Zoo_Holopedium gibberum`    * 158.15 * conversion
zoo$CYCLOP_biom       <- zoo$CYCLOP       * 16.52  * conversion
zoo$CALANOID_biom     <- zoo$CALANOID     * 0.00   * conversion
zoo$ROTIFER_biom      <- zoo$ROTIFER      * 0.2556 * conversion
zoo$COPEPOD_biom      <- zoo$COPEPOD      * 1.58   * conversion
zoo$PREDATOR_biom     <- zoo$PREDATOR     * 94.77  * conversion
zoo$GRAZER_sm_biom    <- zoo$GRAZER_sm    * 1.86   * conversion
zoo$GRAZER_lr_biom    <- zoo$GRAZER_lr    * 23.59  * conversion
zoo$PARASITIC_biom    <- zoo$PARASITIC    * 0.00   * conversion


# Replacing that work and trying to automate it a bit
# Biomass values      <- old zoop counts    ug/m3  
zoo$BOSMINA_biom      <- zoo$BOSMINA      * mean(size_zoop$weight[grep("Bosmina", size_zoop$Genus)])   * conversion
zoo$DAPHNIA_biom      <- zoo$DAPHNIA      * mean(size_zoop$weight[grep("Daphnia", size_zoop$Genus)])  * conversion
zoo$DIAPHANOSOMA_biom <- zoo$DIAPHANOSOMA * mean(size_zoop$weight[grep("Diaphanosoma", size_zoop$Genus)])   * conversion
zoo$SIDA_biom         <- zoo$`Zoo_Sida crystallina` * mean(size_zoop$weight[grep("Sida", size_zoop$Genus)])   * conversion
zoo$LEPTO_biom        <- zoo$LEPTO        * mean(size_zoop$weight[grep("Leptodora", size_zoop$Genus)]) * conversion
zoo$Polyphemus_biom <- 
         zoo$`Zoo_Polyphemus pediculus`   * mean(size_zoop$weight[grep("Polyphemus", size_zoop$Genus)])  * conversion
zoo$Holopedium_biom <- 
         zoo$`Zoo_Holopedium gibberum`    * mean(size_zoop$weight[grep("Holopedium", size_zoop$Genus)]) * conversion
zoo$CYCLOP_biom       <- zoo$CYCLOP       * mean(size_zoop$weight[grep("Cyclop", size_zoop$Genus)])  * conversion
zoo$CALANOID_biom     <- zoo$CALANOID     * 0.00   * conversion
zoo$ROTIFER_biom      <- zoo$ROTIFER      * 0.2556 * conversion
zoo$COPEPOD_biom      <- zoo$COPEPOD      * mean(size_zoop$weight[grep("Copepod", size_zoop$Genus)])   * conversion

# Unfortunately we are missing a lot of species weight length relationship (all Alona for example). 
# Instead, use the grouping prior, and then use an average weight for each group?
zoo$PREDATOR_biom     <- zoo$PREDATOR     * mean(size_zoop$weight[grep("Polyphemus|Leptodora|Holopedium", size_zoop$Genus)])  * conversion
zoo$GRAZER_sm_biom    <- zoo$GRAZER_sm    * mean(size_zoop$weight[grep("Bosmina|Chydorus", size_zoop$Genus)])   * conversion
zoo$GRAZER_lr_biom    <- zoo$GRAZER_lr    * mean(size_zoop$weight[grep("Daphnia|Sida|Diaphanosoma|Cyclops|Calanoid", size_zoop$Genus)])  * conversion
zoo$PARASITIC_biom    <- zoo$PARASITIC    * 0.00   * conversion

plot(zoo$PREDATOR, zoo$PREDATOR_biom)

# Below is the start if we were to have the weight per species.
# Group by very large groups (i.e. grazers, predators)
# zoo$PREDATOR_biom    <- rowSums(zoo[,grep("Polyphemus_biom|LEPTO_biom|Holopedium_biom",names(zoo))]) 
# zoo$GRAZER_sm_biom   <- rowSums(zoo[,grep("BOSMINA_biom|Alon_biom|Chyd_biom|ROTIFER_biom|leurox_biom|ladocer_biom",names(zoo))])  
# zoo$GRAZER_lr_biom   <- rowSums(zoo[,grep("DAPHNIA_biom|SIDA_biom|DIAPHANOSOMA_biom|CYCLOP_biom|CALANOID_biom|opep_biom|Eurycercus_biom|aupl_biom|GRAZER_lr_biom",colnames(zoo))])  


# Focus on main lake
zoo19 <- zoo[zoo$StationID==19,c("VisitDate", "StationID", "Year", "Month", "yday",
                                   "PREDATOR_biom", "GRAZER_sm_biom", "GRAZER_lr_biom", "PARASITIC_biom")]


plot(zoo19$VisitDate[zoo19$PREDATOR_biom != 0],zoo19$PREDATOR_biom[zoo19$PREDATOR_biom != 0], pch=20, col=adjustcolor("black", alpha.f = .3) , xlab="Visit Date", ylab="Biomass, t/km2")
points(zoo19$VisitDate[zoo19$GRAZER_lr_biom != 0],zoo19$GRAZER_lr_biom[zoo19$GRAZER_lr_biom != 0], pch=20, col=adjustcolor("blue", alpha.f = .3) )
points(zoo19$VisitDate[zoo19$GRAZER_sm_biom != 0],zoo19$GRAZER_sm_biom[zoo19$GRAZER_sm_biom != 0], pch=20, col=adjustcolor("red", alpha.f = .3) )
points(zoo19$VisitDate[zoo19$PARASITIC_biom != 0],zoo19$PARASITIC_biom[zoo19$PARASITIC_biom != 0], pch=20, col=adjustcolor("green", alpha.f = .3) )

ggplot(zoo19) +
  geom_point(aes(VisitDate, PREDATOR_biom, colour="Predacious")) + 
  geom_point(aes(VisitDate, GRAZER_lr_biom, colour="Large grazers")) + 
  geom_point(aes(VisitDate, GRAZER_sm_biom, colour="Small grazers")) +
  labs(x="Year", y="Biomass (t/km3)",
       title = paste0("Zooplankton Biomass, station(s) ", paste(unique(zoo19$StationID), sep="-"))) +
  theme_bw() + 
  theme(
    legend.position = c(.95, .95),
    legend.justification = c("right", "top"),
    legend.box.just = "right",
    legend.margin = margin(6, 6, 6, 6)
    ) +
  scale_colour_manual(name="Type",
                      values=c("Predacious"="black",
                               "Large grazers"="coral3",
                               "Small grazers"="deepskyblue3"))


#head(plktn)
#head(zoo19)

zoo19 <- zoo19[rowSums(zoo19[,c("PREDATOR_biom", "GRAZER_sm_biom", "GRAZER_lr_biom", "PARASITIC_biom")])>0,]
zoo19_month <- aggregate(zoo19[,c("PREDATOR_biom", "GRAZER_sm_biom", "GRAZER_lr_biom", "PARASITIC_biom")], list(format(zoo19$VisitDate, "%Y-%m")), mean)
#print(zoo19_month)
zoo19_month$Year   <- as.numeric(substr(zoo19_month$Group.1,1,4))
zoo19_month$Month  <- as.numeric(substr(zoo19_month$Group.1,6,7))
zoo19_month_Predator <- dcast(zoo19_month, Year ~ Month, value.var = "PREDATOR_biom", fun.aggregate = mean)
zoo19_month_Grazer_sm <- dcast(zoo19_month, Year ~ Month, value.var = "GRAZER_sm_biom", fun.aggregate = mean)
zoo19_month_Grazer_lr <- dcast(zoo19_month, Year ~ Month, value.var = "GRAZER_lr_biom", fun.aggregate = mean)

zoo19_month_Predator
```


## Try to assign zooplankton biomass and species name with fuzzy matching

```{r}
agrep(gsub("Zoo_","",colnames(zoo)[9]),size_zoop$Genus,max = 15, ignore.case = TRUE)

```


## Other approach: PCA
I realized that some names were too similar. For example, I thought that _LEPTO_ would call solely _Leptodora kindtii_, while, in reality, it was also using _Leptodiaptomus spp._. In this case, I could easily fix it, but what if it happen often and I am grouping several species the wrong way?  

Instead, I could try to run a PCA, and extract species contributing to each axis.

```{r zooplankton PCA}
head(zoo)
colnames(zoo)[grep("Lepto", colnames(zoo))]
plktn2[,c(1, 2, grep("Zoo_",   names(plktn2)))]
```


# Mysis

`r tab_cap("mysis", caption = "Head of the table with mysis data")`
```{r load datasets, echo=FALSE, message=FALSE, warning=FALSE}
mysis <- read.delim(paste0(getpath4data(), "data_from_Jason/mysis_long_term.txt"))
mysis$Date <- parse_date_time(mysis$Date, orders = c("d/m/Y"))
head(mysis)
```

Mysis data are available from `r paste(min(mysis$Year),"to",max(mysis$Year))`, usually from months `r paste(min(month(mysis$Date)),"to",max(month(mysis$Date)))`, for `r length(unique(mysis$Station))` (`r paste(unique(mysis$Station),sep="", collapse=", ")`).

Lake Champlain Mysid net tows = 0.5 m net, whole water column tows. 
To calculate the net area, we use the formula for the volume of a cylinder:<br>

$V = r^2 * \pi$

<br>

```{r get net area fo mysis tow}
diameter_tow = 0.5
net_area = (diameter_tow/2)^2*pi
```

The #/m<sup>2</sup> is obtained that by dividing the number counted in the tow by the volume.

```{r recalculate the number of mysis per m2}
mysis$number.m2 = mysis$Total/net_area
```

## Calculate average per year.


```{r average mysis per year, echo=FALSE, message=FALSE, warning=FALSE}
mysis_summ_d <- as.data.frame(with(mysis, tapply(number.m2
  ,list("Year"=Year,"depth_round"=round(mysis$Depth/10)*10), mean, na.rm=T)))
mysis_summ_d <- data.frame(melt(mysis_summ_d), "Year"=rep(unique(mysis$Year), times=ncol(mysis_summ_d)))

ggplot(mysis_summ_d, aes(variable, Year)) + geom_tile(aes(fill = value),colour = "white") + scale_fill_gradient(low = "white", high = "steelblue") + ggtitle("Total number of mysis per m2") + xlab("Average depth (rounded to 10 m)")

```
<br>
`r fig_cap("mysis vs years", caption="Total number of mysis per m2")`

`r tab_cap("mysis stats", caption="Average number and weight of mysis per year (with standard deviation)")`
```{r summary biomass per year, echo=FALSE, message=FALSE, warning=FALSE}
mysis_summ <- data.frame(
  "Year"=unique(mysis$Year),
  "mean"=as.vector(with(mysis, tapply(number.m2
  ,list("Year"=Year), mean, na.rm=T))),
  "sd"=as.vector(with(mysis, tapply(number.m2
  ,list("Year"=Year), sd, na.rm=T))))

mysis_summ

```


```{r view data}
with (data=mysis_summ
      , expr = errbar(Year,mean,mean+sd/2,mean-sd/2, pch=16, cap=.01, xlab="Year",ylab="mean density (# mysis/m2)", cex=.8)
        )
```
<br>
`r fig_cap("mysis abundance 1", caption="Average (and sd) mysis density per year")`

## Changepoint analysis

```{r do changepoint analysis}
#library(changepoint)
ans=cpt.mean(as.vector(mysis_summ$mean))
summary(ans)
#mysis_summ$Year[cpts(ans)]
```

Changepoint detected in `r mysis_summ$Year[cpts(ans)]`.

```{r plot changepoint on graph}
lm1 <- lm(mysis_summ$mean[1:cpts(ans)]~mysis_summ$Year[1:cpts(ans)])
lm2 <- lm(mysis_summ$mean[-c(1:cpts(ans))]~mysis_summ$Year[-c(1:cpts(ans))])


with (data=mysis_summ
      , expr = errbar(Year,mean,mean+sd/2,mean-sd/2, pch=16, cap=.01, xlab="Year",ylab="mean density (# mysis/m2)", cex=.8)
        )



lines(mysis_summ$Year[1:cpts(ans)], c(lm1$coefficients[1]+mysis_summ$Year[1:cpts(ans)]*lm1$coefficients[2]), lwd=2)

lines(mysis_summ$Year[-c(1:cpts(ans))], c(lm2$coefficients[1]+mysis_summ$Year[-c(1:cpts(ans))]*lm2$coefficients[2]), lwd=2)
                            


```
<br>
`r fig_cap("mysis_abundance_2", caption="Average (and sd) mysis density per year. Linear regression for the two periods detected.")`


## Get biomass in grams
Using mysis weight data from Chesapeake Bay (given by Rosie) to get an estimate of average/median weigth.

```{r read mysis data}
mysis_w <- read.delim(paste0(getpath4data(),"data_from_Rosie/ChesapeakeBay_Mysis_oxygen_consumption_data_RC_AN.txt"))
```

```{r plot mysis weigth, echo=FALSE, message=FALSE, warning=FALSE}
p1<- ggplot(data=mysis_w, aes(mysis_w$Wet_wt, fill=Sex)) + 
  geom_histogram(col="black") + xlab("Mysis wet weight (mg)") + theme(legend.position = "none")
p2<- ggplot(data=mysis_w, aes(mysis_w$Dry_wt..mg., fill=Sex)) + 
  geom_histogram(col="black") + xlab("Mysis dry weight (mg)")

grid.arrange(p1,p2,nrow=1, widths=c(1,1.3))

mysis_w_mean    = mean(mysis_w$Wet_wt, na.rm=T)
mysis_w_median  = median(mysis_w$Wet_wt, na.rm=T)
```
`r fig_cap("mysis dry and wet weigth", caption="Distribution of mysis dry and wet weigth")`


The distribution is not normal, so median value should be chosen over mean. <br>
* mean: `r mysis_w_mean` <br
* median: `r mysis_w_median`<br>

We multiply the mysis count per this biomass:
```{r calculate mean mysis biomass and visualise}
mysis_summ$mean_w <- mysis_summ$mean*mysis_w_median
mysis_summ$sd_w <- mysis_summ$sd*mysis_w_median

with (data=mysis_summ
      , expr = errbar(Year,mean_w,mean_w+sd_w/2,mean_w-sd_w/2, pch=16, cap=.01, xlab="Year",ylab="mean biomass (mg mysis/m2)", cex=.8)
        )
```
<br>`r fig_cap("mysis biomass 1", caption="Average (and sd) mysis biomass per year")`

## Get biomass in t/km2
1 g.m<sup>-2</sup> = 1,000,000 t.m<sup>-2</sup> = 1,000,000/1e-6 t.km<sup>-2</sup> = 1t.km<sup>-2</sup> 


# Benthic invertebrates

## Juvenile densities

__Data:__ <br>
  * Monitoring data initiated during the initial colonization
  * 2014 survey, data handed by Ellen on January 11, 2020.

From the <a href="https://dec.vermont.gov/watershed/lakes-ponds/aquatic-invasives/monitoring/zebra-mussels">VTDEC website</a>:
"The Vermont Department of Environmental Conservation (VTDEC), in cooperation with the Lake Champlain Basin Program, initiated the Lake Champlain Zebra Mussel Monitoring Program in 1994 to track the zebra mussel's distribution through the lake. Reports are provided annually.

The efficient combination of the Zebra Mussel Monitoring Program with the Long-term Water Quality and Biological Monitoring Program provides a nationally unique lake database. Information on veliger and juvenile densities monitored consistently since the initial colonization is obtained concurrently with comprehensive water quality data. This information is critical to determining the effects of zebra mussels on the Lake Champlain ecosystem and the potential risk and impact of zebra mussel colonization of other water bodies.

Zebra mussel monitoring includes veliger (larvae), settled veliger (juvenile), and adult life stages at open-water and nearshore lake stations, lake tributaries and inland lakes. Greater emphasis is placed on veliger monitoring, as it is in their pelagic stage that zebra mussels are most easily spread and sampled in Lake Champlain.

Zebra mussels in Lake Champlain continued to reproduce and settle successfully during 2018. The range expansion in the Northeast Lake is now complete.  Zebra mussel adults have been well established in the South, Central, and Northwest Lake since 1996. Season settling plates retrieved at nearshore stations in these areas in 2018 confirm continued reproductive success, and similar growth rates as in years past. 
"

__Other resources:__ <br
<a href="https://dec.vermont.gov/sites/dec/files/wsm/lakes/images/lp_zm-sitemap.gif">Map of sampling locations</a>
  
__STA19__ in the veligers dataset is the station in the Main Lake. I'm going to extract these density to start with (veligers/m3)

```{r read ZM data from state, message=FALSE, warning=FALSE, include=FALSE}
ZMjuv <- read.delim(paste0(getpath4data(),"VTDEC_zebra_mussel/Juvenile_ZM.txt"))
ZMvel <- read.delim(paste0(getpath4data(),"VTDEC_zebra_mussel/Veliger_ZM.txt"))
ZMjuv$Date <- as.Date(ZMjuv$Date, format="%d/%m/%Y")
ZMvel$Date <- as.Date(ZMvel$Date, format="%d/%m/%Y")
head(ZMjuv)
tail(ZMvel)
unique(ZMjuv$Lake.Sta)
unique(ZMvel$LakeSta)


```

```{r get summary per year veligers station 19}
ZMvel_summ <- as.data.frame(with(ZMvel, tapply(ZMvel[,"Density"],
  list("Year"=Expr1,"station"=LakeSta), mean, na.rm=T)))
ZMvel_summ <- ZMvel_summ[,colSums(ZMvel_summ,na.rm=T)>0]

plot(rownames(ZMvel_summ),ZMvel_summ$STA19, xlab="Year", ylab="Seasonal mean density (veligers/m3)", type="l")

#Data extracted from the graph using WebPlotDigitizer on Google Chrome because excel is missing some lines
#Source plot:
# https://dec.vermont.gov/sites/dec/files/wsm/lakes/ans/images/1994-2018%20NE%20Seasnly-int%20graphs1.pdf
#log scale
ZMvel_STA19 <- data.frame("Year"=c(1994:2005,2011:2018), "Density"=c(0,167,4734,4973,12056,11477,20713,19718,6359,7017,8133,17871,2051,7750,1953,2623,5487,8974,10926,7371))
#lines(ZMvel_STA19$Year,ZMvel_STA19$Density, col="pink")
#==> not exactly the same data, what's wrong? Ask Pete Stangel maybe

```

## Adult survey

```{r zebra mussels from 2014 survey, echo=FALSE}
ZM14 <- read.delim(paste0(getpath4data(),"data_from_Ellen/QZ_database_2014-07-28.txt"))
summary(ZM14)

i=2 # Longitude
ZM14 <- 
  mutate(ZM14, Lon = case_when(Site == "Missisquoi Bay" ~ c(45.022313, -73.133799)[i],
                             Site == "Colchester Point" ~ c(44.566795, -73.312679)[i],
                             Site == "Alburgh Passage" ~ c(44.862116, -73.294569)[i],
                             Site == "Appletree Bay" ~ c(44.500161, -73.267250)[i],
                             Site == "Arnold Bay" ~ c(44.147666, -73.369197)[i],
                             Site == "Benson Landing" ~ c(43.728599, -73.368032)[i],
                             Site == "Chipman Point" ~ c(43.800849, -73.375585)[i],
                             Site == "Chipman Point Marina" ~ c(43.799592, -73.375258)[i],
                             Site == "Collymer Point" ~ c(44.416279, -73.243882)[i],
                             Site == "Crown Point Bridge" ~ c(44.031132, -73.425729)[i],
                             Site == "Cumberland Bay" ~ c(44.702587, -73.408615)[i],
                             Site == "Cumberland Head" ~ c(44.690977, -73.390591)[i],
                             Site == "Eagle Mountain" ~ c(44.670408, -73.213337)[i],
                             Site == "Gordon Landing" ~ c(44.688837, -73.348902)[i],
                             Site == "Inland Sea" ~ c(44.730856, -73.225923)[i],
                             Site == "Island Line Causeway" ~ c(44.556216, -73.303760)[i],
                             Site == "Mallets Bay" ~ c(44.570940, -73.198126)[i],
                             Site == "Rouses Point Bridge" ~ c(44.995481, -73.342855)[i],
                             Site == "St. Albans Bay" ~ c(44.783680, -73.153395)[i],
                             Site == "Texaco Beach" ~ c(44.457352, -73.224607)[i],
                             Site == "Trembleau Point" ~ c(44.522325, -73.391025)[i],
                             Site == "Wilcox Bay" ~ c(44.702352, -73.350381)[i]
                             ))

i=1 # Latitude
ZM14 <- 
  mutate(ZM14, Lat = case_when(Site == "Missisquoi Bay" ~ c(45.022313, -73.133799)[i],
                             Site == "Colchester Point" ~ c(44.566795, -73.312679)[i],
                             Site == "Alburgh Passage" ~ c(44.862116, -73.294569)[i],
                             Site == "Appletree Bay" ~ c(44.500161, -73.267250)[i],
                             Site == "Arnold Bay" ~ c(44.147666, -73.369197)[i],
                             Site == "Benson Landing" ~ c(43.728599, -73.368032)[i],
                             Site == "Chipman Point" ~ c(43.800849, -73.375585)[i],
                             Site == "Chipman Point Marina" ~ c(43.799592, -73.375258)[i],
                             Site == "Collymer Point" ~ c(44.416279, -73.243882)[i],
                             Site == "Crown Point Bridge" ~ c(44.031132, -73.425729)[i],
                             Site == "Cumberland Bay" ~ c(44.702587, -73.408615)[i],
                             Site == "Cumberland Head" ~ c(44.690977, -73.390591)[i],
                             Site == "Eagle Mountain" ~ c(44.670408, -73.213337)[i],
                             Site == "Gordon Landing" ~ c(44.688837, -73.348902)[i],
                             Site == "Inland Sea" ~ c(44.730856, -73.225923)[i],
                             Site == "Island Line Causeway" ~ c(44.556216, -73.303760)[i],
                             Site == "Mallets Bay" ~ c(44.570940, -73.198126)[i],
                             Site == "Rouses Point Bridge" ~ c(44.995481, -73.342855)[i],
                             Site == "St. Albans Bay" ~ c(44.783680, -73.153395)[i],
                             Site == "Texaco Beach" ~ c(44.457352, -73.224607)[i],
                             Site == "Trembleau Point" ~ c(44.522325, -73.391025)[i],
                             Site == "Wilcox Bay" ~ c(44.702352, -73.350381)[i]
                             ))

head(ZM14)


ggplot(ZM14, aes(Length_mm,Width_mm, color=Live_Dead)) + geom_point() +
  geom_smooth() + 
  xlim(quantile(ZM14$Length_mm, c(0.0005,0.9995))) +
  ylim(quantile(ZM14$Width_mm, c(0.0005,0.9995))) +
  labs(x="Length (mm)", y = "Width (mm)",color='') +
  theme_bw() + scale_color_hue(l=40, c=35) +
    theme(legend.position="bottom")


rbin::rbin_manual(ZM14, response = Width_mm, predictor = Length_mm, cut_points = seq(2,40,by=2))


ggplot(ZM14, aes(Length_mm)) + 
  geom_histogram(aes(y=..density..),binwidth=2,fill="#006666",color="white",alpha=0.7) + 
  geom_density() + 
  facet_wrap(~Site)+
  geom_rug() +
  labs(x='Length (mm)') + 
  theme_bw()

ZM14_live_dead <- as.data.frame(with(ZM14, tapply(rep(1,nrow(ZM14))
  ,list("Sites"=Site,"Live_Dead#"=Live_Dead), sum, na.rm=T)))
ZM14_live_dead$Site <- rownames(ZM14_live_dead)
ZM14_live_dead_melt <- melt(ZM14_live_dead)


```


`r tab_cap("ZM_sample_type", "Way each individual were collected at each station.")` <br>
```{r ZM summary sample type for each station, echo=FALSE, message=FALSE, warning=FALSE}
ZM14_sample_type1 <- as.data.frame(with(ZM14, tapply(rep(1,nrow(ZM14))
  ,list("Sample_Type"=Sample_Type,"Site"=Site), sum, na.rm=T)))
rbind(ZM14_sample_type1, "*Number of techniques used"=apply(ZM14_sample_type1, 2, function(x) sum(!is.na(x))))

```

Ponar technique gets a lot of dead mussels because there might be dead mussels on the sediment. Dive sample involved Ellen diving and scraping off mussels from a quaddrat. These mussels would almost always be alive.
<br> `r tab_cap("ZM_dead_live_sample_type", "Live or dead mussels per sampling type.")` <br>
```{r ZM live or dead depending on sampling technique, echo=FALSE, message=FALSE, warning=FALSE}
as.data.frame(with(ZM14, tapply(rep(1,nrow(ZM14))
  ,list("Sample_Type"=Sample_Type,"Live_Dead"=Live_Dead), sum, na.rm=T)))

ggplot(ZM14_live_dead_melt, aes(Site,value, fill=variable)) +
  geom_bar(stat="identity", position=position_dodge()) + 
  coord_flip() +
  scale_fill_manual("",values = c("Dead"="#cc3399","Live"="#008080","N/A"="grey")) +
  theme_bw() +
  labs(x="Count")
```
<br> `r fig_cap("ZM_count_per_site", "Count of mussels per monitoring site.")`


Look at the number of methods / samples per sites.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Same number of Rep is used accross sites.
summary(ZM14$Site[ZM14$Rep==1]) 
# Create a new column with site name and number replicate
ZM14$SiteRep <- paste(ZM14$Site, ZM14$Rep, sep="_")


ZM14_sample_type2 <- as.data.frame(with(ZM14, tapply(rep(1,nrow(ZM14))
  ,list("Sample_Type"=Sample_Type,"Site"=SiteRep), sum, na.rm=T)))
ZM14_summ_sample <- apply(ZM14_sample_type2, 2, function(x) sum(!is.na(x)))
ZM14_summ_sample[order(ZM14_summ_sample, decreasing = T)]

```

`r english::Words(length(ZM14_summ_sample[ZM14_summ_sample>1]))` sites have replicate numbers that refers to more than one sampling technique. I can't pool the data for: `r paste("<br>- ", names(ZM14_summ_sample[ZM14_summ_sample>1]), collapse="")`


Below I created summary table of the number of mussels per replicate. Some sites have many replicates (e.g., Missisquoi Bay), some have only one (e.g., Gordon Landing). I added as color the percentage of live vs. dead zebra mussels on first plot, 

```{r number of mussels per sites}
#Look at total number of mussels per site ####
ZM14_summ_sites <- as.data.frame(with(ZM14, tapply(rep(1,nrow(ZM14))
  ,list("SiteRep"=SiteRep,"Site"=Site), sum, na.rm=T)))

ZM14_stats_sites <- data.frame("Site" = colnames(ZM14_summ_sites),
                               "Avg"  = colMeans(ZM14_summ_sites, na.rm=T),
                               "sd"   = apply(ZM14_summ_sites, 2, function(x) sd(x,na.rm=T)),
                               "min"   = apply(ZM14_summ_sites, 2, function(x) min(x,na.rm=T)),
                               "max"   = apply(ZM14_summ_sites, 2, function(x) max(x,na.rm=T)),
                               "median"   = apply(ZM14_summ_sites, 2, function(x) median(x,na.rm=T)),
                               "n"   = apply(ZM14_summ_sites, 2, function(x) sum(!is.na(x))))

# Percentage mussels alive
ZM14_live_dead_per_live <- ZM14_live_dead$Live/rowSums(ZM14_live_dead[,c("Dead", "Live", "N/A")], na.rm=T)
ZM14_live_dead_per_live[is.na(ZM14_live_dead_per_live)] <-0

# Prep for plot
ZM14_summ_sites_melt <- melt(cbind(rownames(ZM14_summ_sites),ZM14_summ_sites))
mcol <- rep(NA, nrow(ZM14_summ_sites_melt))
for (i in 1:length(unique(ZM14_summ_sites_melt$variable))) {
    mcol[ZM14_summ_sites_melt$variable==unique(ZM14_summ_sites_melt$variable)[i]] <- ZM14_live_dead_per_live[which(names(ZM14_live_dead_per_live)==unique(ZM14_summ_sites_melt$variable)[i])]  }
ZM14_summ_sites_melt$percent_live <- mcol

#head(ZM14_summ_sites_melt)
p <- ggplot(ZM14_summ_sites_melt, aes(factor(variable), value, fill=percent_live*100))
p <- p + geom_boxplot() +
  labs(x="Sites", y="Number of zebra mussels", subtitle = "a. Zebra mussels collected per site (live and dead)", fill="Percentage zebra \nmussels alive") + 
  coord_flip() + theme_bw() +
    theme(legend.position="bottom") +scale_fill_gradient(low="#DC143C", high="#4169E1")
#p
#ggsave(paste0(getwd(),"/Output/Figures/7-ZebraMussels/Number_zm_per_site.pdf"))

#Number of live mussels per sites, fill = type of sampling method####
ZM14_summ_sites_live <- as.data.frame(with(ZM14[ZM14$Live_Dead=="Live",], tapply(rep(1,nrow(ZM14[ZM14$Live_Dead=="Live",]))
  ,list("SiteRep"=SiteRep,"Site"=Site), sum, na.rm=T)))

# Type of method
ZM14_summ_method <- as.data.frame(with(ZM14, tapply(rep(1,nrow(ZM14))
  ,list("Sites"=SiteRep,"Sample_Type"=Sample_Type), sum, na.rm=T)))

ZM14_summ_method <- melt(cbind("Site"=rownames(ZM14_summ_method),ZM14_summ_method))
ZM14_summ_method <- ZM14_summ_method[!is.na(ZM14_summ_method$value),]
head(ZM14_summ_method)

ZM14_stats_sites_live <- data.frame("Site" = colnames(ZM14_summ_sites_live),
                               "Avg"  = colMeans(ZM14_summ_sites_live, na.rm=T),
                               "sd"   = apply(ZM14_summ_sites_live, 2, function(x) sd(x,na.rm=T)),
                               "min"   = apply(ZM14_summ_sites_live, 2, function(x) min(x,na.rm=T)),
                               "max"   = apply(ZM14_summ_sites_live, 2, function(x) max(x,na.rm=T)),
                               "median"   = apply(ZM14_summ_sites_live, 2, function(x) median(x,na.rm=T)),
                               "n"   = apply(ZM14_summ_sites_live, 2, function(x) sum(!is.na(x))))

ZM14_summ_sites_live_melt <- melt(cbind(rownames(ZM14_summ_sites_live),ZM14_summ_sites_live))
mcol <- rep(NA, nrow(ZM14_summ_sites_live_melt))
for (i in 1:length(unique(ZM14_summ_sites_live_melt$variable))) {
    mcol[ZM14_summ_sites_live_melt$variable==unique(ZM14_summ_sites_live_melt$variable)[i]] <- paste(ZM14_summ_method$variable[which(paste(ZM14_summ_method$Site)==paste(unique(ZM14_summ_sites_live_melt$`rownames(ZM14_summ_sites_live)`)[i]))])
    }
ZM14_summ_sites_live_melt$Sample_type <- mcol



#head(ZM14_summ_sites_live_melt)
p1 <- ggplot(ZM14_summ_sites_live_melt, aes(factor(variable), value, fill=Sample_type, color=Sample_type))  + geom_boxplot() +
  labs(x="Sites", y="Number of zebra mussels", title = "b. Live zebra mussels collected per site", fill="Sampling method", col="") + 
  coord_flip() + theme_bw() +
    theme(legend.position="bottom") + scale_fill_manual(values=adjustcolor(wes_palette("Darjeeling1",n =  length(unique(ZM14_summ_sites_live_melt$Sample_type)), type="continuous"), alpha.f = .5)) + scale_color_manual(values=wes_palette("Darjeeling1",n =  length(unique(ZM14_summ_sites_live_melt$Sample_type)), type="continuous")) + guides(col=FALSE)
#p1
#ggsave(paste0(getwd(),"/Output/Figures/7-ZebraMussels/Number_live_zm_per_sample.pdf"),p1)

p2 <- grid.arrange(p,p1+scale_x_discrete(position = "top"),ncol=2)
#ggsave(paste0(getwd(),"/Output/Figures/7-ZebraMussels/Summary_Number_ZM.pdf"),p2, width = 11, height = 5)

```


Now I'd like to plot these average number per sites

```{r}
ZM14_stats_sites_live$Sample_type <- rep(NA, nrow(ZM14_stats_sites_live))
ZM14_stats_sites_live$Lon   <- rep(NA, nrow(ZM14_stats_sites_live))
ZM14_stats_sites_live$Lat  <- rep(NA, nrow(ZM14_stats_sites_live))
  
for (i in 1:nrow(ZM14_stats_sites_live)) {
  temporary <- summary(ZM14$Sample_Type[ZM14$Site==ZM14_stats_sites_live$Site[i]])
    ZM14_stats_sites_live$Sample_type[i] <- paste(
      names(temporary[temporary==max(temporary, na.rm=T)])
    )
    rm(temporary)
    
    ZM14_stats_sites_live$Lon[i] <- ZM14$Lon[ZM14$Site==ZM14_stats_sites_live$Site[i]][1]
    ZM14_stats_sites_live$Lat[i] <- ZM14$Lat[ZM14$Site==ZM14_stats_sites_live$Site[i]][1]
}

#write.table(ZM14_stats_sites_live, file = "Output/Data/zebra_mussels_2014_summary_data.txt", sep="\t")

```


Left to do:  
We have abundances per replicate, but how to convert that to an area? We need the surface area of the ponar, and the video sample, et al.

Converting everything in number / km^2^

```{r}

# petite ponar 152 x 152 mm * 10^-12 (mm2 to km2)
zm_ponar    <- 152 * 152    * 1e-12 
zm_bigrock <- 1#
zm_rocksample <- 1
zm_underdocks <- 1
zm_gillnet <- 1
zm_trawl <- 1
zm_benthicsample <- 1


ZM14_stats_sites_live %>% 
  mutate(Avg_number_km2  = case_when(
    Sample_type == "Ponar"  ~ Avg/zm_ponar,
    Sample_type == "Big Rock"  ~ Avg/zm_bigrock,
    Sample_type == "Rock Sample"  ~ Avg/zm_rocksample,
    Sample_type == "Under Docks"  ~ Avg/zm_underdocks,
    Sample_type == "Gillnet"  ~ Avg/zm_gillnet,
    Sample_type == "Bottom Trawl"  ~ Avg/zm_trawl,
    Sample_type == "Benthic Sample"  ~ Avg/zm_benthicsample
        ))


```


```{r width and length per site}
#ggplot(ZM14, aes(Length_mm, Width_mm)) + geom_point()
# First way to look at it, do an average per site (no consideration of the rplicates.
ZM14_summ_sites_live_length_1 <- with(ZM14[ZM14$Live_Dead=="Live",], tapply(Length_mm
  ,list("Site"=Site), mean, na.rm=T))
ZM14_summ_sites_live_width_1 <- with(ZM14[ZM14$Live_Dead=="Live",], tapply(Width_mm
  ,list("Site"=Site), mean, na.rm=T))

ZM14_summ_sites_live_length_width_method1 <- 
  data.frame("Site"=names(ZM14_summ_sites_live_length_1),
             "Length_mm" = ZM14_summ_sites_live_length_1,
             "Width_mm" = ZM14_summ_sites_live_width_1)

# Second way to look at it, do an average per replicate, then average per site.
ZM14_summ_sites_live_length <- as.data.frame(with(ZM14[ZM14$Live_Dead=="Live",], tapply(Length_mm
  ,list("SiteRep"=SiteRep,"Site"=Site), mean, na.rm=T)))
ZM14_summ_sites_live_length_2 <- colMeans(ZM14_summ_sites_live_length, na.rm = T)

ZM14_summ_sites_live_width <- as.data.frame(with(ZM14[ZM14$Live_Dead=="Live",], tapply(Width_mm
  ,list("SiteRep"=SiteRep,"Site"=Site), mean, na.rm=T)))
ZM14_summ_sites_live_width_2 <- colMeans(ZM14_summ_sites_live_width, na.rm = T)

temp1 <- melt(cbind(rownames(ZM14_summ_sites_live_length),ZM14_summ_sites_live_length))
colnames(temp1) <- c("SiteRep", "Site", "Length_mm")
temp2 <- melt(cbind(rownames(ZM14_summ_sites_live_width),ZM14_summ_sites_live_width))
colnames(temp2) <- c("SiteRep", "Site", "Width_mm")
ZM14_summ_sites_live_length_width <- cbind(temp1, "Width_mm"=temp2$Width_mm)
ZM14_summ_sites_live_length_width <- ZM14_summ_sites_live_length_width[!is.na(ZM14_summ_sites_live_length_width[,3]) ,]


#head(ZM14_summ_sites_live_length_width)
p1 <- ggplot(ZM14_summ_sites_live_length_width, aes(Length_mm, Width_mm, color=Site))  + geom_point() +
  labs(x="Length(mm)", y="Width (mm)", title = "a. Width-Length relationship zebra mussels per site", col="")  + theme_bw() +
    theme(legend.position="bottom")

p2 <- ggplot(ZM14_summ_sites_live_length_width, aes(Site, Length_mm))  + geom_boxplot() +
  labs(x="", y="Length (mm)", title = "b. Zebra mussel length per site") + 
  coord_flip() + theme_bw() 

p3 <- ggplot(ZM14_summ_sites_live_length_width, aes(Site, Width_mm))  + geom_boxplot() +
  labs(x="", y="Width (mm)", title = "c. Zebra mussel width per site") + 
  coord_flip() + theme_bw()
  

p4 <- grid.arrange(p1,p2,p3,ncol=3)
p4

#ggsave(paste0(getwd(),"/Output/Figures/7-ZebraMussels/Length_width_zebra_mussels_per_site_1.pdf"),p4, width=14,height=6)


# Difference between two methods (do the whole mean, or first do average per replicate)
ZM14_diff_mean_width_length <- data.frame("Site" = names(ZM14_summ_sites_live_length_1),
"Diff_Length"= as.vector(ZM14_summ_sites_live_length_1-ZM14_summ_sites_live_length_2),
"Diff_Width"= as.vector(ZM14_summ_sites_live_width_1-ZM14_summ_sites_live_width_2))

ZM14_diff_mean_width_length <-melt(ZM14_diff_mean_width_length)

ggplot(ZM14_diff_mean_width_length, aes(Site,value, fill=variable)) +
  geom_bar(stat = "identity", position=position_dodge()) +
  coord_flip() + theme_bw() 

```


# Sculpin

# Trout-perch

__Data: __
<br> 
We can calculate CPUE from trawling (bycatch data, 2016-2018). A length distribution for trout perch collected in Lake Champlain is available from measurements collected during the WFB 161 lab (fall 2018). Finally, total length for fish aged `r paste0(min(TroutperchLM1$age),"-",max(TroutperchLM1$age))` (fish aged using scales) is available through the FSAdata library (D. Ogle).


## Data from Ellen -- bycatch from the LT recruitment survey

### Sample locations for trout-perch data 
Data for trout perch (`r nrow(byc[byc$species=="trout-perch",])` observations) were collected and are summarized in the bycatch dataframe. Observations on `r length(summary(byc$site[byc$species=="trout-perch"]))` sites -- sites with higher number of observation are listed below.

```{r where are trout perch found, echo=FALSE, message=FALSE, warning=FALSE}
summ_tp <- summary(byc$site[byc$species=="trout-perch"])
summ_tp[order(summ_tp, decreasing = T)][1:5]

```


```{r trout perch subset, message=FALSE, warning=FALSE, include=FALSE}
#trout perch subset
tps <- byc[byc$species=="trout-perch" & byc$site=="burlington bay",]
tps <- byc[byc$species=="trout-perch" ,]
tps$tote..fullness.[tps$tote..fullness.=="na"] <- NA
tps$est_number[tps$est_number=="na"] <- NA
tps$est_number <- as.numeric(paste(tps$est_number))

# when info is given in tote..fullness., sometimes it says only the fraction, sometimes x/x tote full, sometimes x/x fish tote.
# to qa/qc, remove all mention of tote, keep only the fraction
tps$tote..fullness.[grep("tote", tps$tote..fullness.)] <- substr(tps$tote..fullness.[grep("tote", tps$tote..fullness.)],1,3)
gsub(" ",NA,tps$tote..fullness.)

#View(tps[,c("est_number","tote..fullness.")])
#View(byc[,c("species","est_number","tote..fullness.")])

# Convert to character the 3 columns with fullness info to ease the cleaning process
tps$tote..fullness. <- as.character(tps$tote..fullness.)
tps$X..of.tote      <- as.character(tps$X..of.tote)
tps$est_number      <- as.character(tps$est_number)

```

Unfortunately, there's only one correspondance between 'tote fulness' and 'estimated number': 100 (est. number) = 1 layer.
Talking to Ellen and Pascal, they told me it was too high. It's most likely there's only 40 or so. Talk to fisheries biologist working on other lakes maybe?
For the sake of getting a bit more estimates, trying to convert tote fullness into number.


```{r how many layers of trout perch in 1/4 of a tote}
# 1 layer = 100? 35? how many? find out.
# It's easier (at least for me) to count layers over 1/4 of a fish tote
# I'm assuming there's about 8 layers in 1/4 of a tote
# Meaning that in a tote, there are
#                       number layer in 1/4  * bring back to 1/1
layer_tote_troutperch = 8                    *        4
# tote_troutperch = number in layer *  number layer tote
( tote_troutperch =      40         * layer_tote_troutperch)
```


Now that we somewhat have an estimation of number per tote, convert that back and get an idea of the average abundance. <br>

Note that right now, we are trusting __estimated number__ over __tote fullness__ over __percentage of tote__. <br>

```{r convert percentage and fullness into number of fish}
tps$fish_count <- rep(NA, nrow(tps))

for (i in 1:nrow(tps)) {
  # Turn all to false at the beginning of each loops
  C1=F;C2=F;C3=F
  if(i==1) {n1=0;n2=0;n3=0;nbis1=0;nbis2=0;nbis3=0}
  
  # Case 1: percentage is available
  if(!is.na(tps$X..of.tote[i]) & tps$X..of.tote[i]!="na" & tps$X..of.tote[i]!="") {
    n1=n1+1
    C1=T
    options(warn=-1)
    tps$fish_count[i] = as.numeric(gsub("[\\%,]", "", tps$X..of.tote[i]))
    options(warn=0)
    # Sometimes there's some fraction in the percent column -- consider this as an error
    if(is.na(tps$fish_count[i])) {n1=n1-1}
  }
  
  # Case 2: tote fullness are available
  if(!is.na(tps$tote..fullness.[i]) & tps$tote..fullness.[i]!="") {
    n2=n2+1
    C2=T
    # This is the most complicated case, because sometimes it says layers, sometimes it's a fraction, sometimes it's just a multiplying of layers
    if(tps$tote..fullness.[i]=="full") {
      tps$fish_count[i] = tote_troutperch
    } else {
      if (any(c("layer","layers","single") %in% unlist(strsplit(tps$tote..fullness.[i]," ")))) {
      # If there's a layer, we'll reuse or estimate of number of layers per tote
      nb_layer = layer_tote_troutperch
      tps$fish_count[i] = gsub("layer|layers", "", tps$tote..fullness.[i])
      if ("single" %in% unlist(strsplit(tps$fish_count[i]," "))) {
       tps$fish_count[i] = gsub("single ", "1", tps$fish_count[i])
      }
    } else {
      # if no "layer" in the line, the fraction refers to the full tote, so we're defaulting nb_layer to 1
      nb_layer = 1
      tps$fish_count[i] = tps$tote..fullness.[i]
    }
      
      # If there's a space at the beginning, it can mess up everything. 
      # Removing all first spaces
      while(unlist(strsplit(tps$fish_count[i],""))[1]==" ") tps$fish_count[i] = paste(unlist(strsplit(tps$fish_count[i],""))[-1], sep = "",collapse = "")
      
      # if it's a fraction, we'll have a "/"
    if ("/" %in% unlist(strsplit(tps$fish_count[i],""))) {
      if(" " %in% unlist(strsplit(tps$fish_count[i],split = ""))) {
        tps$fish_count[i] = tote_troutperch *
       as.numeric(unlist(strsplit(tps$fish_count[i],split = "/"))[1]) /
       as.numeric(unlist(strsplit(unlist(strsplit(tps$fish_count[i],split = "/"))[2]," "))[1]) *
       as.numeric(unlist(strsplit(unlist(strsplit(tps$fish_count[i],split = "/"))[2]," "))[2]) /
       nb_layer
      } else {
                tps$fish_count[i] = tote_troutperch *
       as.numeric(unlist(strsplit(tps$fish_count[i],split = "/"))[1]) /
       as.numeric(unlist(strsplit(tps$fish_count[i],split = "/"))[2])  /
       nb_layer
      }
    } else {
      tps$fish_count[i] = tote_troutperch * as.numeric(tps$fish_count[i]) / nb_layer
  }
    }
    
    } 
  
  
  # Case 3: estimated numbers are available
  if(!is.na(tps$est_number[i])) {
    n3=n3+1
    C3=T
    tps$fish_count[i] = tps$est_number[i]
  }
  
  # Were indicators present twice?
  if(C1&C2) nbis1 = nbis1 + 1
  if(C1&C3) nbis2 = nbis2 + 1
  if(C2&C3) nbis3 = nbis3 + 1
  
  if(all(is.na(tps$fish_count[i]) & any(C1|C2|C3))) stop(print(i))
  
  if(i==nrow(tps)) message(paste0(" ✓ There are ",n1," lines with info on percentage fullness. \n ✓ There are ",n2," lines with info on tote fullness. \n ✓ There are ",n3," lines with info on estimated number. \n ✕ There were ",nrow(tps)-n1-n2-n3, " lines with no info on how many fish are present.\n\n Note that:\n   - both percent and tote fullness were available for ",nbis1, " lines,\n   - both percent and est. number were available for ",nbis2, " lines,\n   - both est.number and tote fullness were available for ",nbis3, " lines."))
}

tps$fish_count <- as.numeric(tps$fish_count)
```

We now have estimated number of trout perch for `r length(which(!is.na(tps$fish_count)))` sampling event out of `r nrow(tps)` total events with trout perch collected (i.e., `r round(length(which(!is.na(tps$fish_count)))/nrow(tps)*100)`% of the events).

It'd be easier to assign the GPS coordinates to each date to be sure there's not a big spot with / without trout-perch. <br>
[Code hidden to save plot on the .html, go to .Rmd to see it]

```{r match gps coordinates and duration trawls for trout perch surveys, message=FALSE, warning=FALSE, include=FALSE}
# Read LTeff compiled
melo_effort <- read.delim(paste0(getpath4data(),"data_from_Pascal/LTeff_compiled_RB.txt"))
tps$start.lon.dd <- rep(NA, nrow(tps))
tps$end.lon.dd <- rep(NA, nrow(tps))
tps$start.lat.dd <- rep(NA, nrow(tps))
tps$end.lat.dd <- rep(NA, nrow(tps))
tps$duration <- rep(NA, nrow(tps))
for (i in 1:nrow(tps)) {
  if(i==1) {n1=0;n2=0;whichn1=NULL}
  narrow2day <- melo_effort[as.character(melo_effort$date)==as.character(tps$date[i]),]
  narrow2trawl <- narrow2day[as.numeric(paste(narrow2day$netID))==as.numeric(paste(tps$netID[i])),]
  if(nrow(narrow2trawl)==1 & narrow2trawl$start.lat.dd != "#VALUE!" && as.numeric(paste(narrow2trawl$start.lat.dd)) > 0) {
    tps$start.lon.dd[i] <- as.numeric(paste(narrow2trawl$start.lon.dd))
    tps$end.lon.dd[i]   <- as.numeric(paste(narrow2trawl$end.lon.dd))
    tps$start.lat.dd[i] <- as.numeric(paste(narrow2trawl$start.lat.dd))
    tps$end.lat.dd[i]   <- as.numeric(paste(narrow2trawl$end.lat.dd))
    tps$duration[i]     <- substr(narrow2trawl$duration,4,5)
    n1 <- n1+1 # for info message
  } else {
      n2 <- n2+1 # for info message
      whichn1 <- c(whichn1,i)
      }
  # Info message
  if(i==nrow(tps)) message(paste0(" ✓ Found matching GPS coordinates for ", n1," of the trawls","\n ✕ No or several potential GPS coordinates were found for ", n2, " of the trawls (call 'whichn1' in the console to know which rows of the dataframe were not matched, or find the rows with NAs)." ))
}

tps$avg.lon.dd <- (tps$start.lon.dd+tps$end.lon.dd)/2
tps$avg.lat.dd <- (tps$start.lat.dd+tps$end.lat.dd)/2

```


`r fig_cap("troutperch number lake", caption="Circle size shows the number of trout-perch collected per sampling event. Colour scale refers to day of the year. Rectangle identify Burlington Bay. [you can zoom and unzoom on the map if you're reading the html version]", display = FALSE)`

`r fig_cap("troutperch number lake", display="cite")` shows the number of trout perch collected against the center location of the trawl. The radius show the number of fish captured. Note that we have CPUE (1 unit effort = 1 minute of trawling).

```{r get CPUE trout perch}
tps$fish_count_CPUE <- tps$fish_count/as.numeric(tps$duration)
```


```{r map the number of trout perch caught per lake location, echo=FALSE, message=FALSE, warning=FALSE}
# p1 <- ggplot(tps[!is.na(tps$fish_count) & tps$site=="burlington bay",], aes(x = avg.lon.dd, y = avg.lat.dd, size = fish_count, colour=yday)) + geom_point() + labs(x="Longitude", y="Latitude")
# 
# ggplotly(p1)

# create color palette and shapes
colfunc <- colorRampPalette(c("yellow", "red"))
pal <- colfunc(max(tps$yday)-min(tps$yday))

addLegendCustom <- function(map, colors, labels, sizes, opacity = 0.5){
      colorAdditions <- paste0(colors, "; width:", sizes, "px; height:", sizes, "px")
      labelAdditions <- paste0("<div style='display: inline-block;height: ", sizes, "px;margin-top: 4px;line-height: ", sizes, "px;'>", labels, "</div>")

      return(addLegend(map, colors = colorAdditions, labels = labelAdditions, opacity = opacity))
    }

troutperch_map <- leaflet() %>%
  addTiles() %>%  # Add default OpenStreetMap map tiles
  setView(lng = -73.255, lat = 44.465, zoom = 12) %>% 
  addCircleMarkers(
    lng = tps$avg.lon.dd,
    lat=tps$avg.lat.dd,
    radius = ifelse(!is.na(tps$fish_count_CPUE),as.numeric(tps$fish_count_CPUE)/5, 2),
    color = pal[as.numeric(tps$yday)-min(tps$yday)],
    stroke = FALSE, fillOpacity = 0.5
  )  %>%
  addRectangles(
    lng1=-73.290, lat1=44.45,
    lng2=-73.231, lat2=44.48,
    fillColor = "transparent"
  ) %>%
  addLegend("topright", title = "Day of the year",colors = pal[seq(1,(max(tps$yday)-min(tps$yday)),by = 30)],values = seq(1,(max(tps$yday)-min(tps$yday)),by = 30),
            labels=(min(tps$yday):(max(tps$yday)))[seq(1,(max(tps$yday)-min(tps$yday)),by = 30)]) 

troutperch_map

```
<br>`r fig_cap("troutperch number lake", display="full")`


`r fig_cap("troutperch per yday", caption="(a) Trout-perch CPUE across the year, (b) number of sampling events per day of the year and (c) number of sampling events with CPUE reported.", display = FALSE)`

__Question for Ellen__: CPUE are always lower during summer (see `r fig_cap("troutperch per yday", display="cite")`), could it be because there's more work with Lake Trout, so data are only recorded when CPUEs are low? 

```{r trout perch count vs. day, echo=FALSE, message=FALSE, warning=FALSE}
p1 <- ggplot(tps, aes(yday, fish_count_CPUE )) + geom_point() + ggtitle("a. CPUE per day of the year") + xlab("Day of the year") + ylab("CPUE (UE= 1 minute of bottom trawling)")
p2 <- ggplot() + geom_histogram(data=tps, aes(yday,fill="All sampling events")) + stat_bin(bins = 30) + geom_histogram(data=tps[!is.na(tps$fish_count_CPUE),], aes(yday, fill="Sampling events with \nCPUE data reported")) + stat_bin(bins = 30) + ggtitle("b. Sampling events per day of the year") + theme(legend.title = element_blank())  + xlab("Day of the year") + ylab("Number of sampling events")
grid.arrange(p1,p2,nrow=1, widths=c(2.5,4))
```
<br>`r fig_cap("troutperch per yday", display="full")`

## Data from WFB 161 - Fall 2018

```{r read data from WFB 161 fall 2018, message=FALSE, warning=FALSE, include=FALSE}
# Read data
data <- read.delim("Input/WFB161_2018_Lab3_data.txt", header = T)
metadata <- read.delim("Input/WFB161_2018_Lab3_metadata_2.txt", header = T)

length <- read.delim("Input/WFB161_2018_Lab3_length.txt")
length_sp <- length[1,]
length <- length[-1,]
indx <- sapply(length, is.factor)
length[indx] <- lapply(length[indx], function(x) as.numeric(as.character(x)))

str(length)

troutperch <- read.delim("Input/WFB161_2018_Lab3_length_troutperch.txt", header = T)
alewife <- read.delim("Input/WFB161_2018_Lab3_length_alewife.txt", header = T)

```
 
Trawl on September 17th (Monday lab) and 19th (Wednesday lab), 2018, as part of Fisheries Biology and Techniques (UVM/WFB 161). We met at 1pm with the first group, conducted 2 trawls, and then met at 3.30pm with the second group for the 2nd trip (2 more trawls). That makes a total of 8 trawls (4 trawls per afternoon). Metadata collected are presented below: <br>

`r metadata`


`r fig_cap("trout perch trawl", caption="Start and end depth of trawls conducted in 2018 for WFB 161.", display=FALSE)`

Trawls were done deeper and deeper (`r fig_cap("trout perch trawl", display="cite")`).

```{r depth trawls wfb 161, echo=FALSE, message=FALSE, warning=FALSE}
plot(1:8,colMeans(metadata[5:6,-1]), pch=20, ylim=c(min(metadata[5:6,-1]), max(metadata[5:6,-1])), xlab="# trawls", ylab="depth (m)")
for (i in 1:8) {
  lines(c(i,i),c(metadata[5,i+1], metadata[6,i+1]), col="grey")
}
points(1:8,metadata[5,-1], pch=20, col="grey", cex=.8)
points(1:8,metadata[6,-1], pch=15, col="brown1")
points(1:8,colMeans(metadata[5:6,-1]), cex=1.4, pch=20)
legend("bottomrigh", legend = c("Start", "End", "Average depth"), pch=c(20,15,20), col=c("grey", "brown1","black"), bty='n')

```
<br>
`r fig_cap("trout perch trawl", display="full")`


Length were collected for `r nrow(troutperch)` trout-perch (and `r nrow(alewife)` alewifes). Note that we collected more trout-prech for each trawl but stopped measuring after 115-125 individuals. Trawling locations show different size distribution.

```{r histogram trout perch length, fig.cap=c(cap1,cap2,cap3), echo=FALSE, message=FALSE, warning=FALSE}
cap1=fig_cap("size distrib trout perch 1", caption="size distribution of trout perch")
hist(troutperch$Length_trout_perch, breaks = c(seq(0,130,2)), col="grey", xlab="length class (mm)", main="")
# hist(troutperch$Length_trout_perch[troutperch$Trawl==1], breaks = c(seq(0,130,5)), col="grey", ylim = c(0,100))
# par(new=T)
cap2=fig_cap("size distrib trout perch 2", caption="size distribution of trout perch - shallower and deeper sites evidenced")
hist(troutperch$Length_trout_perch[troutperch$Trawl==1|troutperch$Trawl==2|troutperch$Trawl==3], breaks = c(seq(0,130,5)), col=adjustcolor(col = "blue",alpha.f = .3), ylim = c(0,100), main='', xlab='length class (mm)')
# par(new=T)
# hist(troutperch$Length_trout_perch[troutperch$Trawl==4], breaks = c(seq(0,130,5)), col=adjustcolor(col = "blue",alpha.f = .3))
par(new=T)
hist(troutperch$Length_trout_perch[troutperch$Trawl==5|troutperch$Trawl==6|troutperch$Trawl==7|troutperch$Trawl==8], breaks = c(seq(0,130,5)), col=adjustcolor(col = "red",alpha.f = .3), ylim = c(0,100), main='', xlab='')
legend("topleft", legend = c("Trawls #1-3", "Trawls #5-8"), fill =c(adjustcolor(col = "blue",alpha.f = .3),adjustcolor(col = "red",alpha.f = .3)), bty='n')
cap3=fig_cap("size distrib trout perch 3", caption="size distribution of trout perch")
boxplot(troutperch$Length_trout_perch~troutperch$Trawl , xlab="trawls", ylab="length (mm)")

```

Size between trout-perch caught in trawls 1-3 and trawls 5-8 is significantly different (t-test, t = `r t.test(troutperch$Length_trout_perch[troutperch$Trawl==1|troutperch$Trawl==2|troutperch$Trawl==3|troutperch$Trawl==4],troutperch$Length_trout_perch[troutperch$Trawl==5|troutperch$Trawl==6|troutperch$Trawl==7|troutperch$Trawl==8])$statistic`, p-value = `r t.test(troutperch$Length_trout_perch[troutperch$Trawl==1|troutperch$Trawl==2|troutperch$Trawl==3|troutperch$Trawl==4],troutperch$Length_trout_perch[troutperch$Trawl==5|troutperch$Trawl==6|troutperch$Trawl==7|troutperch$Trawl==8])$p.value`).

Below is a more detailed characterisation of each trawl.

```{r various stats of each trawl trout perch WFB161, message=FALSE, warning=FALSE}
library(psych)
describeBy(troutperch$Length_trout_perch, group = troutperch$Trawl)

```

We stopped measuring for each trawl after 115-125 individuals -- below is a code I used to show the students that if we had sample less fish, we would have still find the same mean for each trawl.

```{r resample trout perch data, echo=FALSE, message=FALSE, warning=FALSE}
# resample data
# independent 2-group t-test
# Principle: t.test(y1,y2) # where y1 and y2 are numeric
par(mfrow=c(1,2), mar=c(8.5,4.1,3.8,2.1))
plot(c(10,100), c(0,1), xlab="number of individuals measured", ylab="p-value", pch=NA)
rect(xleft = 0,ybottom = -0.1,xright = 120,ytop = 0.05, col=adjustcolor("grey", alpha.f = .5), border=NA)
mycol <- wes_palette("Darjeeling1", 8, type="continuous")
mtext("a. Mean comparison (independent\n     2-group t-test)", font=2, side = 3, line = .8, at = 5, adj = 0)
for (i in 1:8) {
  for (j in seq(10,100,10)){
    myttest <- NULL
    for (k in 1:100) {
      mysample <- sample(troutperch$Length_trout_perch[troutperch$Trawl==i],size = j, replace = F)
      ttest <- t.test(mysample,troutperch$Length_trout_perch[troutperch$Trawl==i])
      myttest <- c(myttest,ttest$p.value)
    }
    points(j, mean(myttest), pch=20, col=mycol[i])
  }
}

plot(c(10,100), c(0,1), xlab="number of individuals measured", ylab="p-value", pch=NA)
rect(xleft = 0,ybottom = -0.1,xright = 120,ytop = 0.05, col=adjustcolor("grey", alpha.f = .5), border = NA)
mycol <- wes_palette("Darjeeling1", 8, type="continuous")
mtext("b. Variance comparison (independent\n     2-group var-test)", font=2, side = 3, line = .8, at = 5, adj = 0)
for (i in 1:8) {
  for (j in seq(10,100,10)){
    myvartest <- NULL
    for (k in 1:100) {
      mysample <- sample(troutperch$Length_trout_perch[troutperch$Trawl==i],size = j, replace = F)
      vartest <- var.test(mysample,troutperch$Length_trout_perch[troutperch$Trawl==i], alternative = "two.sided")
      myvartest <- c(myvartest,vartest$p.value)
    }
    points(j, mean(myvartest), pch=20, col=mycol[i])
  }
}

par(xpd=T)
legend(x = -5, y=-.39, legend = paste("trawl", 1:3), col=mycol[1:3], pch=20, bty='n')
legend(x = 30, y=-.39, legend = paste("trawl", 4:6), col=mycol[4:6], pch=20, bty='n')
legend(x = 65, y=-.39, legend = paste("trawl", 7:8), col=mycol[7:8], pch=20, bty='n')
par(xpd=F)
par(mfrow=c(1,1), mar=c(5.1,4.1,4.1,2.1))

```
<br>
`r fig_cap("trout perch sample size stats", caption="Testing robustness of our results by changing sample size")`

## Data from Lake Michigan

The assigned ages (by scales), total lengths (mm), and sexes of Troutperch (Percopsis omsicomaycus) captured in southeastern Lake Michigan, from the library _FSAdata_.

```{r data trout perch from lake michigan }
?TroutperchLM1
head(TroutperchLM1)
```


```{r plot data trout perch from lake michigan, echo=FALSE, message=FALSE, warning=FALSE}
# make the plot average into a function so I don't have to repeat the code twice
plot_mean_WFB_troutperch <- function() {
  polygon(x=c(-2,12,12,-2), y=  quantile(troutperch$Length_trout_perch[troutperch$Trawl<4], c(.25, .25, .75, .75)), col=adjustcolor("cadetblue",alpha=.2), border = NA)
  abline(h=mean(troutperch$Length_trout_perch[troutperch$Trawl<4]), lty=2, col="cadetblue")
  polygon(x=c(-2,12,12,-2), y=  quantile(troutperch$Length_trout_perch[troutperch$Trawl>=4], c(.25, .25, .75, .75)), col=adjustcolor("coral2",alpha=.2), border = NA)
  abline(h=mean(troutperch$Length_trout_perch[troutperch$Trawl>=4]), lty=2, col="coral2")
  legend("bottomright", title = "Trout-perch average length \n(and 25-75th percentiles)", legend = c("in trawls 1-3","in trawls 4-8"), lty=2,col=c("cadetblue","coral2"), cex=.8, bty='n')
}

# Actual plot
op <- par(mfrow=c(1,2),pch=19)
plot(tl~age,data=TroutperchLM1,subset=sex=="f",main="female", ylim=c(min(TroutperchLM1$tl), max(TroutperchLM1$tl)))
plot_mean_WFB_troutperch()
plot(tl~age,data=TroutperchLM1,subset=sex=="m",main="male", ylim=c(min(TroutperchLM1$tl), max(TroutperchLM1$tl)))
plot_mean_WFB_troutperch()
par(op)
?FSAdata
```
<br>
`r fig_cap("trout perch data FSA package", caption="Trout-perch total length per age class from the FSA package (Lake Michigan, House and Wells, 1973). Average length of trout-perch collected as part of the WFB 161 lab (fall 2018) is represented.")`

`r fig_cap("trout perch data FSA package", display="cite")` suggests that the trawls conducted during the lab mainly caught 2 years-old fish.


## Get an average biomass

Get average CPUE: `r round(mean(tps$fish_count_CPUE, na.rm=T))`/trout-perch/minute trawled. A trout-perch weight on average 
What is the average volume sampled per minute of trawl? __Ask Steve__.

According to fish base, a and b parameters are respectively: 0.00398 and 3.15


# Smelt
For fish in general, we need to get the a and b parameters of the $ W = a L^{b} $ equation.

__Data:__ 
<br>

```{r read smelt data, message=FALSE, warning=FALSE, include=FALSE}
smelt <- read.csv(file = paste0(getpath4data(),"data_from_Ellen/MasterFileSmeltBio1984-2015-2-24-16.csv"))
smelt <- smelt[smelt$Species == "Rainbow Smelt",]
smelt$Station <- gsub("-"," ",smelt$Station)
smelt$Age <- as.numeric(paste(smelt$Age))
head(smelt)
```

The data were provided by Ellen Marsden. It contains `r nrow(smelt)` observations of smelt. Each row has some metadata associated (date and basin sampled) as well as individuals characteristics (length, weight, year class, condition).

```{r map smelt data origin, message=FALSE, warning=FALSE, include=FALSE}

smelt_coord <- read.csv(file = paste0(getpath4data(), "smelt_coord.csv"))

xIcon <- makeIcon(
  iconUrl = "https://cdn4.iconfinder.com/data/icons/defaulticon/icons/png/256x256/cancel.png",
  iconWidth = 20, iconHeight = 20)
```

## Metadata / general considerations about the sampling

### Sampling stations
Here, you can see rough coordinates of the stations sampled for rainbow smelt throughout the years. For ambiguous locations such as Main Lake, Main Lake North, Main Lake South, etc., we just coordinates roughly in the center of the area. You can click on the icons to see the stations specific coordinates. 

```{r map smelt sampling sites, echo=FALSE, message=FALSE, warning=FALSE}
# Creation of the map with each station. Includes name of station, latitude, and longitude
coord_map <- leaflet() %>%
  addTiles() %>%  # Add default OpenStreetMap map tiles
  addMarkers(icon = xIcon, lng = smelt_coord$Longitude, lat = smelt_coord$Latitude,
             popup = paste("<b>Station:</b>", smelt_coord$Station, "<br>",
                           "<b>Latitude:</b>", smelt_coord$Latitude, "<br>",
                           "<b>Longitude:</b>", smelt_coord$Longitude))

coord_map
```

### Number of fish caught per year for biological variables

Note that there are no data for 1986, 1988, and 1989.

```{r number smelt caught per yr, echo=FALSE, message=FALSE, warning=FALSE, fig.cap=c(cap1,cap2)}
# Data frame which includes the number of fish sampled per year
summ_smelt_catches1 <- as.data.frame(summary(as.factor(smelt$Year)))
summ_smelt_catches1 <- cbind(rownames(summ_smelt_catches1), summ_smelt_catches1)
rownames(summ_smelt_catches1) <- c()
colnames(summ_smelt_catches1) <- c("Year", "num_fish")

# Bar plot which displays the number of fish sampled per year
ggplot(data = summ_smelt_catches1, mapping = aes(x = Year, y = num_fish)) + 
  geom_bar(stat = "summary") + 
  labs(x = "Year", y = "Number of Fish Sampled") + 
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
cap1 <- fig_cap("number smelt sampled per year", caption="Number of rainbow smelt sampled per year.")

# Table which displays the number of fish sampled each year at each station 
station_number_sampled <- as.data.frame(with(smelt, tapply(rep(1,nrow(smelt))
  ,list("Year#"=Year,"station"=Station), sum, na.rm=T)))
station_number_sampled[is.na(station_number_sampled)] <- 0
cap2 <- tab_cap("number smelt sampled per year per station", caption="Number of rainbow smelt sampled per year and per station.")
station_number_sampled <- na_if(station_number_sampled, 0)
kable(station_number_sampled)

```

### Quick info about age structure of the smelt sampled

"The age distribution of rainbow smelt was skewed heavily, such that age-1 to age-4 fish comprised 98% of all fish and the remaining 2% was composed of age 5 and older fish and some YOY which are not fully recruited to the gear." (Euclide, Pientka, Marsden, 2020^[Euclide, P.T., Pientka, B., Ellen Marsden, J., 2020. Genetic versus demographic stock structure of rainbow smelt in a large fragmented lake. Journal of Great Lakes Research. https://doi.org/10.1016/j.jglr.2020.02.009])

Repeating the stats on the whole dataset just to see if I find comparable results.  
No age were available for `r nrow(smelt) - nrow(smelt[smelt$Age<=4,]) + nrow(smelt[smelt$Age>4,])` fish (`r round((nrow(smelt) - nrow(smelt[smelt$Age<=4,]) + nrow(smelt[smelt$Age>4,]))/nrow(smelt)*100, 1)`%). 

`r round(nrow(smelt[smelt$Age<=4&!is.na(smelt$Age),])/nrow(smelt[!is.na(smelt$Age),])*100, 1)`% of fish that were aged were comprised in the 1-4 year interval, `r round(nrow(smelt[smelt$Age>4&!is.na(smelt$Age),])/nrow(smelt[!is.na(smelt$Age),])*100, 1)`% of fish that were age were 5 years or older. 

The distribution is indeed really skewed.


### Evolution of sampled stations

The table of 0's and 1's indicates whether or not a station was sampled for a particular year.

```{r stations sampled per yr, echo=FALSE, message=FALSE, warning=FALSE, fig.cap=c(cap1, cap2)}
# Data frame which includes the years, list of the stations sampled during that year, and number of stations sampled that year
summ_smelt_catches2 <- smelt %>% 
  group_by(Year) %>% 
  summarise(list_stations = list(unique(Station)), num_stations = length(unlist(list_stations)), num_fish = length(Year))

# Bar plot showing the number of stations sampled per year
ggplot(data = summ_smelt_catches2, mapping = aes(x = as.factor(Year), y = num_stations)) +
  geom_bar(stat = "summary") +
  labs(x = "Year", y = "Number of Stations Sampled") + 
  scale_y_continuous(breaks = c(seq(1, 10, 1))) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
cap1 <- fig_cap("number station sampled smelt per year", caption = "Number of stations sampled for rainbow smelt per year.")

# Bar plot showing the number of stations sampled per year
ggplot(data = summ_smelt_catches2, mapping = aes(x = as.factor(Year), y = num_fish/num_stations)) +
  geom_hline(yintercept=200, linetype="dashed", color = "grey") +
  geom_bar(stat = "summary") +
  labs(x = "Year", y = "Average number of individual data per stations per year")   +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank())
cap2 <- fig_cap("number smelt weighted by number station sampled per year", caption = "Average number of fish per station sampled.")

# Table which displays which stations were sampled when
station_which_sampled <- as.data.frame(with(smelt, tapply(rep(1,nrow(smelt))
  ,list("Year#"=Year,"station"=Station), sum, na.rm=T)))
station_which_sampled[is.na(station_which_sampled)] <- 0
station_which_sampled[station_which_sampled > 0] <- 1

# Put in red the sites that were sampled to make it easier to see which sites were sampled when
library(huxtable)
ht <- as_hux(station_which_sampled)
ht <- set_background_color(ht, where(ht == 1), "pink")
ht <- huxtable::add_colnames(ht, colnames = colnames(station_which_sampled))
ht <- huxtable::add_rownames(ht, rownames = rownames(station_which_sampled))
col_width(ht) <- 0.5
wrap(ht) <- TRUE
ht



# Table which displays the total number of fish sampled at each station across all years
station_total_sampled <- station_number_sampled %>% summarise_all(list(sum))
kable(station_total_sampled)
```

Get a summary figure for smelt paper of average number of fish surveyed by station per year.

```{r Get a summary figure for smelt paper of average number of fish surveyed by station per year, echo=FALSE, message=FALSE, warning=FALSE}
 
smelt_summ_bio <- as.data.frame((with(smelt, tapply(rep(1,nrow(smelt)),list( "Station"=Station,"Year"=Year), sum))))
smelt_summ_bio$Basin <- smelt$Basin[!duplicated(smelt$Station)][order(smelt$Station[!duplicated(smelt$Station)])]


smelt_summ_bio <-cbind("Station"=rep(rownames(smelt_summ_bio, ncol(smelt_summ_bio))),melt(smelt_summ_bio, variable.name = "Year", value.name = "Num_fish"))
smelt_summ_bio <- smelt_summ_bio[!is.na(smelt_summ_bio$Num_fish),]

ggplot(smelt_summ_bio, aes(as.numeric(paste(Year)), Num_fish, color=Basin, pch=Basin)) + 
  geom_hline(yintercept=200, linetype="dashed", color = "grey") + 
  geom_point(alpha=.8, cex=2) +
  scale_color_manual(values=c("grey", "tomato", "black")) +
  theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  labs(x="Year", y="Number of fish with biological\ndata collected")
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Number_fish_bio_data.png"), width = 6, height=3)


```



## Length distribution by survey

Can we identify year class?

```{r look at smelt size frequency per stations and per year}
#head(smelt)
pal <- wes_palette("GrandBudapest1", 12, type="continuous")
pal <- c("grey", pal[c(1,5,9,2,6,10,3,8,4,11,7)])
for (i in seq_along(unique(smelt$Station))) {
  #plot
  ggplot(data = smelt[smelt$Station==unique(smelt$Station)[i],], mapping = aes(x = Length, fill=Age)) +
    geom_histogram(binwidth=5) +
    geom_vline(xintercept = mean(smelt$Length, na.rm=T)) +
    geom_vline(xintercept = mean(smelt$Length[smelt$Station==unique(smelt$Station)[i]], na.rm=T), lty=2) +
    labs(x = "Length (mm)", y = "Frequency")  + 
    xlim(min(smelt$Length, na.rm=T), max(smelt$Length,na.rm=T)) + 
    facet_wrap(~Year, scales = "free") +
    scale_fill_manual(values=pal) +
    theme_bw()
  
  #Save plot
  ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Length_frequency_per_site_",unique(smelt$Station)[i],".pdf"))
}

for (i in seq_along(unique(smelt$Basin))) {
  #plot
  ggplot(data = smelt[smelt$Basin==unique(smelt$Basin)[i],], mapping = aes(x = Length, fill=Age)) +
    geom_histogram(binwidth=5) +
    geom_vline(xintercept = mean(smelt$Length, na.rm=T)) +
    geom_vline(xintercept = mean(smelt$Length[smelt$Basin==unique(smelt$Basin)[i]], na.rm=T), lty=2) +
    labs(x = "Length (mm)", y = "Frequency")  + 
    xlim(min(smelt$Length, na.rm=T), max(smelt$Length,na.rm=T)) + 
    facet_wrap(~Year, scales = "free") +
    scale_fill_manual(values=pal) +
    theme_bw()
  
  #Save plot
  ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Length_frequency_per_basin_",unique(smelt$Basin)[i],".pdf"))
}

```

Get for each year, the average length, and for each year class, the number of fish, the frequency of length for each year class

```{r work more on smelt year class, echo=FALSE, message=FALSE, warning=FALSE}
smelt$Year <- as.numeric(paste(smelt$Year))
smelt$Age <- as.numeric(paste(smelt$Age))

# Initiate
Basins <- c("Lake Champlain", "Main Lake", "Malletts Bay", "Northeast Arm")
smelt_length_freq <- list()

# start loop
for (j in seq_along(Basins)) {
  if(Basins[j] == "Lake Champlain") temp1 <- smelt else temp1 <- smelt %>% filter(Basin2 == Basins[j])
  for (i in unique(smelt$Year)) {
      temp2 <- temp1 %>% 
      filter(Year  == i)
    for (k in unique(smelt$Age)) {
     temp3 <- temp2 %>%
    filter(Age == k)
     
    temp4 <-
       data.frame(
        "Basin" = Basins[j],
        "Year"  = i,
        "Age"   = k,
        "number" = nrow(temp3),
        "mean_length" =  mean(temp3$Length, na.rm=T),
        "median_length" =  median(temp3$Length, na.rm=T),
        "sd_length" =  sd(temp3$Length, na.rm=T),
        "mean_weight" =  mean(temp3$Weight, na.rm=T),
        "mean_condition" =  mean(temp3$condition, na.rm=T))
     
     if(nrow(temp4) > 0) {
       if (!Basins[j] %in%  names(smelt_length_freq)) { # If the first row hasn't been created yet, create it
        smelt_length_freq[[Basins[j]]] <- temp4
     } else { # otherwise, just rbind new values
       smelt_length_freq[[Basins[j]]] <- rbind(
         smelt_length_freq[[Basins[j]]], temp4)
     }
     }
    }
  }
}

summary(smelt_length_freq$`Lake Champlain`)
summary(smelt_length_freq$`Main Lake`)

ggplot(smelt_length_freq$`Lake Champlain`, aes(Year, mean_length))  + geom_line(smelt_length_freq$`Lake Champlain`, mapping = aes(Year, mean_length, color=as.factor(Age))) + geom_point() + theme_bw() +
  labs(subtitle = "Mean length per age class per year (rainbow smelt)")

#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Mean_length_per_age_class_smelt.png"), width = 6, height=4.5)



```

```{r Smelt number of year class per year and per basins, echo=FALSE, message=FALSE, warning=FALSE}
# Look at number of year class per year and per basins

Basins <- c("Lake Champlain", "Main Lake", "Malletts Bay", "Northeast Arm")

for(j in 2:length(Basins)) {
  mdf <- smelt_length_freq[[Basins[j]]]

  temp1 <- data.frame("Year" = unique(mdf$Year)[order(unique(mdf$Year))],
                      "Basin" = rep(Basins[j], length(unique(mdf$Year))),
    "Number_year_class" = with(mdf, tapply(ifelse(number>0,1,0),list("Year"=Year), sum, na.rm=T)),
    "Max_year_class" = with(mdf, tapply(Age,list("Year"=Year), max, na.rm=T)),
    "Number_individuals" = with(mdf, tapply(number,list("Year"=Year), sum, na.rm=T)))
  
  if(j == 2) mdf_summ <- temp1 else  mdf_summ <- rbind(mdf_summ, temp1)

}


mdf_summ$Number_stations_sampled <- 
melt(with(smelt_summ_bio, tapply(rep(1, nrow(smelt_summ_bio)),list("Year"=Year, "Basin"= Basin), sum, na.rm=T)))$value

# Plot it
p1 <- ggplot(mdf_summ, aes(Year, Number_year_class, fill=Number_individuals/Number_stations_sampled))  +
  geom_hline(yintercept = seq(0,8,2), lwd=.2, col=adjustcolor("grey", alpha.f = .8)) +
  geom_vline(xintercept = 2003, lty=2) +
  geom_bar(stat = "identity", position="dodge", 
           col="black", lwd=.2) +
  theme_bw() +
  scale_y_continuous(
      name   = "Number of year classes",
      breaks = seq(0, max(mdf_summ$Number_year_class), 1),
      minor_breaks = seq(0, max(mdf_summ$Number_year_class), 1)
      ) +
  scale_x_continuous(
      breaks =  seq(1985,2015,5)
      ) + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) + 
  facet_wrap(~Basin, ncol = 1,
              labeller = label_glue('({.l}) {Basin}')) +
  scale_fill_gradient2(low = muted("red"),
  mid = grey(.8),
  high = muted("blue"),
  midpoint = 200, name="Number of\nindividuals\ncollected\nper stations") +
  labs(subtitle = "B")
  #guides(fill = guide_legend(title.position = "top"), 
  #                            title="Basin")) +
  # scale_fill_manual(values = c("tomato", grey(.7), grey(.9), grey(.5))) 
  
   

# ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Number_year_class2.png"),p1, width = 6, height=5)

p2 <- ggplot(smelt, aes(x=Age)) + 
  geom_histogram(binwidth=1, col="grey", fill="lightgray" ) +
  facet_wrap(~Basin2, ncol=1,
              labeller = label_glue('({.l}) {Basin2}')) +
  stat_bin(binwidth=1, geom="text", colour="black", size=2.5,
           aes(label=..count.., group=Basin2, y=..count..),
           position=position_stack(vjust=1)) +
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  scale_x_continuous(
  labels = scales::number_format(accuracy = 1)
  ) 
p2

# ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Age_structure_smelt.png"),  p2, width = 7, height=3)
temp1 <- smelt %>% group_by(Basin2,Age) %>% tally %>% mutate(f = n/sum(n))
p2 <- ggplot(temp1, aes(Age,f)) + 
  geom_bar(stat = "identity",col="grey", fill="lightgray") +
  geom_text(mapping = aes(Age,f, label=n),
            nudge_y = 0.03, size = 2.8) +
  facet_wrap(~Basin2, ncol=1,
              labeller = label_glue('({.l}) {Basin2}')) +
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  scale_x_continuous(
  labels = scales::number_format(accuracy = 1)
  ) +
  scale_y_continuous(
    labels = scales::percent
    ) +
  labs(y = "Percentage", subtitle = "A")
p2

p3 <- grid.arrange(p2, p1, widths=c(1,2.5))

# ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Description_Smelt_bio_dataset.png"), p3, width = 8, height=5)

p3

```
<br> `r fig_cap("summary age structure smelt bio dataset", caption="(A) Proportion of individuals per year class and per basins. Numbers refer to the absolute number in each year class. (B) Number of year classes represented per year. Color coding indicates the number of individuals collected, on average, per station (that were then grouped by basins). Protocol aims for 200 individuals. Red indicates that fewer individuals were captured than recommended by the protocol, blue indicates that data were collected on more individuals than recommended by the protocol. Vertical line indicates alewife invasion, in 2003.")`

## Length/weigth/condition evolution

### Weigth/length relationship
```{r smelt weight length, echo=FALSE, message=FALSE, warning=FALSE}
# Test of a fit without assumptions
p1 <- ggplot(aes(x=Length, y=Weight), data=smelt )+
  geom_point() + stat_smooth()

# per station
p2 <- ggplot(aes(y=Weight, x=Length), data=smelt )+
  geom_point()+ geom_smooth() +
  facet_wrap(~Station)

grid.arrange(p1,p2,nrow=1)
```
<br>
`r fig_cap("WL relationship smelt", caption="Smelt Weigth/length relationship by monitoring station.")`

### Condition of rainbow smelt over time by lake station 

It appears that the condition of rainbow smelt has stayed realtively constant over time in Lake Champlain. The trendlines show an average condition of roughly 0.5 to 0.7 over time.

```{r condition by station, echo=FALSE, message=FALSE, warning=FALSE, fig.cap=c(cap1, cap2)}
# Grid of plots which display the condition of rainbow smelt over time at each station
smelt <- smelt %>% mutate(Basin2 = case_when(
                      Basin == "Main Lake" ~ "Main Lake",
                      Basin == "Northeast" ~ "Northeast Arm",
                      Basin == "Malletts" ~ "Malletts Bay"))
smelt$Basin2 <- as.factor(smelt$Basin2)

smelt <- smelt[smelt$Station %in% c("Northeast Arm", "Valcour Island", "Malletts Bay", "Juniper Island", "Barber Point") ,]

ggplot(smelt[smelt$condition<2&smelt$condition>0&!is.na(smelt$condition),], aes(x=Year, y=condition) )+
  geom_point(alpha=.2)+ 
  geom_smooth(color="tomato") +
  geom_vline(xintercept = 2003, lty=2) +
  facet_wrap(~Basin2, drop=TRUE, ncol=1,
             labeller = label_glue('({.l}) {Basin2}')) +  
  theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  labs(y="Condition")
cap1 <- "Condition of individuals for stations in the (a) Main Lake, (b) Mallets Bay, and (c) the Northeast Arm. Each point is an individual. Line shows the best fit to the data (model gam, y ~ s(x, bs = 'cs')). Vertical line indicates alewife invasion, in 2003."
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_condition_per_basin.png"), width = 3, height=7)

smelt_condition <- as.data.frame(with(smelt[smelt$condition<2&smelt$condition>0,], tapply(condition,list("Year"=Year, "Basin"=Basin2), mean, na.rm=T)))
  
smelt_condition_w <- data.frame("Year" = as.numeric(paste(rownames(smelt_condition))))
smelt_condition_w$MainLake_5yr <- NA
smelt_condition_w$MallettsBay_5yr <- NA
smelt_condition_w$NortheastArm_5yr <- NA

for (i in 6:(nrow(smelt_condition)-2)) {
  smelt_condition_w$MainLake_5yr[i] <- sum(smelt_condition$`Main Lake`[(i-2):(i+2)])/5
  smelt_condition_w$MallettsBay_5yr[i] <- sum(smelt_condition$`Malletts Bay`[(i-2):(i+2)])/5
  smelt_condition_w$NortheastArm_5yr[i] <- sum(smelt_condition$`Northeast Arm`[(i-2):(i+2)])/5
}

colnames(smelt_condition_w) <- c("Year", colnames(smelt_condition))

smelt_condition_w <- smelt_condition_w[!is.na(smelt_condition_w[,2]),]

smelt_condition_w <- melt(smelt_condition_w, id.vars = "Year", variable.name = "Basin", value.name = "condition")

smelt_condition <- (cbind("Year" = rep(as.numeric(paste(rownames(smelt_condition))), ncol(smelt_condition)), melt(smelt_condition, variable.name = "Basin", value.name = "condition")))

ggplot(smelt_condition_w, aes(Year, condition)) + 
  geom_hline(yintercept = mean(smelt_condition_w$condition), alpha=.3) +
  #geom_smooth(color="tomato") +
  geom_line(color="black") +
  geom_vline(xintercept = 2003, lty=2) +
  geom_point(smelt_condition, mapping=aes(Year, condition), alpha=.4) +
  #geom_point(smelt_condition[smelt_condition$Year==1987,], mapping=aes(Year, CPUE), pch=4, col = "tomato") +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  facet_wrap(~Basin, ncol = 1,
             labeller = label_glue('({.l}) {Basin}'))
cap2 <- "Mean condition (dots) and 5-years running average condition (line) of individuals for stations in the (a) Main Lake, (b) Mallets Bay, and (c) the Northeast Arm. Vertical line indicates alewife invasion, in 2003. Horizontal line shows the average condition across basins."
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_condition_per_basin_running_average.png"), width = 3, height=7)

```
<br>
`r fig_cap("smelt condition over year", caption="Evolution of smelt condition in Lake Champlain, by monitoring station.")`


### Rainbow smelt per year class in Lake Champlain

```{r catch per year, warning = FALSE, message = FALSE}
# Data frame which includes the number of fish obtained per year class
summ_smelt_ageclass <- as.data.frame(summary(as.factor(smelt$Age)))
summ_smelt_ageclass <- cbind(rownames(summ_smelt_ageclass), summ_smelt_ageclass)
rownames(summ_smelt_ageclass) <- c()
colnames(summ_smelt_ageclass) <- c("year_class", "num_fish")
summ_smelt_ageclass

# Bar plot which displays the number of fish obtained per year class
ggplot(data = summ_smelt_ageclass[3:12,], aes(x = year_class, y = num_fish)) + 
  geom_bar(stat = "summary") + 
  labs(x = "Year Class", y = "Number of Fish")
```
<br>
`r fig_cap("number of smelt per year class", caption="Number of smelt per year class in our sample.")`

## Exploring growth parameters for rainbow smelt

### Weight-length relationship

Using Rosalie's code from LT analysis and Derek Ogle's tutorial.

```{r smelt weigth length relationship basic plot, message = FALSE, warning = FALSE}
# Two plots here--the first is the weight-length relationship of rainbow smelt without a log-transformation. The second plot is a log-transformed plot of this relationship with a line of best fit
par(mfrow=c(1,2))
plot(smelt$Weight ~ smelt$Length ,xlab="Total Length (mm)", ylab = "Weight (g)", main = "", pch=20)

smelt$logW <- log10(smelt$Weight)
smelt$logL <- log10(smelt$Length)

lm1 <- lm(logW~logL,data = smelt)
fitPlot(lm1,xlab="Log Total Length (mm)", ylab = "Log Weight (g)", main="")

```

The relationship is not linear without log-transforming the data. Here, we have the coefficients of the log-transformed data. 

```{r summary model smelt W ~ L, message = FALSE, warning = FALSE}
summary(lm1)
```

### Test whether rainbow smelt exhibit isometric or allometric growth

A test of whether the fish in a population exhibit isometric growth or not can be obtained by noting that b is the estimated slope from fitting the transformed length-weight model. The slope is generically labeled with β such that the test for allometry can be translated into the following statistical hypotheses:
* H0: β=3 ⇒ H0 :"Isometricgrowth"
* HA: β≠3 ⇒ HA :"Allometricgrowth"
(All taken from Derek Ogle tutorial. Go back there for more details).

A test, and confidence interval for b, of whether rainbow smelt from Lake Champlain exhibited allometric growth or not is constructed with:

```{r smelt allo or isometric growth, message = FALSE, warning = FALSE}
hoCoef(lm1,2,3)
confint(lm1)
```

These results show that LT exhibit allometric growth (p = 1.3e-93) with an exponent parameter (b) between 2.87 and 2.89, with 95% confidence.

### Prediction on original scale
Again, from Derek Ogle tutorial: "Predictions of the mean value of the response variable given a value of the explanatory variable can be made with predict(). In the length-weight regression, the value predicted is the mean log of weight. Most often, of course, the researcher is interested in predicting the mean weight on the original scale. An intuitive and common notion is that the log result can simply be back-transformed to the original scale by exponentiation. However, back-transforming the mean value on the log scale in this manner underestimates the mean value on the original scale. This observation stems from the fact that the back-transformed mean value from the log scale is equal to the geometric mean of the values on the original scale. The geometric mean is always less than the arithmetic mean and, thus, the back-transformed mean always underestimates the arithmetic mean from the original scale."

We want to extract the sigma, and then get the correction factor:

```{r get growth parameters smelt original scale, message = FALSE, warning = FALSE}
syx <- summary(lm1)$sigma
(cf <- exp((syx^2)/2))
```

(1) Predict log weight of a rainbow smelt of size 130 mm
(2) Biased prediction on original scale
(3) Corrected prediction on original scale

```{r check error and bias, message = FALSE, warning = FALSE}
(pred.log <- predict(lm1,data.frame(logL=log(130)),interval="c")) ##(1)
(bias.pred.orig <- exp(pred.log)) ##(2)
(pred.orig <- cf*bias.pred.orig) ##(3)
```

### Comparison of weight-length relationship {.tabset}

#### Across years

Include year as a factor.  

```{r does weigth length relationship for smelt change across yrs, message = FALSE, warning = FALSE}
smelt$fyear <- factor(smelt$Year)
lm2 <- lm(logW~logL*fyear, data = smelt)
```

The analysis of variable table is constructed by submitting the saved lm object to anova() as such: 

```{r anova lm2, message = FALSE, warning = FALSE}
anova(lm2)
```

These results indicate that the interaction terms are significant (p = 2.2e-16). There is evidence to conclude that there is a difference in slopes in the length-weight relationship between years. The p-value for the indicator variable suggests that there is a difference in intercepts between the three years (p = 2.2e-16).

Plots and confidence intervals should be constructed for the model with the interaction term, as it was significant. The confidence intervals, constructed with:

```{r confint of model, message = FALSE, warning = FALSE}
confint(lm2)
par(mfrow=c(1,1))
fitPlot(lm2,xlab="Log Length (mm)",ylab="Log Weight (g)", legend = "topleft",main = "", col = adjustcolor(c("red","blue","grey"), alpha.f = .5))
```


#### Across Basins

Include basins as a factor.  

```{r does weigth length relationship for smelt change across stations, message = FALSE, warning = FALSE}
smelt$fBasin <- factor(smelt$Basin)
lm3 <- lm(logW~logL*fBasin, data = smelt)
``` 

The analysis of variable table is constructed by submitting the saved lm object to anova() as such:

```{r anova lm3, message = FALSE, warning = FALSE}
anova(lm3)
```

These results indicate that the interaction terms is significant (p = 2.2e-16). There is evidence to conclude that there is difference in slopes in the length-weight relationship between basins The p-value for the indicator variable suggests that there is a difference in intercepts between the three basins (p = 2.2e-16). 

Plots and confidence intervals should be constructed for the model with the interaction term, as it was significant. The confidence intervals, constructed with:
```{r confint model 3, message = FALSE, warning = FALSE}
confint(lm3)
par(mfrow=c(1,1))
fitPlot(lm3, xlab="Log Length (mm)",ylab="Log Weight (g)", legend = "topleft",main = "", col = adjustcolor(c("red","blue","grey"), alpha.f = .5))
```

## Conclusion: a and b parameters
In <a href=http://www.dnr.state.mi.us/publications/pdfs/ifr/manual/smii%20chapter17.pdf> Schneider et al 2010 report for Michigan Department of Natural Resources</a>, growth parameter are reported for rainbow smelt:    
  *  a = -5.12117 <br/>
  *  b =  2.96408 <br/>
We found (see results for lm1):  <br/>
  *  a = `r as.numeric(lm1$coefficients[1])`<br/>
  *  b =  `r as.numeric(lm1$coefficients[2])`<br/>
There are some discrepancies between the two, but they're fairly close.  <br/>

To convert them to the initial equation W = aL<sup>b</sup>:  
```{r conclusion a and b parameters for rainbow smelt, message = FALSE, warning = FALSE}
(a = 10^(lm1$coefficients[1]))
(b = lm1$coefficients[2])

a=10^(-5.12117)
b=2.96408
L=c(60,100)
a*L^b
```

Therefore, the intial equation is W = `r 10^(lm1$coefficients[1])` x L<sup>`r as.numeric(lm1$coefficients[2])`</sup>.

***

## Weight-length relationships for specific groups of rainbow smelt {.tabset}

### Age-0 (for Lake Champlain fish.xlsx)

The calculations for a and b for age-0 and age-1 rainbow smelt are for the purpose of transcribing rainbow smelt density to biomass values in Lake Champlain fish.xlsx in our Dropbox!

n = 89

Because most rainbow smelt of age-0 or with a year class of "YOY" don't have a weight, we will calculate an average weight for them based on the average length of rainbow smelt of age-0 (n = 89). We will use the weight-length equation calculated earlier for all rainbow smelt in Lake Champlain. Again, the equation from earlier was: <br/><br/> 
W = 0.000009405 x L<sup>2.88230</sup> 
<br/><br/>
Therefore, if we use the average length of 41 mm for the 89 fish with a classification of "YOY", our equation is: <br/><br/> 
W = 0.000009405 x 41<sup>2.88230</sup> 

```{r W and L for smelt YOY}
mean(smelt$Length[smelt$YearClass == "YOY"], na.rm = TRUE)
length(smelt$Length[smelt$YearClass == "YOY"])
(weight_age0 <- 0.000009405 * (41^2.8830))
```

The average weight of age-0 smelt in Lake Champlain is around 0.42 grams. 

### Age-1 (for Lake Champlain fish.xlsx)

n = 9,754

Using data from 9,754 rainbow smelt of age-1, we can find an average weight.

```{r W and L for smelt Age-1}
mean(smelt$Weight[smelt$Age == 1], na.rm = TRUE)
mean(smelt$Length[smelt$Age == 1], na.rm = TRUE)
length(smelt$Weight[smelt$Age == 1])
```

The average weight of age-0 rainbow smelt in Lake Champlain is around 8.59 grams. Their average length is 114 mm.

### <4 years old

n = 10,987

```{r W and L for smelt Age2-4}
lm_4years <- lm(logW~logL,data = smelt[as.numeric(smelt$Age) <= 4,])
fitPlot(lm_4years, xlab = "Log Total Length (mm)", ylab = "Log Weight (g)", main = "")
summary(lm_4years)
```

a = -5.19480 <br/>
b =  2.96750 <br/>

W = 0.0000064 x L<sup>2.96750</sup>

### <5 years old

n = 19,412

```{r W and L for smelt Age4-5}
lm_5years <- lm(logW~logL,data = smelt[as.numeric(smelt$Age) <= 5,])
fitPlot(lm_5years, xlab = "Log Total Length (mm)", ylab = "Log Weight (g)", main = "")
summary(lm_5years)
```

a = -5.12426 <br/>
b =  2.93121 <br/>

W = 0.0000075 x L<sup>2.93121</sup>

### <6 years old

n = 23,296

```{r W and L for smelt Age6-7}
lm_6years <- lm(logW~logL,data = smelt[as.numeric(smelt$Age) <= 6,])
fitPlot(lm_6years, xlab = "Log Total Length (mm)", ylab = "Log Weight (g)", main = "")
summary(lm_6years)
```

a = -5.14460 <br/>
b =  2.90205 <br/>

W = 0.0000086 x L<sup>2.90205</sup>

### At or below 200 mm

n = 24,816

```{r W and L for smelt below 200mm}
lm_below200mm <- lm(logW~logL,data = smelt[as.numeric(smelt$Length) <= 200,])
fitPlot(lm_below200mm, xlab = "Log Total Length (mm)", ylab = "Log Weight (g)", main = "")
summary(lm_below200mm)
```

a = -5.02208 <br/>
b =  2.88082 <br/>

W = 0.0000095 x L<sup>2.880817</sup>

### Above 200 mm

n = 180

```{r W and L for smelt above 200 mm}
lm_above200mm <- lm(logW~logL,data = smelt[as.numeric(smelt$Length) > 200,])
fitPlot(lm_above200mm, xlab = "Log Total Length (mm)", ylab = "Log Weight (g)", main = "")
summary(lm_above200mm)
```

a = -5.3648 <br/>
b =  3.0303 <br/>

W = 0.0000043 x L<sup>3.0303</sup>

## Summary of a and b

```{r summary a and b for smelt}
# Table which includes the age/size group and their respective a and b parameters
age_group <- c("All", "<4 years", "<5 years", "<6 years", "<=200 mm", ">200 mm")
a <- c(-5.05001, -5.19480, -5.12426, -5.14460, -5.02208, -5.3648)
b <- c(2.88230, 2.96750, 2.93121, 2.90205, 2.88082, 3.0303)

a_and_b_summary <- data.frame(age_group, a, b)
kable(a_and_b_summary)
```


## Comparison of a and b parameters with other systems

Other a and b parameters were retrieved from <a href="https://www.fishbase.se/popdyn/LWRelationshipList.php?ID=253&GenusName=Osmerus&SpeciesName=mordax&fc=80">Fish Base</a>.

The units of length and weight in FishBase are <a href="https://www.fishbase.in/manual/fishbasethe_length_weight_table.htm">centimeter and gram</a>, respectively. Thus when length-weight relationships are not in cm-g, the intercept 'a' is transformed as follows: 
a'(cm, g) = a (mm, g)x10^b
a'(cm, g) = a (cm, kg)x1000
a'(cm, g) = a (mm, mg)x10^b/1000
a'(cm, g) = a (mm, kg) x 10^b x 1000

```{r read smelt a b for other systems and compare with lake Champlain }
# From Lake Champlain ####

# Total length ####
# Re-do it all to be sure
smelt$logW <- log10(smelt$Weight)
smelt$logL <- log10(smelt$Length)

lm1   <- lm(logW~logL,data = smelt)
lm_MB <- lm(logW~logL,data = smelt[smelt$Basin=="Malletts",])
lm_ML <- lm(logW~logL,data = smelt[smelt$Basin=="Main Lake",])
lm_NE <- lm(logW~logL,data = smelt[smelt$Basin=="Northeast",])

ab <- data.frame("Country" = rep("USA",4),
                 "Lake" = c(rep("Lake Champlain", 4)),
           "Basin" = c("Lake Champlain", "Malletts Bay", "Main Lake", "Northeast"),
           "log10a" = c(lm1$coefficients[1],lm_MB$coefficients[1],lm_ML$coefficients[1],lm_NE$coefficients[1]),
           "b" = c(lm1$coefficients[2],lm_MB$coefficients[2],lm_ML$coefficients[2],lm_NE$coefficients[2]),
           "sd_a_min" = c(confint(lm1)[1,1],confint(lm_MB)[1,1],confint(lm_ML)[1,1],confint(lm_NE)[1,1]),
           "sd_a_max" = c(confint(lm1)[1,2],confint(lm_MB)[1,2],confint(lm_ML)[1,2],confint(lm_NE)[1,2]),
           "sd_b" = c(hoCoef(lm1,1,3)[4],hoCoef(lm_MB,2,3)[4],hoCoef(lm_ML,2,3)[4],hoCoef(lm_NE,2,3)[4]))

# Conversion of a' to get to the same value than on fish base
# a'(cm, g) = a (mm, g)x10^b
ab$a <- 10^(ab$log10a)*10^ab$b
ab$sd_a_min <- 10^(ab$sd_a_min)*10^ab$b
ab$sd_a_max <- 10^(ab$sd_a_max)*10^ab$b


# Standard length ####
# Re-do it all to be sure
smelt$logW <- log10(smelt$Weight)
smelt$logL <- log10(smelt$Length*0.789)

lm1   <- lm(logW~logL,data = smelt)
lm_MB <- lm(logW~logL,data = smelt[smelt$Basin=="Malletts",])
lm_ML <- lm(logW~logL,data = smelt[smelt$Basin=="Main Lake",])
lm_NE <- lm(logW~logL,data = smelt[smelt$Basin=="Northeast",])

ab <- data.frame("Country" = rep("USA",5),
                 "Lake" = c(rep("Lake Champlain", 4), "Lake Superior"),
           "Basin" = c("Lake Champlain", "Malletts Bay", "Main Lake", "Northeast", "Chequamegon Bay"),
           "log10a" = c(lm1$coefficients[1],lm_MB$coefficients[1],lm_ML$coefficients[1],lm_NE$coefficients[1], -5.12117),
           "b" = c(lm1$coefficients[2],lm_MB$coefficients[2],lm_ML$coefficients[2],lm_NE$coefficients[2], 2.96408),
           "sd_a_min" = c(confint(lm1)[1,1],confint(lm_MB)[1,1],confint(lm_ML)[1,1],confint(lm_NE)[1,1],NA),
           "sd_a_max" = c(confint(lm1)[1,2],confint(lm_MB)[1,2],confint(lm_ML)[1,2],confint(lm_NE)[1,2],NA),
           "sd_b" = c(hoCoef(lm1,1,3)[4],hoCoef(lm_MB,2,3)[4],hoCoef(lm_ML,2,3)[4],hoCoef(lm_NE,2,3)[4],NA))

# Conversion of a' to get to the same value than on fish base
# a'(cm, g) = a (mm, g)x10^b
ab$a <- 10^(ab$log10a)*10^ab$b
ab$sd_a_min <- 10^(ab$sd_a_min)*10^ab$b
ab$sd_a_max <- 10^(ab$sd_a_max)*10^ab$b



# From Fish Base ####
abfb <- read.delim(paste0(getpath4data(), "GIS/Smelt_a_b_param_fish_base.txt"), sep = "\t")
abfb$sex <- as.factor(abfb$sex)

# Keep only the lakes
abfb <- abfb[abfb$IsLake,]


mycol <- wes_palette("Darjeeling1", 4, type="continuous")


p <- ggplot(abfb, aes(a,b, color= Lake, fill=length_type)) + 
  xlim(0.002,0.018) +
  ylim(2.7,3.15) +
  geom_vline(xintercept = mean(abfb$a[abfb$length_type=="TL"]), lty=2) +
  geom_vline(xintercept = mean(abfb$a[abfb$length_type=="SL"]), lty=2) +
  geom_hline(yintercept = 3, lty=2) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = "bottom",
        plot.margin = unit(c(1.5,1.5,0.2,0.2), "cm")) +  # Make room for the grob
  geom_errorbar(abfb[!is.na(abfb$sd_a_min),], mapping = aes(ymin=b-sd_b, ymax=b+sd_b), width=.0002) +
  geom_errorbarh(abfb[!is.na(abfb$sd_a_min),], mapping = aes(xmax = sd_a_max, xmin = sd_a_min),height=0.01) +
  scale_color_manual(values=mycol) +
  scale_fill_manual(values=c(adjustcolor("black", alpha.f = .1), 
                             "black")) +
  geom_point(abfb[abfb$length_type=="SL",], mapping = aes(x=a,y=b,shape=factor(abfb[abfb$length_type=="SL","sex"])), cex=2.9, color="black")  +
  geom_point(aes(shape=factor(abfb$sex)), cex=2)  +
   guides(color = guide_legend(ncol=2,byrow=TRUE, title.position = "top"),
          fill  = guide_legend(ncol=1,byrow=TRUE, title.position = "top", title = "Length type", override.aes = list(color=c('black','white'),fill=c("grey","grey"), shape=c(22,22), cex=3)),
          shape = guide_legend(ncol=1,byrow=TRUE, title = "Sex", title.position = "top", override.aes = list(color="grey"))) +
  geom_text(abfb[abfb$Lake=="Lake Champlain",], mapping = aes(a,b, label = code), col="black", check_overlap = T, nudge_x = c(-0.0006,-0.0012,-0.00005,-0.0007), 
            nudge_y = c(0.01,0.0,-0.04,0.01), cex=2)
#  annotate("text", x=0.016, y=3.2, label= "plumper fish, \na > median") +
#  annotate("text", x=0.003, y=3.2, label= "plumper fish, \na < median")

#  geom_label(ab[ab$Lake=="Lake Champlain",], mapping = aes(a,b, label = Basin))

myannotation <- data.frame("x" = c(mean(abfb$a[abfb$length_type=="TL"], na.rm=T)-0.0015, mean(abfb$a[abfb$length_type=="SL"],na.rm=T)-0.0015,0.02,0.019,0.02), 
                  "y" = c(3.20,  3.20, 3.16, 2.989, 2.92),
                  "label" = c("average TL", "average SL", "plumper fish\nwhen growing", "allometric\n  growth", "leaner fish\nwhen growing"),
                  "rot" = c(0,0,270,340,270))

for (i in 1:nrow(myannotation))  {
p <- p + annotation_custom(
      grob = textGrob(label = myannotation$label[i], hjust = 0, gp = gpar(cex = .7), rot =  myannotation$rot[i]),
      ymin = myannotation$y[i],#-.5,      # Vertical position of the textGrob
      ymax = myannotation$y[i],#+.5,
      xmin = myannotation$x[i],#-0.01,         # Note: The grobs are positioned outside the plot area
      xmax = myannotation$x[i])#+0.01)
 }    

# Code to override clipping
gt <- ggplot_gtable(ggplot_build(p))
gt$layout$clip[gt$layout$name == "panel"] <- "off"
gt <- gt
grid.draw(gt)

ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_a_b_parameters.png"), width = 5, height=5,   plot = gt)

# Compare a and b parameters on Total length across years and basins ####
# Re-do it all to be sure
smelt$logW <- log10(smelt$Weight)
smelt$logL <- log10(smelt$Length)

smelt$Year <- as.numeric(paste(smelt$Year))
ab_per_yr <- NULL

for (i in unique(smelt$Year)) {
  lm1   <- lm(logW~logL,data = smelt[smelt$Year==i,])
  
  if(nrow(smelt[smelt$Basin=="Malletts"&smelt$Year==i,])>0) {
    lm_MB <- lm(logW~logL,data = smelt[smelt$Basin=="Malletts"&smelt$Year==i,])
    out_temporary_MB <- c(lm_MB$coefficients[1], lm_MB$coefficients[2], confint(lm_MB)[1,1], confint(lm_MB)[1,2], hoCoef(lm_MB,2,3)[4])
    } else {
    out_temporary_MB <- rep(NA,5)
  }
  
  if(nrow(smelt[smelt$Basin=="Main Lake"&smelt$Year==i,])>0) {
    lm_ML <- lm(logW~logL,data = smelt[smelt$Basin=="Main Lake"&smelt$Year==i,])
    out_temporary_ML <- c(lm_ML$coefficients[1], lm_ML$coefficients[2], confint(lm_ML)[1,1], confint(lm_ML)[1,2], hoCoef(lm_ML,2,3)[4])
    } else {
    out_temporary_ML <- rep(NA,5)
  }
  
  if(nrow(smelt[smelt$Basin=="Northeast"&smelt$Year==i,])>0) {
    lm_NE <- lm(logW~logL,data = smelt[smelt$Basin=="Northeast"&smelt$Year==i,])
    out_temporary_NE <- c(lm_NE$coefficients[1], lm_NE$coefficients[2], confint(lm_NE)[1,1], confint(lm_NE)[1,2], hoCoef(lm_NE,2,3)[4])
    } else {
    out_temporary_NE <- rep(NA,5)
  }
  
  ab <- data.frame("Country" = rep("USA",4),
                   "Lake" = c(rep("Lake Champlain", 4)),
             "Basin" = c("Lake Champlain", "Malletts Bay", "Main Lake", "Northeast"),
             "Year" = rep(i,4),
             "n_individual" = c(nrow(smelt[smelt$Year==i,]),
                                nrow(smelt[smelt$Basin=="Malletts"&smelt$Year==i,]),
                                nrow(smelt[smelt$Basin=="Main Lake"&smelt$Year==i,]),
                                nrow(smelt[smelt$Basin=="Northeast"&smelt$Year==i,])),
             "mean_length" = c(mean(smelt[smelt$Year==i,"Length"], na.rm=T),
                                mean(smelt[smelt$Basin=="Malletts"&smelt$Year==i,"Length"], na.rm=T),
                                mean(smelt[smelt$Basin=="Main Lake"&smelt$Year==i,"Length"], na.rm=T),
                                mean(smelt[smelt$Basin=="Northeast"&smelt$Year==i,"Length"], na.rm=T)),
             "log10a" = c(lm1$coefficients[1], out_temporary_MB[1], out_temporary_ML[1], out_temporary_NE[1]),
             "b" = c(lm1$coefficients[2],out_temporary_MB[2], out_temporary_ML[2], out_temporary_NE[2]),
             "sd_a_min" = c(confint(lm1)[1,1],out_temporary_MB[3], out_temporary_ML[3], out_temporary_NE[3]),
             "sd_a_max" = c(confint(lm1)[1,2],out_temporary_MB[4], out_temporary_ML[4], out_temporary_NE[4]),
             "sd_b" = c(hoCoef(lm1,1,3)[4], out_temporary_MB[5], out_temporary_ML[5], out_temporary_NE[5]))
  
  # Conversion of a' to get to the same value than on fish base
  # a'(cm, g) = a (mm, g)x10^b
  ab$a <- 10^(ab$log10a)*10^ab$b
  ab$sd_a_min <- 10^(ab$sd_a_min)*10^ab$b
  ab$sd_a_max <- 10^(ab$sd_a_max)*10^ab$b
  
  # Save results
  if(is.null(ab_per_yr)) ab_per_yr <- ab else ab_per_yr <- rbind(ab_per_yr,ab)
}

head(ab_per_yr)

p1 <- ggplot(ab_per_yr, aes(Year, mean_length, color=Basin)) + theme_bw() + 
  geom_smooth(se = F) + geom_point() +
  geom_vline(xintercept = 2003, lty=2)
p2 <- ggplot(ab_per_yr, aes(Year, n_individual, color=Basin)) + theme_bw() + 
  geom_smooth(se = F) + geom_point() +
  geom_vline(xintercept = 2003, lty=2)
p3 <- ggplot(ab_per_yr, aes(Year, a, color=Basin)) + theme_bw() + 
  geom_smooth(se = F) + 
  geom_point() +
  geom_vline(xintercept = 2003, lty=2)
p4 <- ggplot(ab_per_yr, aes(Year, b, color=Basin)) + theme_bw() + 
  geom_smooth(se = F) + 
  geom_point() +
  geom_vline(xintercept = 2003, lty=2)

(p1/p2/p3/p4)

```




## Get instantaneous mortality rate.

From Derek Ogle's tutorial.  
The regression method for estimating Z will be demonstrated in this section using the catches-at-age for Brook Trout (Salvelinus fontinalis) captured by the U.S. Fish and Wildlife Service from 1996-1998 in Tobin Harbor of Isle Royale (data shown in (Table 2); Quinlan (1999.)).  
From the initial catch curve plot it was determined that the descending limb consisted of ages 2 through 6. Thus, a new data frame which contains only the information for these ages on the descending limb should be extracted with Subset(), which requires the original data frame as the first argument and a conditioning statement as the second argument. 

```{r instantaneous mortality rate from Ogle tutorial}
( bkt <- data.frame(age=0:6,ct=c(39,93,112,45,58,12,8)) )
bkt$logct <- log(bkt$ct)
str(bkt)
plot(logct~age,data=bkt,ylab="log(Catch)",pch=19)
( bkt.d <- Subset(bkt,age >= 2) )

cc <- lm(logct~age,data=bkt.d)
coef(cc)
confint(cc)
( A <- 1-exp(coef(cc)[2]) )
( A.ci <- 1-exp(confint(cc)[2,]) )

thcc <- catchCurve(ct~age,data=bkt,ages2use=2:6)
summary(thcc)
confint(thcc)
plot(thcc)

```

Thus, the estimated annual mortality rate is 48.3% with an approximate 95% confidence interval between 20.1% and 66.6%.

```{r smelt instantaneous mortality rate}
Basins <- c("Lake Champlain", "Main Lake", "Malletts Bay", "Northeast Arm")
smelt_length_freq_df <- rbind(smelt_length_freq$`Main Lake`, smelt_length_freq$`Malletts Bay`, smelt_length_freq$`Northeast Arm`)

im <- smelt_length_freq_df %>% group_by(Age) %>% summarise("ct" = sum(number))
im <- im[!is.na(im$Age),]
im$logct <- log(im$ct)
str(im)
plot(logct~Age,data=im,ylab="log(Catch)",pch=19)
( im.d <- Subset(im,Age >= 1 & Age < 9) )

cc <- lm(logct~Age,data=im.d)
coef(cc)
confint(cc)
( A <- 1-exp(coef(cc)[2]) )
( A.ci <- 1-exp(confint(cc)[2,]) )

thcc <- catchCurve(ct~Age,data=im,ages2use=1:8)
summary(thcc)
confint(thcc)
par(mar=c(5.1,4.1,2.1,4.1))
mvec <- mlab <- c(0:10,seq(10, 100,10),seq(200,1000,100))
mlab[!mvec %in% c(1,10,100,1000)] <- NA
plot(thcc, col.pt = 1, col.mdl = 1)
axis(4, log(mvec), labels = NA, tck=-.015)
axis(4, log(mlab), mlab)
mtext(text = "Catch", side = 4, line = 2.1)

# Do the same, but per basin
par(mfrow=c(3,1))
for (i in unique(smelt_length_freq_df$Basin)) {
  im <- smelt_length_freq_df[smelt_length_freq_df$Basin==i,] %>% group_by(Age) %>% summarise("ct" = sum(number))
  im <- im[!is.na(im$Age),]
  im <- im[im$ct>0,]
  im$logct <- log(im$ct)
  #str(im)
  if(i==unique(smelt_length_freq_df$Basin)[1]) im_out <- cbind("Basin"=rep(i,nrow(im)),im) else im_out <- rbind(im_out, cbind("Basin"=rep(i,nrow(im)),im))
    
  #plot(logct~Age,data=im,ylab="log(Catch)",pch=19)
  ( im.d <- Subset(im,Age >= 1) )
  
  cc <- lm(logct~Age,data=im.d)
  coef(cc)
  confint(cc)
  ( A <- 1-exp(coef(cc)[2]) )
  ( A.ci <- 1-exp(confint(cc)[2,]) )
  
  thcc <- catchCurve(ct~Age,data=im,ages2use=1:8)
  summary(thcc)
  confint(thcc)
  if(i==unique(smelt_length_freq_df$Basin)[1]) thcc_out <- NULL
  thcc_out <- c(thcc_out,i,summary(thcc)[1,1],confint(thcc)[1,],summary(thcc)[2,1],confint(thcc)[2,])
  par(mar=c(5.1,4.1,2.1,4.1))
  mvec <- mlab <- c(0:10,seq(10, 100,10),seq(200,1000,100), seq(1000,10000,1000))
  mlab[!mvec %in% c(1,10,100,1000)] <- NA
  #par(new=T)
  plot(thcc, col.pt = 1, col.mdl = 1, xlim=c(0,9))
  axis(4, log(mvec), labels = NA, tck=-.015)
  axis(4, log(mlab), mlab)
  mtext(text = "Catch", side = 4, line = 2.1)
  mtext(i,3)
}
thcc_out <- as.data.frame(matrix(thcc_out,nrow=3,byrow = T))
colnames(thcc_out) <- c("Basin","Z","Z_LCI","Z_UCI","A","A_LCI","A_UCI")
thcc_out$label <- paste0("Z=", round(as.numeric(paste(thcc_out$Z)),3),
                         "\nA=", round(as.numeric(paste(thcc_out$A)),1), "%")

im_out$used4lm <- ifelse(im_out$Age<9&im_out$Age>=1,16,1)
im_out$used4lm <- ifelse(im_out$Basin=="Mallets Bay",im_out$used4lm-1,im_out$used4lm)
im_out$used4lm <- ifelse(im_out$Basin=="Northeast Arm",im_out$used4lm+1,im_out$used4lm)


mvec <- mlab <- c(0:10,seq(10, 100,10),seq(200,1000,100), seq(1000,10000,1000))
mlab[!mvec %in% c(1,10,100,1000)] <- NA
  
ggplot(im_out, aes(Age,logct)) + 
  theme_bw() + 
  stat_smooth(data = im_out[im_out$Age<9&im_out$Age>=1,], 
              aes(Age,logct),
              method="lm", col=adjustcolor("black", alpha.f = .4)) +
  geom_point(pch=ifelse(im_out$Age<9&im_out$Age>=1,16,1)) +
  theme(panel.grid.major = element_blank())+
  facet_wrap(~Basin, ncol = 1,
             labeller = label_glue('({.l}) {Basin}')) + 
  scale_y_continuous(
    name   = "Catch",
    breaks = log(mlab),
    labels = mlab,
    minor_breaks = log(mvec), 
    sec.axis = sec_axis(~ ., name = "log(Catch)")
    ) +
  scale_x_continuous(breaks = seq(0,8,2),
                    minor_breaks = NULL) +
  geom_text(data = thcc_out, aes(x = 6.5,  y = 8, label = label),
            hjust = 0, size=3)

#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_inst_mortality.png"), width=3, height=5.5)
```

Instantaneous mortality per cohort
```{r smelt Instantaneous mortality per cohort}
# Will need to divide each number in catches per effort
smelt_effort <- dcast(smelt_trawl, Year~Basin)
# But this effort is just the number of trawl: in fact, needs to get the CPUE.
# So use the percentage of Age 1, 2, 3, etc and project it on the actual CPUE
# Then, conduct the analysis.
# First, get CPUE per station
smelt_trawl$StationYear <- paste0(smelt_trawl$Station, "_", smelt_trawl$Year)

# Then, get age distribution per station
# start loop
Station <- c("Barber Point", "Juniper Island", "Malletts Bay", "Northeast Arm", "Valcour Island")
smelt_station_length_freq <- list()
for (j in seq_along(Station)) {
  temp1 <- smelt %>% filter(Station == Station[j])
  for (i in unique(smelt$Year)) {
      temp2 <- temp1 %>% 
      filter(Year  == i)
    for (k in unique(smelt$Age)) {
     temp3 <- temp2 %>%
    filter(Age == k)
     
    temp4 <-
       data.frame(
        "Station" = Station[j],
        "Basin" = ifelse(Station[j] %in% c("Barber Point", "Juniper Island", "Valcour Island"), "Main Lake", Station[j]),
        "Year"  = i,
        "Age"   = k,
        "number" = nrow(temp3),
        "mean_length" =  mean(temp3$Length, na.rm=T),
        "median_length" =  median(temp3$Length, na.rm=T),
        "sd_length" =  sd(temp3$Length, na.rm=T),
        "mean_weight" =  mean(temp3$Weight, na.rm=T),
        "mean_condition" =  mean(temp3$condition, na.rm=T))
     
     if(nrow(temp4) > 0) {
       if (!Station[j] %in%  names(smelt_station_length_freq)) { # If the first row hasn't been created yet, create it
        smelt_station_length_freq[[Station[j]]] <- temp4
     } else { # otherwise, just rbind new values
       smelt_station_length_freq[[Station[j]]] <- rbind(
         smelt_station_length_freq[[Station[j]]], temp4)
     }
     }
    }
  }
}

for (i in  names(smelt_station_length_freq)) {
  if(i == names(smelt_station_length_freq)[1]) smelt_station_length_freq_df <- smelt_station_length_freq[[i]] else  smelt_station_length_freq_df <- rbind(smelt_station_length_freq_df, smelt_station_length_freq[[i]])
}
head(smelt_station_length_freq_df)
smelt_station_length_freq_df$StationYear <- paste0(smelt_station_length_freq_df$Station, "_", smelt_station_length_freq_df$Year)

# Merge Dataset with CPUE and dataset with age distrib
# First, get a dataset of year vs age class
head(smelt_age_prop <- dcast(smelt_station_length_freq_df[!is.na(smelt_station_length_freq_df$Age),], StationYear ~ Age, value.var = "number"))
# Transform in percentage
head(smelt_age_prop <- cbind(StationYear = smelt_age_prop$StationYear, smelt_age_prop[,-1]/rowSums(smelt_age_prop[,-1])))
# Merge
head(smelt_age_CPUE <- merge(smelt_trawl, smelt_age_prop, by=c("StationYear")))
# Extract just Station
smelt_age_CPUE$Station <- substr(smelt_age_CPUE$StationYear, 1, nchar(smelt_age_CPUE$StationYear)-5)
# Extract just Year
smelt_age_CPUE$Year <- as.numeric(paste(substr(smelt_age_CPUE$StationYear, nchar(smelt_age_CPUE$StationYear)-3, nchar(smelt_age_CPUE$StationYear))))

# Check whether it is right #
# Many values are repeated (see head() below)
# It probably is because we got 4 trawls for CPUE (or maybe 6 sometimes?)
# From each trawl, 50 individuals were collected, and pulled together.
# I cannot re-assign individuals to their trawl, so I have to make the assumption that the same age structure was collected in each trawl.
# Second reason for discrepancies: bio data were only collected from 1990, so I cannot calculate it for the year prior to that
smelt_age_CPUE[1:10,]
nrow(smelt_trawl)
nrow(smelt_trawl[smelt_trawl$Year>=1990,])
nrow(smelt_age_prop)
# 140 = number of station_year with age structure info
# 4   = we assume 4 trawls per station
140*4
# Getting close to the number of trawls. But some station have more than 4 trawls:
summary(factor(smelt_age_CPUE$StationYear))[summary(factor(smelt_age_CPUE$StationYear))>4]
# Some station don't have age structure info
smelt_age_CPUE$StationYear[is.na(smelt_age_CPUE$`2`)]
smelt_age_CPUE$CPUE[is.na(smelt_age_CPUE$`2`)]

# Convert year proportion to abundance, by multiplying by CPUE.
# The condition if is just in case I rerun the script not from the top. If I run the following code twice, I would get hte wrong CPUE
if(sum(smelt_age_CPUE[1, !colnames(smelt_age_CPUE) %in% colnames(smelt_trawl)])==1) {
  smelt_age_CPUE[, !colnames(smelt_age_CPUE) %in% colnames(smelt_trawl)] <- smelt_age_CPUE[, !colnames(smelt_age_CPUE) %in% colnames(smelt_trawl)] * smelt_age_CPUE$CPUE
}
head(smelt_age_CPUE)
# Almost there.
# Now we have some Number of fish caught and age distribution.

# Will need to divide each number in catches per effort
smelt_effort <- dcast(smelt_age_CPUE, Year~Basin)


# Track for each cohort the number of catches per year
for (i in unique(smelt_age_CPUE$Station)) {
  smelt_temporary <- smelt_age_CPUE[smelt_age_CPUE$Station==i,]
  ste <- smelt_temporary # short name to make it easier
  ste <- ste[ste$Year>=1987,]
  
  # Do CPUE mean / sd per Year
  # Since I use mean, no need to divide per effort
  ste_mean <- aggregate(ste[,!colnames(ste) %in% colnames(smelt_trawl)], list("Year" = ste$Year), mean, na.rm=T)
  ste_sd <- aggregate(ste[,!colnames(ste) %in% colnames(smelt_trawl)], list("Year" = ste$Year), sd, na.rm=T)
  
  
  ste_mean <- melt(ste_mean, id.vars = c("Year"), variable.name = "Age", value.name = "number")
  ste_sd <- melt(ste_sd, id.vars = c("Year"), variable.name = "Age", value.name = "number")
  
  ste_mean$Year <- as.numeric(paste(ste_mean$Year))
  ste_mean$Age <- as.numeric(paste(ste_mean$Age))
  ste_mean$Year_cohort <- ste_mean$Year-ste_mean$Age
  
  ste_sd$Year <- as.numeric(paste(ste_sd$Year))
  ste_sd$Age <- as.numeric(paste(ste_sd$Age))
  ste_sd$Year_cohort <- ste_sd$Year-ste_sd$Age

  # For mean
  for (j in unique(ste_mean$Year_cohort)) {
    smelt_temporary <- ste_mean[ste_mean$Year_cohort==j, c("Age", "number")]
    if(i == unique(smelt_age_CPUE$Station)[1] &
       j == unique(ste_mean$Year_cohort)[1]) {
     ste_out <- cbind("Station"=rep(i, nrow(smelt_temporary)), "Cohort"=rep(j, nrow(smelt_temporary)), smelt_temporary)
    } else {
     ste_out <- rbind(ste_out, cbind("Station"=rep(i, nrow(smelt_temporary)), "Cohort"=rep(j, nrow(smelt_temporary)), smelt_temporary))
    }
  }
  
    # For sd
  for (j in unique(ste_sd$Year_cohort)) {
    smelt_temporary <- ste_sd[ste_sd$Year_cohort==j, c("Age", "number")]
    if(i == unique(smelt_age_CPUE$Station)[1] &
       j == unique(ste_sd$Year_cohort)[1]) {
     ste_out_sd <- cbind("Station"=rep(i, nrow(smelt_temporary)), "Cohort"=rep(j, nrow(smelt_temporary)), smelt_temporary)
    } else {
     ste_out_sd <- rbind(ste_out_sd, cbind("Station"=rep(i, nrow(smelt_temporary)), "Cohort"=rep(j, nrow(smelt_temporary)), smelt_temporary))
    }
  }
}

# For mean
ste_out <- ste_out[ste_out$number>0,]
ste_out <- ste_out[!is.na(ste_out$Cohort),]
ste_out <- ste_out[order(ste_out$Station, ste_out$Cohort, ste_out$Age),]
ste_out$Year <- ste_out$Cohort + ste_out$Age
ste_out <- dcast(data = ste_out,formula = Station+Cohort ~ Age,fun.aggregate = sum,value.var = "number")
tail(ste_out)

# For sd
ste_out_sd <- ste_out_sd[ste_out_sd$number>0,]
ste_out_sd <- ste_out_sd[!is.na(ste_out_sd$Cohort),]
ste_out_sd <- ste_out_sd[order(ste_out_sd$Station, ste_out_sd$Cohort, ste_out_sd$Age),]
ste_out_sd$Year <- ste_out_sd$Cohort + ste_out_sd$Age
ste_out_sd <- dcast(data = ste_out_sd,formula = Station+Cohort ~ Age,fun.aggregate = sum,value.var = "number")
tail(ste_out_sd)

# plot year class strength
# Basically just plot catches at age 1 per year
mvec <- mlab <- c(0:10,seq(10, 100,10),seq(200,1000,100), seq(1000,10000,1000))
mlab[!mvec %in% c(1,10,100,1000)] <- NA
  
ggplot(ste_out, aes(Cohort, ifelse(ste_out$`2`==0,NA,log(ste_out$`2`)))) + 
  geom_smooth(color="tomato") +
  geom_line(color="black") +
  geom_line(ste_out, mapping=aes(Cohort, ifelse(ste_out$`1`==0,NA,log(ste_out$`1`))), col="tomato", alpha=.4) +
  geom_point(ste_out, mapping=aes(Cohort, ifelse(ste_out$`1`==0,NA,log(ste_out$`1`))), alpha=.4, col="tomato") +
  geom_vline(xintercept = 2003, lty=2) +
  geom_vline(xintercept = 2008, lty=1) +
  geom_point(ste_out, mapping=aes(Cohort, ifelse(ste_out$`2`==0,NA,log(ste_out$`2`))), alpha=.4) +
  #geom_point(smelt_condition[smelt_condition$Year==1987,], mapping=aes(Year, CPUE), pch=4, col = "tomato") +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  facet_wrap(~Station, ncol = 1,
             labeller = label_glue('({.l}) {Station}')) +
  labs(x = "Cohort", y = "Number of individuals collected") + 
  scale_y_continuous(
    name   = "CPUE",
    breaks = log(mlab),
    labels = mlab,
    minor_breaks = log(mvec), 
    sec.axis = sec_axis(~ ., name = "log(CPUE)")
    ) 
cap1 <- "Number of individual collected per cohort (cohort strength). Age 2 were used, so each data reported was in fact collected 2 years later."
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_cohort_strength_1_2.png"), width = 4, height=6)

# Steps to take:
# 1) Cross information in dataset smelt_trawl and smelt.
# Done above
# 2) Compute inst mortality per cohort, before and after. Do an average of the instantaneous mortality


ste_out_pre <- ste_out[ste_out$Cohort<2001,]
ste_out_post <- ste_out[ste_out$Cohort>=2006,]

# Instantaneous mortality 
ste <- ste_out_pre
if(!R_U_KNITTING) pdf(paste0(getwd(),"/Output/Figures/9-Smelt/Inst_mortality_before_after_alewife_3-6.pdf"),width = 10, height = 7)
par(mfrow=c(2,3))
for (i in 2:3) {
  
  for (j in 1:3) {
    
    if(i==1|i==2) ste <- ste_out_pre else ste <- ste_out_post
    mytitle <- paste0(min(ste$Cohort),"-",max(ste$Cohort), " regression ", j, "-6"," years")
    im <-data.frame("Age"=as.numeric(colnames(ste)[-c(1:3)]),"ct"=colSums(ste[,-c(1:3)]))
    im <- im[!is.na(im$Age),]
    im <- im[im$ct>0,]
    im$logct <- log(im$ct)
    #str(im)
    if(i==1) im_out <- cbind("data"=rep(i,nrow(im)),im) else im_out <- rbind(im_out, cbind("data"=rep(i,nrow(im)),im))
      
    #plot(logct~Age,data=im,ylab="log(Catch)",pch=19)
    ( im.d <- Subset(im,Age >= 1) )
    
    cc <- lm(logct~Age,data=im.d)
    coef(cc)
    confint(cc)
    ( A <- 1-exp(coef(cc)[2]) )
    ( A.ci <- 1-exp(confint(cc)[2,]) )
    
    if(i==1) thcc <- catchCurve(ct~Age,data=im,ages2use=2:8) else thcc <- catchCurve(ct~Age,data=im,ages2use=j:6)
    summary(thcc)
    confint(thcc)
    if(!is.vector(thcc_out)) thcc_out <- NULL
    thcc_out <- c(thcc_out,i,j,summary(thcc)[1,1],confint(thcc)[1,],summary(thcc)[2,1],confint(thcc)[2,])
    par(mar=c(5.1,4.1,2.1,4.1))
    mvec <- mlab <- c(0:10,seq(10, 100,10),seq(200,1000,100), seq(1000,10000,1000))
    mlab[!mvec %in% c(1,10,100,1000)] <- NA
    #par(new=T)
    plot(thcc, col.pt = 1, col.mdl = 1, xlim=c(0,9))
    axis(4, log(mvec), labels = NA, tck=-.015)
    axis(4, log(mlab), mlab)
    mtext(text = "Catch", side = 4, line = 2.1)
    mtext(mytitle,3)
  }
  
  
}
if(!R_U_KNITTING) dev.off()
thcc_out <- as.data.frame(matrix(thcc_out,ncol=8,byrow = T))
colnames(thcc_out) <- c("Data", "MinAge","Z","Z_LCI","Z_UCI","A","A_LCI","A_UCI")
thcc_out$label <- paste0("Z=", round(as.numeric(paste(thcc_out$Z)),3),
                         "\nA=", round(as.numeric(paste(thcc_out$A)),1), "%")
im_out$used4lm <- ifelse(im_out$Age<5&im_out$Age>=1,16,1)

  


# Instantaneous mortality per station and per cohort ####
ste_out_pre <- ste_out[ste_out$Cohort>=1989 & ste_out$Cohort<2001,]
ste_out_post <- ste_out[ste_out$Cohort>=2006&ste_out$Cohort<2012,]

# Do the same but this time per station, and per cohort
im_out <- NULL
for (i in 1) { # pre and post alewife
  ste_all <- ste_out
  for (j in 1:3) { # min age in regression
    for (k in unique(ste_all$Station)) { # do it for each station
      ste <- ste_all[ste_all$Station==k,]
      for (h in unique(ste$Cohort)) { # do it for each Cohort
       im <- data.frame("Age" = c(0:9), "ct" = t(ste[ste$Cohort==h,c((ncol(ste)-9):ncol(ste))]))
       colnames(im) <- c("Age", "ct")
       im <- im[im$ct>0,]
       im$logct <- log(im$ct)
       if(is.null(im_out)) im_out <- cbind("Station"=rep(k, nrow(im)),
                                           "Cohort"=rep(h, nrow(im)),
                                           "pre_post_alewife"=
                                             rep(ifelse(i==1,"pre","post"),nrow(im)),
                                           "MinAge"=rep(j, nrow(im)),
                                           im, "included" = ifelse(im$Age>=j & im$ct>0, 16, 1)) else im_out <- rbind(im_out, cbind("Station"=rep(k, nrow(im)),
                                           "Cohort"=rep(h, nrow(im)),
                                           "pre_post_alewife"=
                                             rep(ifelse(i==1,"pre","post"),nrow(im)),
                                           "MinAge"=rep(j, nrow(im)),
                                           im, "included" = ifelse(im$Age>=j & im$ct>0, 16, 1)))
       
       im.d <- Subset(im, Age>=j)
       if(nrow(im.d)>2) {
         cc <- lm(logct~Age,data=im.d)
         ( A <- 1-exp(coef(cc)[2]) )
         ( A.ci <- 1-exp(confint(cc)[2,]) )
       }
       
       
       # Save output
       if(!is.vector(thcc_out)) thcc_out <- NULL
       if(nrow(im.d)>2) {
         thcc_out <- c(thcc_out,
                     k, # Station
                     h, # Cohort
                     ifelse(i==1, "pre-alewife", "post-alewife"), # prepost alewife
                     j, # Min Age
                     nrow(im.d), # Number of data to fit the lm
                     -coef(cc)[2], # Z
                     confint(cc)[2,], # Z conf interval
                     A, # Age
                     A.ci) # Age conf interval
       } else {
         thcc_out <- c(thcc_out,
                     k, # Station
                     h, # Cohort
                     ifelse(i==1, "pre-alewife", "post-alewife"), # prepost alewife
                     j, # Min Age
                     nrow(im.d), # Number of data to fit the lm
                     NA, # Z
                     NA,NA, # Z conf interval
                     NA, # Age
                     NA,NA) # Age conf interval
       }

      }
    }
  }
}

# Coefficient out
thcc_out <- as.data.frame(matrix(thcc_out,ncol=11,byrow = T))
colnames(thcc_out) <- c("Station", "Cohort", "pre_post_alewife", "MinAge", "NumberYearFit", "Z", "Z_LCI","Z_UCI","A","A_LCI","A_UCI")
thcc_out$label <- paste0("Z=", round(as.numeric(paste(thcc_out$Z)),3),
                         "\nA=", round(as.numeric(paste(thcc_out$A)),1), "%")
# Transform data column to numeric
cols.num <- c("Cohort","MinAge", "NumberYearFit", "Z", "Z_LCI","Z_UCI","A","A_LCI","A_UCI")
thcc_out[cols.num] <- sapply(thcc_out[cols.num],paste)
thcc_out[cols.num] <- sapply(thcc_out[cols.num],as.numeric)
sapply(thcc_out, class)
head(thcc_out)
thcc_out$Station <- factor(thcc_out$Station, levels = c("Valcour Island","Juniper Island","Barber Point", "Malletts Bay", "Northeast Arm"))

# Data used to fit the model_out
head(im_out)



# plot
ggplot(thcc_out, aes(Cohort,A,color=factor(MinAge))) +
  geom_hline(yintercept = 0, col="grey") +
  geom_point(alpha=.2) +
  geom_point(alpha=(thcc_out$NumberYearFit-min(thcc_out$NumberYearFit))/(max(thcc_out$NumberYearFit)-min(thcc_out$NumberYearFit))) + 
  #geom_errorbar(aes(ymin=A_LCI, ymax=A_UCI), width=.5) + 
  facet_wrap(~Station, ncol=1) +
  theme_bw() +
  theme(legend.position = "right") +
  guides(color = guide_legend(title="Minimum age \nused for fit",
                              title.position="top", title.hjust = 0.5, ncol=1)) +
  ylim(-.2,1) 
# ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Cohort_A.png"), width = 4, height=7)

head(thcc_out)
# Get moving average instantaneous mortality age 2
# First, replace any positive mortality (missing data??) with NA
thcc_out$A_QAQC <- thcc_out$A
thcc_out$A_QAQC[thcc_out$A_QAQC<0] <- NA

# Weighted average for Station
im_w <- NULL
for (j in Station) {
  for (i in 3:(nrow(thcc_out[thcc_out$MinAge==2&thcc_out$Station==j,])-2)) {
     n_avail <- length(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Station==j][(i-2):(i+2)][!is.na(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Station==j][(i-2):(i+2)])])
     n_avail_3 <- length(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Station==j][(i-1):(i+1)][!is.na(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Station==j][(i-1):(i+1)])])
     im_w_temp_5 <- sum(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Station==j][(i-2):(i+2)], na.rm=T) / n_avail
     im_w_temp_3 <- sum(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Station==j][(i-1):(i+1)], na.rm=T) / n_avail_3
    im_w <- c(im_w, j, thcc_out$Cohort[thcc_out$MinAge==2&thcc_out$Station==j][i],
      ifelse(n_avail>4, im_w_temp_5, NA), ifelse(n_avail_3>2, im_w_temp_3, NA), im_w_temp_3)
    rm(im_w_temp,n_avail, n_avail_3)
  }
}
im_w <- as.data.frame(matrix(im_w, ncol=5, byrow=T))
colnames(im_w) <- c("Station", "Year", "im_5yr_QAQC", "im_3yr_QAQC", "im_3yr")
im_w$Year <- as.numeric(paste(im_w$Year))
im_w$im_3yr <- as.numeric(paste(im_w$im_3yr))
im_w$im_3yr_QAQC <- as.numeric(paste(im_w$im_3yr_QAQC))
im_w$im_5yr_QAQC <- as.numeric(paste(im_w$im_5yr_QAQC))

# Add basin
thcc_out <- thcc_out %>% mutate(Basin = case_when(
  Station == "Malletts Bay"   ~ "Malletts Bay",
  Station == "Northeast Arm"  ~ "Northeast Arm",
  Station %in% c("Valcour Island","Juniper Island","Barber Point") ~ "Main Lake"
))

# Weighted average for Basin
Basin <- factor(unique(thcc_out$Basin), levels = c("Main Lake", "Malletts Bay", "Northeast Arm"))

im_w_ba <- NULL
for (j in Basin) {
  for (i in 3:(nrow(thcc_out[thcc_out$MinAge==2&thcc_out$Basin==j,])-2)) {
    n_avail <- length(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Basin==j][(i-2):(i+2)][!is.na(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Basin==j][(i-2):(i+2)])])
    n_avail_3 <- length(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Basin==j][(i-1):(i+1)][!is.na(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Basin==j][(i-1):(i+1)])])
    im_w_ba_temp_5 <- sum(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Basin==j][(i-2):(i+2)], na.rm=T) / n_avail
    im_w_ba_temp_3 <- sum(thcc_out$A_QAQC[thcc_out$MinAge==2&thcc_out$Basin==j][(i-1):(i+1)], na.rm=T) / n_avail_3
    im_w_ba <- c(im_w_ba, j, thcc_out$Cohort[thcc_out$MinAge==2&thcc_out$Basin==j][i],
              ifelse(n_avail>4, im_w_ba_temp_5, NA), ifelse(n_avail_3>2, im_w_ba_temp_3, NA), im_w_ba_temp_3)
    rm(im_w_ba_temp,n_avail, n_avail_3)
  }
}
im_w_ba <- as.data.frame(matrix(im_w_ba, ncol=5, byrow=T))
colnames(im_w_ba) <- c("Basin", "Year", "im_5yr_QAQC", "im_3yr_QAQC", "im_3yr")
im_w_ba$Year <- as.numeric(paste(im_w_ba$Year))
im_w_ba$im_3yr <- as.numeric(paste(im_w_ba$im_3yr))
im_w_ba$im_3yr_QAQC <- as.numeric(paste(im_w_ba$im_3yr_QAQC))
im_w_ba$im_5yr_QAQC <- as.numeric(paste(im_w_ba$im_5yr_QAQC))
 

im_w_ba <- im_w_ba %>% 
  group_by(Basin, Year) %>% 
       summarise(
         im_3yr = mean(im_3yr, na.rm=T),
         im_3yr_QAQC = mean(im_3yr_QAQC, na.rm=T),
         im_5yr_QAQC = mean(im_5yr_QAQC, na.rm=T)
         )

# plot instantaneous mortality for age 2, Station then Basin ####
p_im <- 
  ggplot(thcc_out[thcc_out$MinAge==2,], aes(Cohort,A)) +
    geom_vline(xintercept = 2003-0.3, lty=2) +
    geom_vline(xintercept = 2008-0.3, lty=1) +
    # geom_vline(xintercept = 1995.5, col="cornflowerblue", alpha=.4) + 
  geom_hline(yintercept = 0, col="grey") +
  geom_point(alpha=.2) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  guides(color = guide_legend(title="Minimum age \nused for fit",
                              title.position="top", title.hjust = 0.5, ncol=1)) +
  ylim(0,1) 

# for station
p_im +
  geom_line(im_w, mapping = aes(Year, im_3yr), lty=3, alpha=.7) +
  geom_line(im_w, mapping = aes(Year, im_3yr_QAQC), lty=2, alpha=.7) +
  geom_line(im_w, mapping = aes(Year, im_5yr_QAQC)) +
  facet_wrap(~Station, ncol = 1,
             labeller = label_glue('({.l}) {Station}')) 

# for basin
p_im +
  geom_line(im_w_ba, mapping = aes(Year, im_3yr), lty=3, alpha=.7) +
  geom_line(im_w_ba, mapping = aes(Year, im_3yr_QAQC), lty=2, alpha=.7) +
  geom_line(im_w_ba, mapping = aes(Year, im_5yr_QAQC)) +
  facet_wrap(~Basin, ncol = 1,
             labeller = label_glue('({.l}) {Basin}')) 

# ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Cohort_A_Age2.png"), width = 3, height=7)

head(im_out)
# Plot data that were used to calculate the 
ggplot(im_out, aes(Age, logct, col=Station)) + geom_point() +
  facet_wrap(~Cohort)

```


## Get smelt biomass evolution

First, select fish sampled in the main lake. Juniper Island is a location with consistent sampling. The site is 70-90 m deep. In deeper sites, trawl was lowered to approximately 35 m depth. The net was towed at the maximum depth for 10 minutes, allowing it to stabilize. The net was then raised about 3 m and towed for an additional 5 minutes. This step is repeated until the net was 10 m below the surface, and then it is hauled back to the boat. Thus, in deep-water sites such as Juniper Island, each trawl consisted of nine steps and lasted for 55 minutes. Four trawls per night were conducted at each sites. <br>
CPUE is expressed in terms of catch per 55-minutes of trawling (catch X 55 min/actual trawling time). A sample of 50 fish was randomly selected for each haul and frozen for later otolith extraction. In the laboratory, smelt were thawed, measured, weighed, and otoliths were extracted. 

```{r smelt subset main lake}
smelt_sub <- smelt[smelt$Station=="Juniper Island",]
smelt_sub_summ<-as.data.frame(with(smelt_sub, tapply(rep(1,nrow(smelt_sub)),list("Year#"=Year), sum)))
colnames(smelt_sub_summ) = "CPUE"
smelt_sub_summ$Year <- as.numeric(paste(rownames(smelt_sub_summ)))

ggplot(smelt_sub_summ, aes(Year, CPUE)) + geom_point() + geom_line()
```


## Calculating CPUEs following meeting with Bernie

Patrick Blachard and I met with Bernie Pientka (VTDFW, Essex Junction, VT) on February 21, 2020.

Up until now, I was using the MasterFileBio....xls, that only has the fish that were sampled for aging (and weight and length).

There is also a MasterFileTrawl...xls, that has catches.

```{r explore the dataset MasterFileTrawl, echo=FALSE, message=FALSE, warning=FALSE}

use_Basin = T

smelt_trawl <- read.delim(paste0(getpath4data(), "data_from_Bernie/MasterFileTrawlCPUE1987-2015.txt"))

# Keep only the 5 main sites
smelt_trawl <- smelt_trawl[smelt_trawl$Station %in% c("Northeast Arm", "Valcour Island", "Malletts Bay", "Juniper Island", "Barber Point"),]


smelt_trawl2 <-  dcast(smelt_trawl, Year ~ Station, mean, value.var = "CPUE")
smelt_trawl2 <- melt(smelt_trawl2, id.vars = "Year", variable.name = "Station")
smelt_trawl2$Station2 <- as.numeric(factor(smelt_trawl2$Station, levels = rev(c("Valcour Island","Juniper Island","Barber Point", "Malletts Bay", "Northeast Arm"))))
smelt_trawl2 <- smelt_trawl2 %>% mutate(Basin = case_when(
  Station == "Malletts Bay"   ~ "Malletts Bay",
  Station == "Northeast Arm"  ~ "Northeast Arm",
  Station %in% c("Valcour Island","Juniper Island","Barber Point") ~ "Main Lake"
))


smelt_trawl2_sd <-  dcast(smelt_trawl, Year ~ Station, sd, value.var = "CPUE")
smelt_trawl2_sd <- melt(smelt_trawl2_sd, id.vars = "Year", variable.name = "Station")
smelt_trawl2_sd$Station2 <- as.numeric(factor(smelt_trawl2_sd$Station, levels = rev(c("Valcour Island","Juniper Island","Barber Point", "Malletts Bay", "Northeast Arm"))))
smelt_trawl2_sd$min <- smelt_trawl2$value - smelt_trawl2_sd$value
smelt_trawl2_sd$min <- (smelt_trawl2_sd$min-min(smelt_trawl2_sd$min, na.rm = T))/(max(smelt_trawl2_sd$min, na.rm = T)-min(smelt_trawl2_sd$min, na.rm = T))
smelt_trawl2_sd$max <- smelt_trawl2$value + smelt_trawl2_sd$value
smelt_trawl2_sd$max <- (smelt_trawl2_sd$max-min(smelt_trawl2_sd$max, na.rm = T))/(max(smelt_trawl2_sd$max, na.rm = T)-min(smelt_trawl2_sd$max, na.rm = T))
smelt_trawl2_sd$ci <- (smelt_trawl2_sd$value-min(smelt_trawl2_sd$value, na.rm = T))/(max(smelt_trawl2_sd$value, na.rm = T)-min(smelt_trawl2_sd$value, na.rm = T))
  
ggplot(smelt_trawl2, aes(Year,factor(Station2))) +
  geom_point(smelt_trawl2, mapping=aes(size=value), alpha=.5) + 
  geom_errorbar(smelt_trawl2_sd, mapping=aes(x=Year, ymin=Station2-ci, ymax=Station2+ci), width=.5, col=adjustcolor("black", alpha.f = .4)) +
  labs(y="Station") +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  geom_vline(xintercept = 2003, lty=2)

smelt_trawl2 <- smelt_trawl2 %>% mutate(bracket = case_when(
                                  value <= 50   ~ "[0,50]",#grey(0),
                     value > 50 & value <= 100  ~ "]50,100]",#grey(0.1),
                    value > 100 & value <= 1000 ~ "]100,1000]",#grey(0.3),
                   value > 1000 & value <= 2000 ~ "]1000,2000]",#grey(0.5),
                   value > 2000 & value <= 4000 ~ "]2000,4000]",#grey(0.7),
                                   value > 4000 ~ "]4000,inf.]"#grey(0.9)
                ))

ggplot(smelt_trawl2, aes(Year,factor(Station),color=factor(bracket, levels=c(NA, "[0,50]", "]50,100]", "]100,1000]", "]1000,2000]", "]2000,4000]", "]4000,inf.]"))), show.legend = F) +
  geom_point(aes(size=value), alpha=.9) + 
  labs(y="Station") +
  theme_bw() +
  geom_vline(xintercept = 2003, lty=2) +
  scale_color_manual(values=c("NA" = "white", 
                             "[0,50]" = grey(0),
                             "]50,100]" = grey(0.2),
                             "]100,1000]" = grey(0.4),
                             "]1000,2000]" = grey(0.5),
                             "]2000,4000]" = grey(0.7),
                             "]4000,inf.]" = grey(.9)),
                     name="brackets CPUE") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  guides(size = guide_legend(title="CPUE",title.position="top", title.hjust = 0.5, ncol=1), 
         color = guide_legend(title.position="top", title.hjust = 0.5, ncol=1))
  
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_timeline_CPUE_per_basin.png"), width = 6, height=4)

# Create log scales
myseq <- c(0:10, seq(20,100,10), seq(200,1000,100), seq(2000, 10000, 1000))
myseqlab <- function(x,seq) {
  seq[!seq %in% x] <- "" 
  return(seq)
}

p1 <- ggplot(smelt_trawl, aes(Year, CPUE)) + 
  geom_hline(yintercept = 0, lwd=.3, alpha=.3) +
  geom_smooth(color="tomato") +
  geom_vline(xintercept = 2003, lty=2) +
  geom_point(aes(shape=Station)) +
  scale_shape_manual(values=c(16,4,16,16,1)) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + xlim(1986,2015) +
  facet_wrap(~Basin, scales="free", ncol = 1,
             labeller = label_glue('({.l}) {Basin}')) +
  guides(shape=FALSE)
p1
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_CPUE_per_basin.png"), width = 3, height=7)

p1.2 <- ggplot(smelt_trawl, aes(Year, log(CPUE))) + 
  #geom_hline(yintercept = 0, lwd=.3, alpha=.3) +
  geom_smooth(color="tomato") +
  geom_vline(xintercept = 2003, lty=2) +
  geom_hline(yintercept = log(200), lwd=1, col=adjustcolor("darkorange", alpha.f = .4)) +
  geom_point(aes(shape=smelt_trawl$Station), alpha=.5, show.legend = F) +
  scale_shape_manual(values=c(16,4,16,16,1)) +
  theme_bw() +
  #theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + xlim(1986,2015) +
  facet_wrap(~Basin, ncol = 1,
             labeller = label_glue('({.l}) {Basin}')) + 
  scale_y_continuous(
    name   = "CPUE",
    breaks = log(c(0,10,100,1000,5000)),
    labels = c(0,10,100,1000,5000),
    minor_breaks = log(myseq), 
    sec.axis = sec_axis(~ ., name = "log(CPUE)"))  
 # scale_y_continuous(sec.axis = sec_axis(~ exp(.), name = "CPUE", breaks = c(0,10,35,120,400,1500,5000)))
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_logCPUE_per_basin3.png"), p1.2, width = 3, height=5.5)

x <- c(1:100)
y <- c(1:100)
p1 <- qplot(x, y)
p1 + theme(panel.grid.minor = element_line(colour="white", size=0.5)) +
    scale_y_continuous(minor_breaks = myseq, breaks = seq(0, 100, 10))

ggplot(smelt_trawl, aes(Year, CPUE)) + geom_point() +
  theme_bw() +
  facet_wrap(~Station)


smelt_trawl_summ <- as.data.frame(with(smelt_trawl,
                            tapply(CPUE,list(Year, Basin), mean, na.rm=T)))

smelt_trawl_w <- data.frame("Year" = as.numeric(paste(rownames(smelt_trawl_summ))))
smelt_trawl_w$MainLake_5yr <- NA
smelt_trawl_w$MallettsBay_5yr <- NA
smelt_trawl_w$NortheastArm_5yr <- NA

for (i in 4:(nrow(smelt_trawl_summ)-2)) {
  smelt_trawl_w$MainLake_5yr[i] <- sum(smelt_trawl_summ$`Main Lake`[(i-2):(i+2)])/5
  smelt_trawl_w$MallettsBay_5yr[i] <- sum(smelt_trawl_summ$`Malletts Bay`[(i-2):(i+2)])/5
  smelt_trawl_w$NortheastArm_5yr[i] <- sum(smelt_trawl_summ$`Northeast Arm`[(i-2):(i+2)])/5
}

colnames(smelt_trawl_w) <- c("Year", colnames(smelt_trawl_summ))

smelt_trawl_w <- smelt_trawl_w[!is.na(smelt_trawl_w[,2]),]

smelt_trawl_w <- melt(smelt_trawl_w, id.vars = "Year", variable.name = "Basin", value.name = "CPUE")

smelt_trawl_summ <- cbind("Year"= rep(as.numeric(paste(rownames(smelt_trawl_summ))), ncol(smelt_trawl_summ)),melt(smelt_trawl_summ, variable.name = "Basin", value.name = "CPUE"))

p2 <- ggplot(smelt_trawl_w, aes(Year, CPUE)) + 
  geom_hline(yintercept = 0, lwd=.3, alpha=.3) +
  #geom_smooth(color="tomato") +
  geom_line(color="black") +
  geom_vline(xintercept = 2003, lty=2) +
  geom_point(smelt_trawl_summ, mapping=aes(Year, CPUE), alpha=.4) +
  geom_point(smelt_trawl_summ[smelt_trawl_summ$Year==1987,], mapping=aes(Year, CPUE), pch=4, col = "tomato") +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + xlim(1986,2015) +
  facet_wrap(~Basin, ncol = 1,
             labeller = label_glue('({.l}) {Basin}'))
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_CPUE_per_basin_running_average.png"), width = 3, height=7)


p3 <- ggplot(smelt_trawl_w, aes(Year, log(CPUE))) + 
  #geom_hline(yintercept = log(0), lwd=.3, alpha=.3) +
  #geom_smooth(color="tomato") +
  geom_line(color="black") +
  geom_vline(xintercept = 2003, lty=2) +
  geom_hline(yintercept = log(200), lwd=1, col=adjustcolor("darkorange", alpha.f = .4)) +
  geom_point(smelt_trawl_summ, mapping=aes(Year, log(CPUE)), alpha=.4) +
  geom_point(smelt_trawl_summ[smelt_trawl_summ$Year==1987,], mapping=aes(Year, log(CPUE)), pch=4, col = "tomato") +
  theme_bw() +
  #theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + xlim(1986,2015) +
  facet_wrap(~Basin, ncol = 1,
             labeller = label_glue('({.l}) {Basin}'))  + 
    scale_y_continuous(
    name   = "CPUE",
    breaks = log(c(0,10,100,1000, 5000)),
    labels = c(0,10,100,1000, 5000),
    minor_breaks = log(myseq), 
    sec.axis = sec_axis(~ ., name = "log(CPUE)"))  
  # scale_y_continuous(sec.axis = sec_axis(~ exp(.), name = "CPUE", breaks = c(0,10,35,120,400,1500,5000)))
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_logCPUE_per_basin_running_average3.png"), p3, width = 3, height=5.5)

library(ecp)
for (i in seq_along(unique(smelt_trawl_summ$Basin))) {
  changepoint_found <- 
    e.divisive(as.matrix(smelt_trawl_summ[smelt_trawl_summ$Basin==unique(smelt_trawl_summ$Basin)[i],"CPUE"]), min.size = 3, sig.lvl = .05)$order.found[-c(1:2)]
  
  print(paste0("Changepoint for basin ", unique(smelt_trawl_summ$Basin)[i], " were found in ", paste(smelt_trawl_summ[smelt_trawl_summ$Basin==unique(smelt_trawl_summ$Basin)[i],"Year"][changepoint_found], collapse = ", "), " (changepoint ranked from most significant to least significant)."))
  
  #cpt mean
  changepoint_found <- 
    cpt.mean(smelt_trawl_summ[smelt_trawl_summ$Basin==unique(smelt_trawl_summ$Basin)[i],"CPUE"])

  print(paste0("Change in mean for basin ", unique(smelt_trawl_summ$Basin)[i], " were found in ", paste(smelt_trawl_summ[smelt_trawl_summ$Basin==unique(smelt_trawl_summ$Basin)[i],"Year"][cpts(changepoint_found)], collapse = ", "), " (changepoint ranked from most significant to least significant)."))
  
  #cpt var
  changepoint_found <- 
    cpt.var(smelt_trawl_summ[smelt_trawl_summ$Basin==unique(smelt_trawl_summ$Basin)[i],"CPUE"])
  
  print(paste0("Change in variance for basin ", unique(smelt_trawl_summ$Basin)[i], " were found in ", paste(smelt_trawl_summ[smelt_trawl_summ$Basin==unique(smelt_trawl_summ$Basin)[i],"Year"][cpts(changepoint_found)], collapse = ", "), " (changepoint ranked from most significant to least significant)."))
}




(p1 + labs(subtitle = "A") | p2 + labs(subtitle = "B"))
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_CPUE_per_basin_summary.pdf"), width = 6, height=7)

(p1.2 + labs(subtitle = "A") | p3+ labs(subtitle = "B"))
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_logCPUE_per_basin_summary.png"), width = 7, height=7)

```


```{r forage yoy}
forage_yoy <- read.delim(paste0(getpath4data(), "data_from_Bernie/MasterYOYBio2008-2015.txt"))
head(forage_yoy)
dim(forage_yoy)
summary(forage_yoy)
```


## Smelt length at age

```{r smelt length at age, echo=FALSE, message=FALSE, warning=FALSE}
head(smelt)
smelt$Station <- factor(smelt$Station, levels=c("Valcour Island","Juniper Island","Barber Point", "Malletts Bay", "Northeast Arm"))

 
ggplot(smelt %>%
         mutate("Alewife" = case_when(
           Year<=2000 ~ "pre-alewife 1990-2000",
           Year>=2006 ~ "post-alewife 2006-2015",
           Year>2000&Year<2006 ~ "2001-2005"
         )) %>%
         group_by(Alewife, Station, Age) %>% 
         summarise("Length_m" = mean(Length, na.rm=T),
                   "sd" = sd(Length, na.rm=T)), 
       aes(Age, Length_m, col = factor(Alewife, 
                                       levels = c("pre-alewife 1990-2000", "2001-2005", "post-alewife 2006-2015")))) + 
  stat_smooth(col="#E6E6FA") +
  geom_errorbar(aes(ymin=Length_m-sd, ymax=Length_m+sd), width=.2) + 
  geom_point() +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  guides(color = guide_legend(ncol=1,byrow=TRUE, title.position = "top")) +
  facet_wrap(~Station, ncol = 1,
             labeller = label_glue('({.l}) {Station}')) +
  labs(x = "Age", y = "Length (mm)") +
  scale_colour_manual(values=c("pre-alewife 1990-2000" = "deepskyblue4",
                               "post-alewife 2006-2015" = "#DDA0DD" ,
                               "2001-2005" = "grey"),
                      name="Period") 
#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_length_at_age.png"), width = 4.5, height=7)

```

## Model some response variables in smelt population against drivers

```{r Model some response variables in smelt population against drivers - step 1: prepare drivers, message=FALSE, warning=FALSE}
# Drivers
# Mysis biomass
pmysis <- ggplot(mysis_summ, aes(Year, mean)) +
  geom_vline(xintercept = 2003-0.3, lty=2) +
  geom_vline(xintercept = 2008-0.3, lty=1) +
  stat_smooth(data = mysis_summ[mysis_summ$Year<=1995,],method="lm",col="#D8BFD8", fill = "#E6E6FA") +
  stat_smooth(data = mysis_summ[mysis_summ$Year>1995,],method="lm",col="#D8BFD8", fill = "#E6E6FA") +
  geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2) + 
  geom_point() +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  guides(color = guide_legend(ncol=1,byrow=TRUE, title.position = "top")) +
  labs(x = "Year", y = "Number of mysis") 


# Lake trout stocking
stklkt <- read.delim(paste0(getpath4data(),"data_from_Ellen/LC_LKT_stocking_history_1972_2018.txt"))
head(stklkt)
stklkt_summ <- as.data.frame(with(stklkt, tapply(NB_EQUIV,list("Year"=YEAR,"Stocking_site"=STOCKING_SITE), sum, na.rm=T)))
stklkt_summ$TOTAL <- rowSums(stklkt_summ, na.rm = T)
stklkt_summ2 <- data.frame("Year" = as.numeric(paste(rownames(stklkt_summ))),
                           "TOTAL" = stklkt_summ$TOTAL)

plaketrout <- ggplot(stklkt_summ2, aes(x=Year,y=TOTAL)) +
  geom_vline(xintercept = 2003-0.3, lty=2) +
  geom_vline(xintercept = 2008-0.3, lty=1) +
  geom_bar(stat="identity") + xlab("Year") + ylab("Stocked yearling-equivalent ") + theme_bw() + scale_y_continuous(labels = comma) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())

# Mysis and lake trout together
myxlim = c(1970,2016)
grid.draw(rbind(ggplotGrob(plaketrout+labs(subtitle = "a. Lake trout")+xlim(myxlim)+geom_vline(xintercept = 1995.5, col="cornflowerblue", alpha=.4)),
                ggplotGrob(pmysis+labs(subtitle = "b. Mysis")+xlim(myxlim)+geom_vline(xintercept = 1995.5, col="cornflowerblue", alpha=.4)), size = "first"))


drivers<- merge(stklkt_summ2 , mysis_summ, by="Year", all=T)
ggplot(drivers, aes(TOTAL, mean)) + geom_point() + stat_smooth(method="gam", formula = y ~ s(x))
gam1 <- gam(mean ~ s(TOTAL), data = drivers)
acf(resid(gam1), lag.max = 20, main = "ACF")
pacf(resid(gam1), lag.max = 20, main = "pACF")
plot(resid(gam1))
summary(gam1)
plot.gam(gam1, shade = T)

# TP (nutrients)
colnames(dtlcm)
if(!is.Date(dtlcm$VisitDate)) dtlcm$VisitDate <- as.Date(dtlcm$VisitDate, format="%d/%m/%Y")
Station_ltm <- c(7, 19, 36, 25, 34) #Station matching up smelt data.
#Barber Point: 7
#Juniper Island: 19
#Valcours Island: 36
#Malletts Bay: 25
#Northeast Arm:34
# None perfectly match the sampling station, but it is closer than no data at all.
dtlcm_smelt <- 
dtlcm[dtlcm$StationID %in% Station_ltm, ] %>% group_by(StationID, Year) %>%
  summarise(     "Temperature_E_m" = mean(Temperature_E, na.rm=T),
                "Temperature_E_sd" = sd(Temperature_E, na.rm=T),
                 "Temperature_H_m" = mean(Temperature_H, na.rm=T),
                "Temperature_H_sd" = sd(Temperature_H, na.rm=T),
            "Total.Phosphorus_E_m" = mean(Total.Phosphorus_E, na.rm=T),
           "Total.Phosphorus_E_sd" = sd(Total.Phosphorus_E, na.rm=T),
            "Total.Phosphorus_H_m" = mean(Total.Phosphorus_H, na.rm=T),
           "Total.Phosphorus_H_sd" = sd(Total.Phosphorus_H, na.rm=T),
               "Chlorophyll.a_E_m" = mean(Chlorophyll.a_E, na.rm=T),
              "Chlorophyll.a_E_sd" = sd(Chlorophyll.a_E, na.rm=T),
               "Chlorophyll.a_H_m" = mean(Chlorophyll.a_H, na.rm=T),
              "Chlorophyll.a_H_sd" = sd(Chlorophyll.a_H, na.rm=T),
 "Net.phytoplankton..total.biovolume_m" = mean(Net.phytoplankton..total.biovolume, na.rm=T),
"Net.phytoplankton..total.biovolume_sd" = sd(Net.phytoplankton..total.biovolume, na.rm=T),
   "Net.phytoplankton..total.density_m" = mean(Net.phytoplankton..total.density, na.rm=T),
  "Net.phytoplankton..total.density_sd" = sd(Net.phytoplankton..total.density, na.rm=T))

dtlcm_smelt <- dtlcm_smelt %>% mutate("Station" = case_when( 
  StationID ==  7 ~ "Barber Point",
  StationID == 19 ~ "Juniper Island",
  StationID == 36 ~ "Valcour Island",
  StationID == 25 ~ "Malletts Bay",
  StationID == 34 ~ "Northeast Arm"
))

#plot environmental parameters
for (i in seq(3,15,by=4)) {
  # Subset
  if(i == 7) param = "Total phosphorus (µg/l)"
  if(i == 3) param = "Temperature (°C)"
  if(i == 11) param = "Chlorophyll-a (mg/l)"
  if(i == 15) param = "Net phytoplankton biovolume (µm3/l)"
  
  # Initialize output
  if(i == 3) poutput <- list()
  
  dtlcm_smelt_temp <- dtlcm_smelt[,c(1,2,i:(i+3))]
  colnames(dtlcm_smelt_temp)[-c(1,2)] <- c("varE", "varE_sd", "varH", "varH_sd")
  dtlcm_smelt_temp$StationID <- factor(dtlcm_smelt_temp$StationID, levels=c("7", "19", "36", "25", "34"))
  p1 <- 
    ggplot(dtlcm_smelt_temp) +
    geom_vline(xintercept = 2003-0.3, lty=2) +
    geom_vline(xintercept = 2008-0.3, lty=1) +
    geom_vline(xintercept = 1995.5, col="cornflowerblue", alpha=.4) +
    #geom_errorbar(aes(x=Year, ymin=varE-varE_sd, ymax=varE+varE_sd, color=factor(StationID)), width=.3, lwd=.2) +
    geom_point(mapping = aes(Year, varE, color=factor(StationID)), alpha=.6) +
    geom_line(mapping = aes(Year, varE, color=factor(StationID)), alpha=.6)
  if (i !=15) {
    p1 <- p1 + 
    #geom_errorbar(aes(x=Year, ymin=varH-varH_sd, ymax=varH+varH_sd, color=factor(StationID)), width=.3, lwd=.2) +
        geom_point(mapping = aes(Year, varH, color=factor(StationID)), shape=1) +
        geom_line(mapping = aes(Year, varH, color=factor(StationID)), alpha=.6, lty=2)
  }
   p1 <- p1 + 
    labs(y=param) +
    theme_bw() +
    scale_color_manual(values = c("7"  = "#D8BFD8", #Barber Point
                                  "19" = "#EE82EE", #Juniper Island
                                  "36" = "darkslateblue", #Valcours Island
                                  "25" = "darkseagreen4", #Malletts Bay
                                  "34" = "darkorange1" #NE Arm
                                  )) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
    guides(color = guide_legend(ncol=1,byrow=TRUE, title.position = "top", title = "Station \nnumber")) 
   p1
   
   poutput[[param]] <- p1
   
}



myxlim = c(1990,2016)
grid.draw(rbind(ggplotGrob(poutput[[1]] + 
                             labs(subtitle = "a. Water temperature") + 
                             xlim(myxlim)),
                ggplotGrob(poutput[[2]] +
                             labs(subtitle = "b. Nutrients") + 
                             xlim(myxlim)),
                ggplotGrob(poutput[[3]] +
                             labs(subtitle = "c. Chlorophyll-a") + 
                             xlim(myxlim)),
                ggplotGrob(poutput[[4]] +
                             labs(subtitle = "d. Phytoplankton biovolume") + 
                             xlim(myxlim)), size = "last"))

```


```{r Model some response variables in smelt population against drivers - step 2: get the drivers + response dataframe clean from previous step, message=FALSE, warning=FALSE}
drivers_smelt <- drivers
for(i in Station) {
  if(i == Station[1]) drivers_smelt <- cbind("Station" = rep(i, nrow(drivers)), drivers) else
    drivers_smelt <- rbind(drivers_smelt,
                           cbind("Station" = rep(i, nrow(drivers)), drivers))
}

drivers_smelt$Code <- paste0(drivers_smelt$Station, "_", drivers_smelt$Year) 
drivers_smelt <- drivers_smelt[,!colnames(drivers_smelt) %in% c("Station", "Year")]
dtlcm_smelt$Code <- paste0(dtlcm_smelt$Station, "_", dtlcm_smelt$Year) 

drivers_smelt <- merge(drivers_smelt,dtlcm_smelt, by="Code", all = T)

#Now get response (CPUE, condition, etc. for each Station, and model)
smelt_station_CPUE <- smelt_age_CPUE %>% group_by(StationYear) %>%
  summarise("CPUE" = mean(CPUE, na.rm=T),
            "CPUE_age2" = mean(`2`, na.rm=T))

smelt_temporary <- smelt  %>% group_by(Station, Year) %>%
  summarise("condition" = mean(condition, na.rm=T))
smelt_temporary$StationYear <- paste0(smelt_temporary$Station, "_", smelt_temporary$Year)

# Merge 1
resp_smelt <- merge(smelt_bio_summ,smelt_station_CPUE, by = "StationYear", all = T)

# Dataset instantaneous mortality
smelt_temporary <- thcc_out[thcc_out$MinAge==2,]  %>% group_by(Station, Cohort) %>%
  summarise("A" = mean(A, na.rm=T))
smelt_temporary$StationYear <- paste0(smelt_temporary$Station, "_", smelt_temporary$Cohort)
smelt_temporary <- smelt_temporary[,!colnames(smelt_temporary) %in% c("Cohort", "Station")]

# Merge 2
resp_smelt <- merge(resp_smelt,smelt_temporary, by = "StationYear", all = T)

colnames(resp_smelt)[1] <- "Code"
resp_smelt <- resp_smelt[,!colnames(resp_smelt) %in% c("Year", "Station")]


# Merge Drivers and response ####
smelt_mod <- merge(resp_smelt, drivers_smelt, by = "Code", all = T)

smelt_mod$Code <- as.character(smelt_mod$Code)
smelt_mod$Station <- substr(smelt_mod$Code, start = 1, stop = nchar(smelt_mod$Code)-5)
smelt_mod$Year <- as.numeric(paste(substr(smelt_mod$Code, start = nchar(smelt_mod$Code)-3, stop = nchar(smelt_mod$Code))))

smelt_mod <- cbind(smelt_mod[,c("Code", "Station", "StationID", "Year")],smelt_mod[,!colnames(smelt_mod) %in% c("Code", "Station", "StationID", "Year")])

# write.table(smelt_mod, file = paste0(getwd(), "/Output/Data/smelt_data_model.txt"), sep="\t")

# smelt_mod <- read.delim(paste0(getwd(), "/Output/Data/smelt_data_model.txt"))
# # Transform to numeric what needs be
# indx <- 3:ncol(smelt_mod)
# smelt_mod[indx] <- lapply(smelt_mod[indx], function(x) as.numeric(as.character(x)))

```

```{r Model some response variables in smelt population against drivers - step 3: actual model, message=FALSE, warning=FALSE}

colnames(smelt_mod)
# Get two vectors with col numbers of drivers and responses, so I can model everything against everything
   resp_smelt <- c(5:7)
drivers_smelt <- c(8:10,14:29)

# Start loop ####
out_mod_lm = out_mod_gam = NULL

for (i in resp_smelt)  {
  for (j in drivers_smelt) {
    for (k in 0:length(Station)) {
      # Run the model for lake, per stations, and per basin
      smelt_mod_subset <- smelt_mod
      if (k != 0) smelt_mod_subset <- smelt_mod_subset[smelt_mod_subset$Station == Station[k],]
      
      # Subset to non NA data
      smelt_mod_subset <- cbind(smelt_mod_subset[!is.na(smelt_mod_subset[,i]) & !is.na(smelt_mod_subset[,j]),c("Year", "Station")],smelt_mod_subset[!is.na(smelt_mod_subset[,i]) & !is.na(smelt_mod_subset[,j]),c(i,j)])
      colnames(smelt_mod_subset)[3:4] <- c("resp", "driv")
      
      # Linear model ####
      lm1 <- lm(resp ~ driv, data = smelt_mod_subset)
    
      # save output
      out_mod_lm <- c(out_mod_lm, 
                      "lm", 
                      ifelse(k!=0, Station[k], "All lake"),
                      colnames(smelt_mod)[j], colnames(smelt_mod)[i], summary(lm1)[[8]], summary(lm1)[[4]][2,4], j, i)
    
      # GAM ####
      if(nrow(smelt_mod_subset)>18) {
        gam1 <- gam(resp ~ s(driv), data = smelt_mod_subset)
        
        # Save output gam
        gam1_summ <- summary(gam1)
        gam1_summ$r.sq
        gam1_summ$dev.expl
        gam1_summ$s.table
        out_mod_gam <- c(out_mod_gam,
                     "gam", 
                      ifelse(k!=0, Station[k], "All lake"),
                     colnames(smelt_mod)[j], colnames(smelt_mod)[i],
                     gam1_summ$r.sq,         #r-squared
                     gam1_summ$s.table[1,4], #p-value
                     gam1_summ$s.table[1,1], #edf
                     gam1_summ$s.table[1,3], #F
                     gam1_summ$dev.expl,     #dev. explained
                     j,i
                     )
        # If GAM has dev.explained high enough, plot the shape of the relationship
        # sometimes, the fit is weird
        if(gam1_summ$dev.expl>0.3) {
          plot.gam(gam1, xlab = colnames(smelt_mod)[j], 
             ylab = paste0("s(", colnames(smelt_mod)[i], ")"),
             shade = T, residuals = T, main = ifelse(k!=0, Station[k], "All lake")) 
          abline(h=0)
        }
      }
    }
  }
  }


 out_mod_lm <- as.data.frame(matrix(out_mod_lm, ncol = 8, byrow = T))
out_mod_gam <- as.data.frame(matrix(out_mod_gam, ncol = 11, byrow = T))

 colnames(out_mod_lm) <- c("model", "Station", "driver", "response", "rsquared", "pvalue_driver", "j_index", "i_index")
colnames(out_mod_gam) <- c("model", "Station", "driver", "response", "rsquared", "pvalue_driver", "edf", "F", "dev_expl", "j_index", "i_index")

# Transform to numeric what needs be
indx <- 5:ncol(out_mod_lm)
out_mod_lm[indx] <- lapply(out_mod_lm[indx], function(x) as.numeric(as.character(x)))
indx <- 5:ncol(out_mod_gam)
out_mod_gam[indx] <- lapply(out_mod_gam[indx], function(x) as.numeric(as.character(x)))


out_mod_lm <- out_mod_lm[order(out_mod_lm$pvalue_driver),]
out_mod_lm[1:10,]

out_mod_gam <- out_mod_gam[order(out_mod_gam$dev_expl, decreasing = T),]
out_mod_gam[out_mod_gam$driver=="TOTAL",][1:10,]

j=17
i=2

```

```{r Model some response variables in smelt population against drivers - step 4: look at the shape of some relationship, message=FALSE, warning=FALSE}
ggplot(smelt_mod, aes(log(TOTAL), log(CPUE_age2))) + geom_point() +
  facet_wrap(~Station)

```


```{r simple model before after periods smelt, message=FALSE, warning=FALSE}
# code inspired from Lake Geneva paper

# smelt_mod <- read.delim(paste0(getwd(), "/Output/Data/smelt_data_model.txt"))
# # Transform to numeric what needs be
# indx <- 3:ncol(smelt_mod)
# smelt_mod[indx] <- lapply(smelt_mod[indx], function(x) as.numeric(as.character(x)))

colnames(smelt_mod)
   resp_smelt <- c(5:7)
drivers_smelt <- c(8:10,14:29)
library(car) # for function Anova()

i = 6 #CPUE 
j = 9 # total number of fish stocked
l = 2005
k = 0 # whole lake
windowtest <- NULL

# Instead, model before / after date, and see if relationship changes?
for (i in resp_smelt) {
  for (l in 1995:2010) {
      sep= l
      for (k in 0:length(Station)) {
          # Run the model for lake, per stations, and per basin
          smelt_mod_subset <- smelt_mod
          if (k != 0) smelt_mod_subset <- smelt_mod_subset[smelt_mod_subset$Station == Station[k],]
          
          # Select only Year, Station, and response
          smelt_mod_subset <- cbind(smelt_mod_subset[, c("Year", "Station")], 
                                    smelt_mod_subset[, c(i)])
          
          colnames(smelt_mod_subset) <- c("Year", "Station", "resp")
          
          smelt_mod_subset <- smelt_mod_subset[complete.cases(smelt_mod_subset),]
          
          # Add category before /after
          pre <- smelt_mod_subset[smelt_mod_subset$Year<sep,]
          post <- smelt_mod_subset[smelt_mod_subset$Year>=sep,]
          smelt_mod_subset$periods <- c(rep("pre", nrow(smelt_mod_subset[smelt_mod_subset$Year<sep,])), 
                                        rep("post", nrow(smelt_mod_subset[smelt_mod_subset$Year>=sep,])))
          
          # Now model
          all_m <- lm(resp ~ Year, data = smelt_mod_subset)
          if(nrow(pre)>1)  pre_m <- lm(resp ~ Year, data = pre)
          if(nrow(post)>1) post_m <- lm(resp ~ Year, data = post)
          if(nrow(pre)>0&nrow(post)>0) aov_m <- aov(resp ~ Year + periods, data = smelt_mod_subset)
          
          summary(all_m)
          summary(pre_m)
          summary(post_m)
          summary(aov_m)
          
          # Get output
          windowtest <- c(windowtest, 
                      ifelse(k!=0, Station[k], "All lake"),
                      colnames(smelt_mod)[i], 
                      l, #cut_year
                      nrow(pre), nrow(post),
                      summary(all_m)[[8]], summary(all_m)[[4]][2,4], # rquared and p-val
                      ifelse(nrow(pre)>1,  summary(pre_m)[[8]], NA),
                      ifelse(nrow(pre)>1,  summary(pre_m)[[4]][2,4], NA),
                      ifelse(nrow(post)>1, summary(post_m)[[8]], NA), 
                      ifelse(nrow(post)>1, summary(post_m)[[4]][2,4], NA), 
                      ifelse(nrow(pre)>0&nrow(post)>0, summary(aov_m)[[1]][[5]][1], NA), #p-value for year
                      ifelse(nrow(pre)>0&nrow(post)>0, summary(aov_m)[[1]][[5]][2], NA), #p-value for periods
                      i)
          
          if (k==0) plot_list <- list()
          plot_list [[k+1]] <-
          ggplot(smelt_mod_subset, aes(Year, resp)) +
            stat_smooth(method = "lm", fill=NA, col="tomato") + 
            stat_smooth(data = pre_m, mapping = aes(Year, resp), method ="lm", fill = NA, col = "#cedaff") + #fill = "#e7edff"
            stat_smooth(data = post_m, mapping = aes(Year, resp), method ="lm", fill = NA, col = "#DDA0DD") + #fill = "#E6E6FA" 
            geom_point(data = pre_m, mapping = aes(Year, resp), col = "#cedaff") + 
            geom_point(data = post_m, mapping = aes(Year, resp), col = "#DDA0DD") +
            labs(y = colnames(smelt_mod)[i], subtitle = ifelse(k!=0, Station[k], "All lake")) + 
            theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
          
          if (k == length(Station)) {
             g <- grid.arrange(plot_list[[1]], 
                              plot_list[[2]],
                              plot_list[[3]],
                              plot_list[[4]],
                              plot_list[[5]],
                              plot_list[[6]])
             if(!R_U_KNITTING) ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Smelt_linear_model/smelt_linear_model_", ifelse(nrow(pre)>0&nrow(post)>0, ifelse(summary(aov_m)[[1]][[5]][2]<0.05, "signif_", "non_signif_"), "not_enough_data_"),colnames(smelt_mod)[i],"_", l,".png"), plot = g, height=8, width= 7)
          }
      }
    }
}
# Clean output
windowtest <- as.data.frame(matrix(windowtest, ncol = 14, byrow = T))
colnames(windowtest) <- c("Station", "response", "cut_yr",
                          "numb_obs_pre", "numb_obs_post",
                          "lm_all_r2", "lm_all_pv",
                          "lm_pre_r2", "lm_pre_pv",
                          "lm_post_r2", "lm_post_pv",
                          "aov_year_pval", "aov_periods_pval",
                          "index_resp")

str(windowtest)

# Transform to numeric what needs be
indx <- 3:ncol(windowtest)
windowtest[indx] <- lapply(windowtest[indx], function(x) as.numeric(as.character(x)))
head(windowtest)
windowtest$Station <- factor(windowtest$Station, levels = c('All lake', 'Barber Point', 'Juniper Island', 'Valcour Island', 'Malletts Bay', 'Northeast Arm'))

# Plot the impact of periods 
ggplot(windowtest, aes(cut_yr, aov_periods_pval)) +
  geom_hline(yintercept = 0.05) +
  geom_point(pch = ifelse(windowtest$aov_periods_pval<=0.06, 16,1),
             size = ifelse(windowtest$aov_periods_pval<=0.06, 2,1)) +
  facet_grid(Station~response) +
  labs(x = "Cutting year", 
       y = "p-value",
       caption = "Anova test was conducted to compare periods before and after cutting year. Open circles indicate \n
       samples where periods are non-significantly different, close circles indicate cutting dates where period \n
       pre/post were significantly different at a level of 0.05.")  +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())

#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/pval_period.png"), height=8, width= 7)

# example plot of 2 type of relationship
ggplot(smelt_mod, aes(Year, CPUE)) + geom_point() +
  facet_grid(Station~resp, drop = F) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())

# Compare linear models characteristics
smelt_mod_resp <- cbind(smelt_mod[,c("Year", "Station")],
                        smelt_mod[,resp_smelt])
smelt_mod_resp <- melt(smelt_mod_resp, 
                       id.vars = c("Year", "Station"),
                       measure.vars = colnames(smelt_mod)[resp_smelt],
                       variable.name = "resp")
# plot
ggplot(smelt_mod, aes(Year, value)) + geom_point() +
  facet_grid(Station~resp, drop = F) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())


for (i in resp_smelt)  {
  for (j in 6) {# drivers_smelt) {
    for (l in 2000:2010) {
      sep= l
      for (k in 0:length(Station)) {
          # Run the model for lake, per stations, and per basin
          smelt_mod_subset <- smelt_mod
          if (k != 0) smelt_mod_subset <- smelt_mod_subset[smelt_mod_subset$Station == Station[k],]
          
          smelt_mod_subset <- cbind(smelt_mod_subset[, c("Year", "Station")], 
                                    smelt_mod_subset[, c(i,j)])
          
          colnames(smelt_mod_subset) <- c("Year", "Station", "resp", "driv")
          
          smelt_mod_subset <- smelt_mod_subset[complete.cases(smelt_mod_subset),]
          
          smelt_mod_subset$periods <- c(rep("pre", nrow(smelt_mod_subset[smelt_mod_subset$Year<sep,])), 
                                        rep("post", nrow(smelt_mod_subset[smelt_mod_subset$Year>=sep,])))
          
          
          model4=aov(resp ~ driv + periods, data=smelt_mod_subset)
          info <- Anova(model4, type="III")
      
          model41=lm(resp ~ driv + I(driv^1) + I(driv^3), data = smelt_mod_subset[smelt_mod_subset$periods=="pre",]) #exp(-exp(-driv)))
          info41 <- summary(model41) #Model Before
      #model42a=lm(residu[-c(1:sep)]~TempMoyenne[-c(1:sep)], data=smelt_mod_subset)
      #model42b=lm(residu[-c(1:sep)]~poly(TempMoyenne[-c(1:sep)],2), data=smelt_mod_subset)
      #model42c=lm(residu[-c(1:sep)]~poly(TempMoyenne[-c(1:sep)],3), data=smelt_mod_subset)
          model42=lm(resp ~ driv + I(driv^1) + I(driv^3), data = smelt_mod_subset[smelt_mod_subset$periods=="post",]) #exp(-exp(-smelt_mod_subset[,j][-c(1:sep)])), data=smelt_mod_subset)
          info42 <- summary(model42)
      #test_aic <- AIC(model42a,model42b,model42c,model42d)
      #test_llrt <- lrtest(model42a,model42b,model42c,model42d)
          #test_anova <- anova(model42a,model42b,model42c,model42d)
      #test_aic_pristine <- c(test_aic$AIC[1],test_aic$AIC[2],test_aic$AIC[3],test_aic$AIC[4])
      #test_llrt_pristine <- c(test_llrt$LogLik[1],test_llrt$LogLik[2],test_llrt$LogLik[3],test_llrt$LogLik[4])
      #test_anova_pristine <- c(test_llrt$LogLik[1],test_llrt$LogLik[2],test_llrt$LogLik[3],test_llrt$LogLik[4])
      #Results <- c(test_aic_pristine, test_llrt_pristine)
      Results <- c(l,colnames(smelt_mod)[c(j,i)],
                   info$Pr[2],signif(info$Pr[2]),info$Pr[3],
                   ifelse(k!=0, Station[k], "All lake"),
                   signif(info$Pr[3]),model41$coefficients[2],info41$adj.r.squared, model42$coefficients[2],info42$adj.r.squared,l)
      windowtest_residuals <- rbind (windowtest_residuals, Results)
      }
    }
  }
}
colnames(windowtest_residuals) <- c("SplitingYear","driver", "response", "Station","AOV_pvalue_driv","Significativity_driv","AOV_pvalue_Periods","Significativity_Periods","SlopePre","rsquaredPre","SlopePost","rsquaredPost","Year")
windowtest_residuals <- as.data.frame(windowtest_residuals)
#View(windowtest_residuals)

# Transform to numeric what needs be
indx <- 5:ncol(windowtest_residuals)
windowtest_residuals[indx] <- lapply(windowtest_residuals[indx], function(x) as.numeric(as.character(x)))

windowtest_residuals <- windowtest_residuals[order(windowtest_residuals$Significativity_Periods, decreasing = T),]
windowtest_residuals[1:10,]


```


## Summary table for paper with number of smelt captured and sampled

```{r Summary table for paper with number of smelt captured and sampled, message=FALSE, warning=FALSE, include=FALSE}
# station to keep
Station <- c("Barber Point", "Juniper Island", "Valcour Island", "Malletts Bay", "Northeast Arm")

# CPUE data
head(smelt_trawl)
smelt_table_summ <- as.data.frame(with(smelt_trawl[smelt_trawl$Station %in% Station,],
                            tapply(CPUE,list(Year, Station), mean, na.rm=T)))
smelt_table_summ <- smelt_table_summ[,colSums(smelt_table_summ, na.rm=T)>0]

# Biological data
head(smelt)
smelt_table_summ_bio <- as.data.frame(with(smelt,
                            tapply(rep(1,nrow(smelt)),list(Year, Station), sum, na.rm=T)))
smelt_table_summ_bio <- smelt_table_summ_bio[,colnames(smelt_table_summ_bio) %in% Station]

head(smelt_table_summ)
head(smelt_table_summ_bio)

# Assemble data frame
out <- NULL
for (i in 1984:2015) {
  out <- c(out, i)
  for (j in Station) {
    if(length(smelt_table_summ[which(as.numeric(paste(rownames(smelt_table_summ)))==i),j])>0 && !is.na(smelt_table_summ[which(as.numeric(paste(rownames(smelt_table_summ)))==i),j]))
      out <- c(out, 
             paste0(format(round(smelt_table_summ[which(as.numeric(paste(rownames(smelt_table_summ)))==i),j], 0), big.mark=","), " (", smelt_table_summ_bio[which(as.numeric(paste(rownames(smelt_table_summ_bio)))==i),j], ")")) else
               out <- c(out, NA)
  }  
}

out <- str_replace(out, "\\(\\)", "(-)")
out[is.na(out)] <- "-"
out <- matrix(out,ncol=6, byrow = T)
colnames(out) <- c("Year", Station)
head(out)

#View(out)
if(!R_U_KNITTING) write.table(out, file=paste0(getwd(),"/Output/Data/Smelt_summary_CPUE_bio.txt"), sep="\t")

```

`r as.data.frame(out)`


## Summary figure for paper

```{r summary figure for smelt paper}
# What I want is a summary figure with the different responses, per basin, across time.
# Use facet grid, with columns being stations, and rows the different responses.

# Get summary data of all variable together ####
smelt$StationYear <- paste0(smelt$Station, "_", smelt$Year)
smelt_trawl$StationYear <- paste0(smelt_trawl$Station, "_", smelt_trawl$Year)
Station <- c("Barber Point", "Juniper Island", "Malletts Bay", "Northeast Arm", "Valcour Island")

# Do a summary dataset for bio data
head(smelt_bio_stats <-
       smelt %>% group_by(Station, Year, Sample.No.) %>% 
  summarise(mean_l=mean(Length, na.rm=T),
            mean_w=mean(Weight, na.rm=T),
            mean_cond=mean(condition, na.rm=T),
            mean_age=mean(Age, na.rm=T),
            number = n()))

smelt_bio_stats <-
  smelt_bio_stats %>% mutate(Basin = case_when(
  Station == "Malletts Bay"   ~ "Malletts Bay",
  Station == "Northeast Arm"  ~ "Northeast Arm",
  Station %in% c("Valcour Island","Juniper Island","Barber Point") ~ "Main Lake"
))


smelt_bio_stats$Station <- factor(smelt_bio_stats$Station, levels = rev(c("Valcour Island","Juniper Island","Barber Point", "Malletts Bay", "Northeast Arm")))
smelt_bio_stats$Station2 <- as.numeric(factor(smelt_bio_stats$Station, levels = rev(c("Valcour Island","Juniper Island","Barber Point", "Malletts Bay", "Northeast Arm"))))

summary(smelt_bio_stats$number)

head(smelt_bio_stats <-
  melt(smelt_bio_stats, id.vars = c("Station", "Year", "Sample.No.", "Basin", "Station2"))
)

# Create a dataframe that resemble smelt_bio_stats, so we could rbind them together
smelt_trawl_stats <- smelt_trawl
smelt_trawl_stats$logCPUE <- log(smelt_trawl_stats$CPUE)
smelt_trawl_stats <- melt(smelt_trawl_stats, id.vars = c("Station", "Year", "Trawl.No.", "Basin"))
colnames(smelt_trawl_stats)[colnames(smelt_trawl_stats)=="Trawl.No."] <- "Sample.No."
smelt_trawl_stats <- smelt_trawl_stats[smelt_trawl_stats$variable=="logCPUE",]
smelt_trawl_stats$Station <- factor(smelt_trawl_stats$Station, levels = rev(c("Valcour Island","Juniper Island","Barber Point", "Malletts Bay", "Northeast Arm")))
smelt_trawl_stats$Station2 <- as.numeric(factor(smelt_trawl_stats$Station, levels = rev(c("Valcour Island","Juniper Island","Barber Point", "Malletts Bay", "Northeast Arm"))))

# Bind both tables
head(smelt_trawl_stats)
head(smelt_bio_stats)
smelt_trawl_stats <- smelt_trawl_stats[,colnames(smelt_bio_stats)]
smelt_tot_stats <- rbind(smelt_trawl_stats,
                         smelt_bio_stats[smelt_bio_stats$variable != "number",])

# If we want to add instantaneous mortality to the summary figure
instantaneous_mortality = T
if (instantaneous_mortality) {
  instantaneous_mortality2 = F
  
    thcc_out_f <-  melt(thcc_out, id.vars = c("Station", "Cohort", "Basin"), measure.vars = "A")
  colnames(thcc_out_f)[colnames(thcc_out_f)=="Cohort"] <- "Year"
  thcc_out_f <- thcc_out_f %>% 
  group_by(Station, Basin, Year) %>% 
       summarise(value = mean(value, na.rm=T))
  thcc_out_f$variable <- "A"
  thcc_out_f$Sample.No. <- rep(NA, nrow(thcc_out_f))
  thcc_out_f$Station <- factor(thcc_out_f$Station, levels = rev(c("Valcour Island","Juniper Island","Barber Point", "Malletts Bay", "Northeast Arm")))
thcc_out_f$Station2 <- as.numeric(factor(thcc_out_f$Station, levels = rev(c("Valcour Island","Juniper Island","Barber Point", "Malletts Bay", "Northeast Arm"))))



  if(instantaneous_mortality2) {
    im_w_ba_f  <-  melt(im_w_ba, id.vars = c("Year", "Basin"))
  im_w_ba_f$Station <- im_w_ba_f$Station2 <- im_w_ba_f$Sample.No. <- rep(NA, nrow(im_w_ba_f))
  im_w_ba_f <- im_w_ba_f[ , colnames(thcc_out_f)]
  
  im_tot_f <- rbind(im_w_ba_f,thcc_out_f)
  im_tot_f <- im_tot_f[, colnames(smelt_tot_stats)]
  } else {
    im_tot_f <- thcc_out_f[, colnames(smelt_tot_stats)]
  }

  smelt_tot_stats <- rbind(smelt_tot_stats, data.frame(im_tot_f))
  
}

# Transform to numeric what needs be
indx <- which(colnames(smelt_tot_stats)=="value")
smelt_tot_stats[indx] <- lapply(smelt_tot_stats[indx], function(x) as.numeric(as.character(x)))



# Add clean variable name
smelt_tot_stats <- smelt_tot_stats %>%
  mutate(variable2 = case_when(
    variable == "logCPUE" ~ "log(CPUE)",
    variable == "mean_l" ~ "average length (mm)",
    variable == "mean_w" ~ "average weight (g)",
    variable == "mean_cond" ~ "average condition",
    variable == "mean_age" ~ "average age",
    variable == "A" ~ "annual mortality (A)"
  ))

# Do changepoints for all variable in final smelt figure: ####

# Create 2nd summary data
head(smelt_tot_stats_mean <- smelt_tot_stats %>% 
       group_by(variable, variable2, Station, Basin, Year) %>%
       summarise(value = mean(value, na.rm = T))
     ) 

changepoint_found_out <- NULL
for(i in unique(smelt_tot_stats_mean$variable)) {
  for (j in unique(smelt_tot_stats_mean$Basin)) {
    if(i == "logCPUE") {
      changepoint_found <- 
    e.divisive(as.matrix(exp(smelt_tot_stats_mean[smelt_tot_stats_mean$Basin==j & smelt_tot_stats_mean$variable==i,"value"])), min.size = 3, sig.lvl = .05)$order.found[-c(1:2)]
    } else {
      changepoint_found <- 
    e.divisive(as.matrix(smelt_tot_stats_mean[smelt_tot_stats_mean$Basin==j & smelt_tot_stats_mean$variable==i,"value"]), min.size = 3, sig.lvl = .05)$order.found[-c(1:2)]
    }
     
     
     changepoint_found <- ifelse(length(changepoint_found)>0,
                                 smelt_tot_stats_mean[smelt_tot_stats_mean$Basin==j & smelt_tot_stats_mean$variable==i,"Year"][changepoint_found,],NA)
     
     changepoint_found_out <- c(changepoint_found_out,
                                i, j,
                                changepoint_found[[1]][1],
                                changepoint_found[[1]][2],
                                changepoint_found[[1]][3])

  }
}
changepoint_found_out <- as.data.frame(matrix(changepoint_found_out, ncol = 5, byrow = T))
colnames(changepoint_found_out) <- c("variable", "Basin", "Changepoint1", "Changepoint2", "Changepoint3")
# Add clean variable name
changepoint_found_out <- changepoint_found_out %>%
  mutate(variable2 = case_when(
    variable == "logCPUE" ~ "log(CPUE)",
    variable == "mean_l" ~ "average length (mm)",
    variable == "mean_w" ~ "average weight (g)",
    variable == "mean_cond" ~ "average condition",
    variable == "mean_age" ~ "average age",
    variable == "A" ~ "annual mortality (A)"
  ))

# Transform to numeric what needs be
indx <- 3:5
changepoint_found_out[indx] <- lapply(changepoint_found_out[indx], function(x) as.numeric(as.character(x)))

# Add for each changepoint the corresponding value
smelt_tot_stats_mean <- smelt_tot_stats_mean %>% unite("BasinVar", Basin, variable, Year, remove = FALSE, sep = "_")
changepoint_found_out$BasinVar1 <- paste(changepoint_found_out$Basin, changepoint_found_out$variable, changepoint_found_out$Changepoint1, sep = "_")
changepoint_found_out$BasinVar2 <- paste(changepoint_found_out$Basin, changepoint_found_out$variable, changepoint_found_out$Changepoint2, sep = "_")
changepoint_found_out$BasinVar3 <- paste(changepoint_found_out$Basin, changepoint_found_out$variable, changepoint_found_out$Changepoint3, sep = "_")
changepoint_found_out <- data.frame(changepoint_found_out, 
                     
           smelt_tot_stats_mean[match(changepoint_found_out$BasinVar1, smelt_tot_stats_mean$BasinVar), "value"],
           
             smelt_tot_stats_mean[match(changepoint_found_out$BasinVar2, smelt_tot_stats_mean$BasinVar), "value"],
           
             smelt_tot_stats_mean[match(changepoint_found_out$BasinVar3, smelt_tot_stats_mean$BasinVar), "value"])
changepoint_found_out 

colnames(changepoint_found_out)[(ncol(changepoint_found_out)-2):ncol(changepoint_found_out)] <- c("Cpt1", "Cpt2", "Cpt3")

# Plot ####
smelt_tot_stats$variable2 <- factor(smelt_tot_stats$variable2,
                                    levels = c("log(CPUE)" ,"average length (mm)" ,"average weight (g)" ,"average condition", "average age", "annual mortality (A)"))
changepoint_found_out$variable2 <- factor(changepoint_found_out$variable2,
                                    levels = c("log(CPUE)" ,"average length (mm)" ,"average weight (g)" ,"average condition", "average age", "annual mortality (A)"))
#library(tidyquant) # for moving average 
ggplot(smelt_tot_stats, aes(Year, value)) +
  geom_point(data = changepoint_found_out, 
             mapping = aes(Changepoint1, Cpt1), 
             col = "red", size = 10, pch = "|") +
  geom_point(data = changepoint_found_out, 
             mapping = aes(Changepoint2, Cpt2), 
             col = "pink", size = 10, pch = "|") +
  # geom_vline(data = changepoint_found_out, mapping = aes(xintercept = Changepoint1)) +
  # geom_vline(data = changepoint_found_out, mapping = aes(xintercept = Changepoint2)) +
  geom_smooth(color="black") +
  #geom_ma(n=10,col="red", na.rm = TRUE) +
  geom_vline(xintercept = 2003, lty=2) +
  geom_vline(xintercept = 2008, lty=1) +
  geom_point(aes(shape=Station), alpha=.5, show.legend = F) +
  scale_shape_manual(values=c(16,16,16,4,1)) +
  theme_bw() +
  facet_grid(variable2~Basin, scales = "free_y") 
  


#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/Final_figure_summary.png"), width = 6, height=8)


# PCA on this smelt_tot_stats ####
smelt_tot_stats_df <- 
dcast(smelt_tot_stats, Station + Basin + Year ~ variable, value.var = "value", fun.aggregate = mean, na.rm = T)

head(smelt_tot_stats_df)
str(smelt_tot_stats_df) # make sure it's numeric

# prepare datset for 
smelt_tot_stats_df$logCPUE[smelt_tot_stats_df$logCPUE=="-Inf"] <- 0
row.names(smelt_tot_stats_df) <- paste(smelt_tot_stats_df$Station, smelt_tot_stats_df$Basin, smelt_tot_stats_df$Year, sep="_") 
smelt_tot_stats_df$Station <- smelt_tot_stats_df$Basin <- smelt_tot_stats_df$Year <- NULL
head(smelt_tot_stats_df)

df_pca <- prcomp(smelt_tot_stats_df[complete.cases(smelt_tot_stats_df), ], scale. = T,center = T )
summary(df_pca)

df_out <- as.data.frame(df_pca$x)
df_out$Station <- sapply( strsplit(as.character(row.names(smelt_tot_stats_df[complete.cases(smelt_tot_stats_df), ])), "_"), "[[", 1 )
df_out$Basin <- sapply( strsplit(as.character(row.names(smelt_tot_stats_df[complete.cases(smelt_tot_stats_df), ])), "_"), "[[", 2 )
df_out$Year <- as.numeric(paste(sapply( strsplit(as.character(row.names(smelt_tot_stats_df[complete.cases(smelt_tot_stats_df), ])), "_"), "[[", 3 )))
head(df_out)

percentage <- round(df_pca$sdev / sum(df_pca$sdev) * 100, 2)
percentage <- paste( colnames(df_out), "(", paste( as.character(percentage), "%", ")", sep="") )


p1 <- 
  ggplot(df_out,aes(x=PC1,y=PC2,color=Basin )) + 
  geom_hline(yintercept = 0, lwd=.1) +
  geom_vline(xintercept = 0, lwd=.1) +
  geom_point() +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  xlab(percentage[1]) + ylab(percentage[2]) #+
  #scale_color_manual(values=c("tomato", "orange", "black"))

df_out_r <- as.data.frame(df_pca$rotation)
df_out_r$feature <- row.names(df_out_r)

df_out_r

p2 <- 
  ggplot(df_out_r,aes(x=PC1,y=PC2,label=feature)) + #,color=feature )) + 
  geom_hline(yintercept = 0, lwd=.1) +
  geom_vline(xintercept = 0, lwd=.1) +
  geom_point() + 
  theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  geom_text(size=3, nudge_y = .05) +
  labs(x = percentage[1], y = percentage[2]) +
  xlim(-0.5,0.7)

df_out_mean <- df_out %>% group_by(Basin, Year) %>%
  summarise(PC1 = mean(PC1),
            PC2 = mean(PC2),
            PC3 = mean(PC3),
            PC4 = mean(PC4),
            PC5 = mean(PC5))
p3_PC1 <-
  ggplot(df_out) +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 2003, lty=2) +
  geom_vline(xintercept = 2008, lty=1) +
  geom_point(df_out, mapping = aes(Year, PC1, color = Basin)) +
  geom_line(df_out_mean, mapping = aes(Year, PC1, color = Basin)) +
  labs(y = percentage[1]) + 
  theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) 

p3_PC2 <-
  ggplot(df_out) +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 2003, lty=2) +
  geom_vline(xintercept = 2008, lty=1) + 
  geom_point(df_out, mapping = aes(Year, PC2, color = Basin), show.legend = F) +
  geom_line(df_out_mean, mapping = aes(Year, PC2, color = Basin), show.legend = F) +
  labs(y = percentage[2]) +
    theme_bw() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) 

(p1 / p2 / p3_PC1 / p3_PC2)

#ggsave(paste0(getwd(),"/Output/Figures/9-Smelt/PCA.png"), width = 5.5, height=8)

```



# Alewife


```{r read alewife data, message=FALSE, warning=FALSE, include=FALSE}
alewife <- read.csv(file = paste0(getpath4data(),"data_from_Ellen/MasterFileSmeltBio1984-2015-2-24-16.csv"))
alewife <- alewife[alewife$Species == "Alewife",]
alewife$Station <- gsub("-"," ",alewife$Station)
head(alewife)
```

The data were provided by Ellen Marsden. It contains `r nrow(alewife)` observations of smelt for years `r paste(unique(alewife$Year), sep="", collapse="-")`. In fact, most data are for 2012. Each row has some metadata associated (date and basin sampled) as well as individuals characteristics (length, weight, year class, condition).


## Get alewife biomass evolution

Same logic, but if we select alewife && Juniper Island here, we only have data for 2012

```{r alewife subset main lake}
alwf_sub <- alewife[alewife$Station=="Juniper Island",]
alwf_sub_summ<-as.data.frame(with(alwf_sub, tapply(rep(1,nrow(alwf_sub)),list("Year#"=Year), sum)))
colnames(alwf_sub_summ) = "CPUE"
alwf_sub_summ$Year <- as.numeric(paste(rownames(alwf_sub_summ)))

ggplot(alwf_sub_summ, aes(Year, CPUE)) + geom_point() + geom_line()
```



# Whitefish


# Cisco
CiscoTL dataset as part of the FSAdata

CPUE (catch per 55 minutes trawl) of cisco collected, 1999-2014. Data from the VTFWS 2015 annual report (see doc given by Ellen).

Note that in Valcour Island (2013) and in Mallets Bay (2000,2002,2008), CPUE reported are in fact <1.

```{r extract data from VTFWS 2015 report table 12}
cisco <- data.frame("Year"=1999:2014)
cisco$BarberPoint   <- c(15,7,12,6,15,16,11,4,2,4,2,1,1,3,0,0)
cisco$JuniperIsland <- c(2,2,3,24,11,9,8,3,0,3,2,2,4,2,0,0)
cisco$ValcourIsland <- c(4,4,19,35,15,NA,8,4,7,2,3,5,9,3,1,0)
cisco$MalletsBay    <- c(1,1,1,1,0,0,1,0,0,1,0,0,0,0,0,0)
```

```{r cisco CPUE for 4 stations, echo=FALSE}
cisco2 <- cbind(melt(cisco[,-1]), "Year"=rep(cisco$Year,4))
colnames(cisco2) <- c("Station","CPUE","Year")
ggplot(cisco2, aes(Year,CPUE,col=Station)) + geom_point() + geom_line()
```
<br> `r fig_cap("cisco CPUE", "CPUE (catch per 55 minutes trawl) of cisco collected, 1999-2014")`


# Walleye

*Data:* <br>
- Data given by Bernie Pientka.

Bernie recommended a few sources:  
-	Overman, Nathanel C. 2000. Bioenergetics and Stable Isotope Analyses of Walleye in Lake Champlain. MS Thesis, Wildlife and Fisheries Biology, The University of Vermont, Burlington, Vermont. Under supervision of Donna Parrish. <br>
-	Simonin, P.W., Rudstam, L.G., Parrish, D.L., Pientka, B., Sullivan, P.J., 2018. Piscivore Diet Shifts and Trophic Level Change after Alewife Establishment in Lake Champlain. Trans Am Fish Soc 147, 939–947. https://doi.org/10.1002/tafs.10080 <br>
-	Labar G.W., Parrish, D.L., 1996. Bioenergetics Modeling for Lake Trout and other Top Predators in Lake Champlain, LCBP Technical Report #21 <br>
-	Parker Stetter, S.L., Rudstam, L.G., Stritzel Thomson, J.L., Parrish, D.L., 2006. Hydroacoustic separation of rainbow smelt (Osmerus mordax) age groups in Lake Champlain. Fisheries Research 82, 176–185. https://doi.org/10.1016/j.fishres.2006.06.014 <br>
-	Mitro, Matthew G. 1995. Estimation of Larval Walleye Production and the Potential for Starvation Mortality in Two Tributaries of Lake Champlain. MS Thesis, Wildlife and Fisheries Biology, The University of Vermont, Burlington, Vermont.<br>
-	Frater, Benjamin J. 2002. Habitat Selection and Annual Survival of Juvenile Walleye in Malletts Bay, Lake Champlain, Vermont. MS Thesis, Wildlife and Fisheries Biology, The University of Vermont, Burlington, Vermont.<br>
<br>
Bernie explained the rotating sampling and management of walleye population. Shortly, there is a 3-years rotation among rivers with historical walleye fishing:<br>
-	Winooski river (VT),<br>
-	Poultney river (NY/VT),<br>
-	Missisquoi river (VT),<br>
-	(and Lamoille river, but not in the 3-years rotation because the natural reproduction is going well there.<br>
In April, adults are sampled (electrofishing) and brought to the hatchery in Grand Isle. Eggs are sampled, fertilized, hatched, and raised for ~2.5 months, then released by July 4th in the river adults were sampled. Before that, individuals are marked. Fish are raised in ponds outside (Grand Isle hatchery), except for some experiments were fish were grown inside (but most of it takes place in the pond and that is where they got the highest survival).
The objective is to give a little boost to the population once every 3 years. Naturally, walleye have some 4-years cycle, and intervention of VTDFW hopefully avoids having one cohort dominating the whole population.<br>
During electrofishing, length, weight, and sex of individuals are collected, so the population structure can be characterized. Note that if I want to use these data, I should use male data, because females come and go, so sampling may not be representative of the population. As a matter of fact, there are often 4+ times more male walleye collected in the river than female. Also, it is not possible to calculate condition of female from these data because they may still have eggs.
Note that walleye wounding by sea lamprey and skin disease are also reported. Sea lamprey wounding has been null in Missisquoi river for the past two sampling event.<br>
__I could be able to estimate the biomass of walleye in the lake from the number of fish stocked and the proportion of fish recaptured that were stocked. Then calculate mortality using the different cohort strength (data every 3 years).__ <br>


```{r read walleye data}
# I pooled together the walleye data that were available per year
walleye_bio <- read.delim(paste0(getpath4data(),"data_from_Bernie/Walleye_surveys_2004-2019.txt"))
walleye_demo <- read.delim(paste0(getpath4data(),"data_from_Bernie/Walleye_age_structure.txt")) 

# Transform to numeric / factor what needs be
indx <- c(2,4:6,8)
walleye_bio[indx] <- lapply(walleye_bio[indx], function(x) as.numeric(as.character(x)))
walleye_bio$Year_f <- factor(walleye_bio$Year)
walleye_bio$Age_f <- factor(walleye_bio$Age)

indx <- c(2,4:6)
walleye_demo[indx] <- lapply(walleye_demo[indx], function(x) as.numeric(as.character(x)))
walleye_demo$Year_f <- factor(walleye_demo$Year)


# Demographic not within original excel files for at least 2004 and 2007. Extract these from walleye bio
# not working, go back to it 
head(walleye_demo_2)
str(walleye_bio)
#walleye_demo_2 <- 
walleye_bio %>% group_by(Year_f, Sex, Age_f) %>% 
  drop_na(Age) %>% 
  summarise(count = n(na.rm=T))

walleye_bio$count <- 1
walleye_demo2 <- walleye_bio %>% group_by(Year_f, Sex, Age) %>%
  summarise(count = sum(count))

ggplot(walleye_demo2, aes(Age, count)) +
  facet_grid(Year_f~Sex) + 
  geom_bar(stat="identity", position=position_dodge())

```


# Lake Trout

__Data:__ <br>
Data for 2016-2018 field seasons provided by Pascal Wilkins.
Displaying some summary data, including number of wild vs. stocked fish per year and basins, and number of fish collected per year (lot more in 2018 than the previous years).
```{r read data LT, include=FALSE}
LTcond <- read.delim(paste0(getpath4data(),"data_from_Pascal/LT_ConditionOverall.txt"))
LTcond <- LTcond[-c(2065),] # outlier detected by fultons

#head(LTcond)
with(LTcond, tapply(rep(1,nrow(LTcond)),list("Year#"=Year, "Clipped#"=Clipped), sum))
with(LTcond, tapply(rep(1,nrow(LTcond)),list("Site"=Local, "Clipped#"=Clipped), sum))
with(LTcond, tapply(rep(1,nrow(LTcond)),list("Year#"=Year, "Site"=Local), sum))

```

## Simple approach: estimate biomass from number of juvenile stocked

```{r simple approach for LT biomass estimate}
n_lt_stocked = 85000 #number lake trout stocked
w_lt_juv     = 1     #weight juvenile lake trout in g
```


## Read and explore effort data

First, import the data. They are all kept in different files, so that need to be processed a little bit.  
```{r read data effort LT, include=FALSE}
# Read data
LTeff16 <- read.delim(paste0(getpath4data(),"data_from_Pascal/LT_2016_effort2.txt"))
LTeff17 <- read.delim(paste0(getpath4data(),"data_from_Pascal/LT_2017_effort2.txt"))
LTeff18 <- read.delim(paste0(getpath4data(),"data_from_Pascal/LT_2018_effort2.txt"))

# Check which columns match and which don't
colnames(LTeff16)[!colnames(LTeff16) %in% colnames(LTeff17)]
colnames(LTeff16)[!colnames(LTeff16) %in% colnames(LTeff18)]
colnames(LTeff18)[!colnames(LTeff18) %in% colnames(LTeff16)]
colnames(LTeff18)[!colnames(LTeff18) %in% colnames(LTeff17)]

# Vector to reordinate columns at the end following LTeff18 template
order_name <- names(LTeff18)

# Order so all columns are in the same order
LTeff16 <- LTeff16[,c(order(colnames(LTeff16)))]
LTeff17 <- LTeff17[,c(colnames(LTeff16)[order(colnames(LTeff16))],colnames(LTeff17)[!colnames(LTeff17) %in% colnames(LTeff16)])]
LTeff18 <- LTeff18[,c(colnames(LTeff17)[order(colnames(LTeff17))],colnames(LTeff18)[!colnames(LTeff18) %in% colnames(LTeff17)])]

# merge dataframe
LTeff <- merge(t(LTeff17),t(LTeff16), by = "row.names", all = T)
  rownames(LTeff) <- LTeff[,grep("Row.names", colnames(LTeff))]
  LTeff <- LTeff[,-grep("Row.names", colnames(LTeff))]
LTeff <- merge(t(LTeff18),LTeff, by = "row.names", all = T)
  rownames(LTeff) <- LTeff[,grep("Row.names", colnames(LTeff))]
  LTeff <- LTeff[,-grep("Row.names", colnames(LTeff))]
LTeff <- as.data.frame(t(LTeff))
# Check that we have the correct number of rows - two extra, because rownames were added as columns (and then transformed in rows, so two extra rows)
dim(LTeff)
sum(nrow(LTeff16)+nrow(LTeff17)+nrow(LTeff18))

LTeff <- LTeff[,c(order(order_name))]

head(LTeff)

LTeff$AvDepth_m <- (as.numeric(paste(LTeff$start.depth.m)) + as.numeric(paste(LTeff$end.depth.m)))/2
# Just checking Pascal also calculated the average depth by averaging start and end depth:
plot(LTeff$AvDepth_m, as.numeric(paste(LTeff$Average.Depth..m.)))
abline(a=0, b=1)

names(LTeff)
```

Number of fish collected per year and per sites: Main Lake is mainly targeted.

```{r number of LT collected per year per basin, echo=FALSE}
sites = unique(LTcond$Local)
plot(c(unique(LTcond$Year)), rep(1,3),
     cex=sqrt(summary(as.factor(LTcond$Year[LTcond$Local==sites[1]]))/15),
     xlim=c(2015,2019),ylim=c(0,4), axes=F, xlab="", ylab="", main="Relative number of data per year and per site", pch=20)
points(c(unique(LTcond$Year)), rep(2,3),
       cex=sqrt(summary(as.factor(LTcond$Year[LTcond$Local==sites[2]])))/15, pch=20)
points(c(unique(LTcond$Year)), rep(3,3),
       cex=sqrt(summary(as.factor(LTcond$Year[LTcond$Local==sites[3]])))/15, pch=20)
axis(1, at=c(1000,3000));axis(1, at = unique(LTcond$Year))
text(x=rep(2015,3), y=seq(1.5,3.5,1), labels = paste(sites, "lake"), adj = 0)

```


When where the trips done? There are two x-scales here (on top of the depth): year and hour of the day.

```{r when were the trips for LT done, echo=FALSE, message=FALSE, warning=FALSE}
LTeff$date <- as.POSIXlt(substr(parse_date_time(x = LTeff$date,orders = c("%d/%m/%Y", "%d/%m/%y", "%Y-%m-%d")),1,10), format = "%Y-%m-%d")
LTeff$yday <- LTeff$date$yday

LTeff$fyear <- as.factor(LTeff$year)
LTeff$year <- as.numeric(paste(LTeff$year))

LTeff$year_hour <- LTeff$year + as.numeric(paste0(substr(LTeff$start.time, 1,2),substr(LTeff$start.time, 4,5)))/5000-.24

LTeff$netID2 <- paste(LTeff$year,as.numeric(paste(LTeff$netID)),sep="_")
LTeff <- LTeff[order(LTeff$date),]


LTeff <- LTeff[!is.na(LTeff$year),]

ggplot(LTeff, aes(x=year_hour, y=-yday, color=LTeff$AvDepth_m)) + 
  geom_point() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) +
  scale_x_discrete(name ="Year", limits=c(2016,2017,2018)) +
  ylab("Julian Day") +
  annotate(geom="text",x=2016:2018, y=c(rep(-80,3)), label=paste("n=",summary(LTeff$fyear))) + 
  labs(color='Average depth (m)') + scale_fill_continuous(guide = guide_legend()) +
    theme(legend.position="bottom") +
  scale_colour_gradient(high = "grey10", low = "#56B1F7",
  space = "Lab", na.value = "blue", guide = "colourbar",
  aesthetics = "colour")

```

## Map trips
```{r map trip LT, message=FALSE, warning=FALSE, include=FALSE, cache=TRUE}
bathy<-readOGR(paste0(getpath4data(),"GIS/LakeChamplain_Shapefile/LakeChamplain.shp"))
lcgroupmap=c("lake",rep("island", 84562))
bathy2 <- raster(paste0(getpath4data(),"GIS/LCbathy.tif"))

world <- ne_countries(scale = "medium", returnclass = "sf")

class(bathy)
crs(bathy)
crs(world)
bathy <- spTransform(bathy,crs(world))
crs(bathy)
bathy2 <- projectRaster(bathy2, crs = crs(world))

res(bathy2)
#aggregate by factor = 3 to increase plotting speed
bathy2 <- aggregate(bathy2, fact=3)


LTeff$start.lat.dd <- as.numeric(paste(LTeff$start.lat.dd))
LTeff$start.lon.dd <- as.numeric(paste(LTeff$start.lon.dd))
LTeff$end.lat.dd <- as.numeric(paste(LTeff$end.lat.dd))
LTeff$end.lon.dd <- as.numeric(paste(LTeff$end.lon.dd))

# Step not necessary at the moment but make sure we're in the right projection.
LTeff_coord <- LTeff[,c("date","start.lon.dd","start.lat.dd","end.lon.dd","end.lat.dd")]
LTeff_coord <- LTeff_coord[complete.cases(LTeff_coord$start.lon.dd),]
LTeff_coord <- LTeff_coord[complete.cases(LTeff_coord$end.lon.dd),]
class(LTeff_coord)
## [1] "data.frame"
LTeff_start <- LTeff_coord[,c("start.lon.dd","start.lat.dd")]
coordinates(LTeff_start)<-~start.lon.dd+start.lat.dd
class(LTeff_start)
## [1] "SpatialPointsDataFrame"
## attr(,"package")
## [1] "sp"

# does it have a projection/coordinate system assigned?
proj4string(LTeff_start) # nope
## [1] NA

proj4string(bathy)

# we know that the coordinate system is NAD83 so we can manually
# tell R what the coordinate system is
proj4string(LTeff_start)<-CRS("+proj=longlat +datum=WGS84")

# now we can use the spTransform function to project. We will project
# the mapdata and for coordinate reference system (CRS) we will
# assign the projection from counties

LTeff_start<-spTransform(LTeff_start, CRS(proj4string(bathy)))

# double check that they match
identical(proj4string(LTeff_start),proj4string(bathy))

# Do the same for end coords
LTeff_end <- LTeff_coord[,c("end.lon.dd","end.lat.dd")]
coordinates(LTeff_end)<-~end.lon.dd+end.lat.dd
proj4string(LTeff_end)<-CRS("+proj=longlat +datum=WGS84")
LTeff_end<-spTransform(LTeff_end, CRS(proj4string(bathy)))

# double check that they match
identical(proj4string(LTeff_end),proj4string(bathy))


# Go back to dataframe
LTeff_start_df <- as.data.frame(LTeff_start)
LTeff_end_df <- as.data.frame(LTeff_end)
# Include to initial dataframe
LTeff_coord$start.lon.dd <- LTeff_start_df$start.lon.dd
LTeff_coord$start.lat.dd <- LTeff_start_df$start.lat.dd
LTeff_coord$end.lon.dd   <- LTeff_end_df$end.lon.dd
LTeff_coord$end.lat.dd   <- LTeff_end_df$end.lat.dd

```


There are some outliers, so deleting all longitude < -73.48 (2 points) and thus > -73.1.

```{r remove outliers from LT trawls coord}
LTeff_coord <- LTeff_coord[LTeff_coord$start.lon.dd<(-73.1) & LTeff_coord$start.lon.dd > (-73.48),]
```

Map visualising all the trips

```{r map visualize all trips, echo=FALSE, message=FALSE, warning=FALSE}
p2 <- ggplot() +  geom_polygon(data=bathy, aes(x=long, y=lat, group=group, fill=lcgroupmap), show.legend = FALSE) +
  scale_fill_manual(values = c("white","darkgrey")) +
  geom_point(data=LTeff_coord, aes(x=start.lon.dd, y=start.lat.dd), color=NA) +
  xlab("Longitude") + ylab("Latitude") + theme_minimal()  +
  theme_set(theme_bw()) +
  coord_equal(ratio=1) # square plot to avoid the distortion

  

p2 <- p2 + geom_segment(aes(x = LTeff_coord$start.lon.dd, y = LTeff_coord$start.lat.dd, xend = LTeff_coord$end.lon.dd, yend = LTeff_coord$end.lat.dd))

p2


#ggsave(paste0(getwd(),"/Output/Figures/1-descriptive/Trawl_trips_",min(LTeff$year, na.rm=T),"-",max(LTeff$year, na.rm=T),".pdf"), p2)

## Scale on map varies by more than 10%, scale bar may be inaccurate

```

## Explore growth parameters

### Weight-length relationship

Based on <a href=http://derekogle.com/fishR/examples/oldFishRVignettes/LengthWeight.pdf> this tutorial by Derek Ogle</a>, using FSA package.
The relationship between length and weigth is not linear, because length is a linear measure and weight is related to volume
```{r W by L plot for LT}
par(mfrow=c(1,2))
plot(LTcond$weight ~ LTcond$frozen.tl,xlab="total length (mm)",ylab="weight (g)",main="", pch=20)

LTcond$logW <- log(LTcond$weight)
LTcond$logL <- log(LTcond$frozen.tl)

lm1 <- lm(logW~logL,data=LTcond)
fitPlot(lm1,xlab="log total length (mm)",ylab="log weight (g)",main="")
abline(h=0, lwd=.5)
text(x=min(LTcond$logL), y=max(LTcond$logW)*.9, pos=4, label=paste0("y = ", round(lm1$coefficients[1],1)," + x * ", round(lm1$coefficients[2],1)))

```

The relationship is indeed not linear, but we can get the coefficients by log-transforming the data. The coefficients are given below:
```{r summary W by L for LT}
summary(lm1)
```


Try the quantile regression to fit the non-tranformed data
```{r quantile regression, message=FALSE, warning=FALSE}
library(quantreg)
LTcond$weight ~ LTcond$frozen.tl
m1 <- rq(weight~poly(frozen.tl,2), data=LTcond,tau=0.9)
m2 <- rq(weight~poly(frozen.tl,3), data=LTcond,tau=0.9)
m3 <- rq(weight~poly(frozen.tl,4), data=LTcond,tau=0.9)
AIC(m1)
AIC(m2)
AIC(m3)
# geom_quantile uses rq()
ggplot(LTcond, aes(frozen.tl,weight))+ geom_point()+
    geom_quantile(formula=y~poly(x,3),quantiles=0.9)

```


### Test whether LT exhibit isometric or allometric growth

A test of whether the fish in a population exhibit isometric growth or not can be obtained by noting that b is the estimated slope from fitting the transformed length-weight model. The slope is generically labeled with β such that the test for allometry can be translated into the following statistical hypotheses:
* H0: β=3 ⇒ H0 :"Isometric growth"
* HA: β≠3 ⇒ HA :"Allometric growth"
(All taken from Derek Ogle tutorial, go back there for more details).

A test, and confidence interval for b, of whether Lake Trout from Lake Champlain exhibited allometric growth or not is constructed with
```{r iso or allometric growth for LT}
hoCoef(lm1,2,3)
confint(lm1)
```
These results show that LT exhibit allometric growth (p < 0.0000001) with an exponent parameter (b) between 3.22 and 3.24, with 95% confidence.

### Prediction on original scale
Again, from Derek Ogle tutorial: "Predictions of the mean value of the response variable given a value of the explanatory variable can be made with predict(). In the length-weight regression, the value predicted is the mean log of weight. Most often, of course, the researcher is interested in predicting the mean weight on the original scale. An intuitive and common notion is that the log result can simply be back-transformed to the original scale by exponentiation. However, back-transforming the mean value on the log scale in this manner underestimates the mean value on the original scale. This observation stems from the fact that the back-transformed mean value from the log scale is equal to the geometric mean of the values on the original scale. The geometric mean is always less than the arithmetic mean and, thus, the back-transformed mean always underestimates the arithmetic mean from the original scale."

We want to extract the sigma, and then get the correction factor:
```{r sigma for LT growth}
syx <- summary(lm1)$sigma
( cf <- exp((syx^2)/2) )
```

(1) Predict log weight of a LT of size 200 mm
(2) Biased prediction on original scale
(3) Corrected prediction on original scale
```{r check bias for LT growth parameters}
( pred.log <- predict(lm1,data.frame(logL=log(200)),interval="c") ) ##(1)
( bias.pred.orig <- exp(pred.log) ) ##(2)
( pred.orig <- cf*bias.pred.orig ) ##(3)
```

### Comparison of Weight-Length relationship {.tabset}

#### Across years

Include year as a factor.  
```{r condition LT across years}
LTcond$fyear <- factor(LTcond$Year)
lm2 <- lm(logW~logL*fyear,data=LTcond)
```

The analysis of variable table is constructed by submitting the saved lm object to anova() as such
```{r anova on condition LT across years}
anova(lm2)
```
These results indicate that the interaction terms is significant (p = 1.850e-10). There is evidence to conclude that there is difference in slopes in the length-weight relationship between years. The p-value for the indicator variable suggests that there is a difference in intercepts between the three years (p = 1.086e-07). 

Plots and confidence intervals should be constructed for the model with the interaction term, as it was significant. The confidence intervals, constructed with:
```{r confint for condition LT across years}
confint(lm2)
par(mfrow=c(1,1))
fitPlot(lm2,xlab="log frozen length (mm)",ylab="log weight (g)",legend="topleft",main="", col=adjustcolor(c("red","blue","grey"), alpha.f = .5))
```

The difference is not so obvious once plotted


#### Across sites

Include sites as a factor.  
```{r condition LT across sites}
LTcond$fsites <- factor(LTcond$Local)
lm3 <- lm(logW~logL*fsites,data=LTcond)
```

The analysis of variable table is constructed by submitting the saved lm object to anova() as such
```{r anova condition LT across sites}
anova(lm3)
```

These results indicate that the interaction terms is significant (p = 
0.008697). There is evidence to conclude that there is difference in slopes in the length-weight relationship between years. The p-value for the indicator variable suggests that there is a difference in intercepts between the three sites (p = 1.193e-13). 

Plots and confidence intervals should be constructed for the model with the interaction term, as it was significant. The confidence intervals, constructed with:
```{r confint condition LT across sites}
confint(lm3)
par(mfrow=c(1,1))
fitPlot(lm3,xlab="log frozen length (mm)",ylab="log weight (g)",legend="topleft",main="", col=adjustcolor(c("red","blue","grey"), alpha.f = .5))
```

### Conclusion: a and b parameters
In <a href=http://www.dnr.state.mi.us/publications/pdfs/ifr/manual/smii%20chapter17.pdf> Schneider et al 2010 report for Michigan Department of Natural Resources</a>, growth parameter are reported for Lake Trout:  
  *  a= -5.519  
  *  b= 3.17882  
_Warning:_ These parameters are not on original scale.  
We found (see results for lm1):  <br>
  * a= -5.578692 
  * b= 3.225599  
So not too far off.  

To convert them to the initial equation W = aL<sup>b</sup>:  
```{r conclusion a and b parameters for LT}
(a= exp(lm1$coefficients[1]))
(b= lm1$coefficients[2])
```

Year and sites were significant when we tested for interaction: I should probably use parameter for one year and one site? Or on the contrary, we're aware there's some differences but it's more relevant to average them out by using several years.

## Growth equations

### Coding functions

#### Fulton's condition factor
Because of assumed isometric growth, comparisons should be limited to fish of similar length (small size range) so slope is zero 
(in other words, condition does not increase with age)

It means we should calculate a and b for smaller bin sizes, get the K for the ideal fish (K=1), then compare fish from the same bin sizes to that K

Below, I wrote a function to compute Fulton's factor ($K = W/L^3$) for different bin sizes. The function is called *Compute_FultonK*.

#### Relative condition factor

I also wrote a function to compute relative condition factor.
$K_n = W/W'$
W' is the predicted weight for a population (using a and b factors). It compensates for allometric growth. The average for a given species is 1.0.


The function is called *RelCond_Fisheries*.

#### Relative weigth

Below, I wrote a function to compute relative weight.
$Wr = W/Ws * 100$
Ws is a species-specific standard based on W = aLb


The function is called* RelWeight_Fisheries*. The argument *size_limits* allows to calculate the factor only for a range of the population (user must enter a vector of 2 values).

### Fulton's condition factor K

```{r use function Compute_FultonK, echo=FALSE, message=FALSE, warning=FALSE}

Fult1 <- Compute_FultonK(pop_ID = LTcond$Trawl.Id,
                pop_weight = LTcond$weight,
                pop_length = LTcond$tl.mm/10,
                bin_limits = seq(0,800, by = 100))
Fult2 <- Compute_FultonK(pop_ID = LTcond$Trawl.Id,
                pop_weight = LTcond$weight,
                pop_length = LTcond$tl.mm/10,
                bin_limits = seq(0,800, by = 800))
Fult3 <- Compute_FultonK(pop_ID = LTcond$Trawl.Id,
                pop_weight = LTcond$weight,
                pop_length = LTcond$tl.mm/10,
                bin_limits = seq(0,800, by = 400))
grid.arrange(Fult1$plot_KL,Fult2$plot_KL,Fult3$plot_KL, nrow=1)
# Fult4 <- Compute_FultonK(pop_ID = LTcond$Trawl.Id[which(LTcond$tl.mm>100 & LTcond$tl.mm <400)],
#                 pop_weight = LTcond$weight[which(LTcond$tl.mm>100 & LTcond$tl.mm <400)],
#                 pop_length = LTcond$tl.mm[which(LTcond$tl.mm>100 & LTcond$tl.mm <400)]/10,
#                 bin_limits = seq(0,800, by = 20))
# Fult4$plot_KL
# Fult4$Growth_parameters
Fult5 <- Compute_FultonK(pop_ID = LTcond$Trawl.Id[which(LTcond$tl.mm>100 & LTcond$tl.mm <400)],
                pop_weight = LTcond$weight[which(LTcond$tl.mm>100 & LTcond$tl.mm <400)],
                pop_length = LTcond$tl.mm[which(LTcond$tl.mm>100 & LTcond$tl.mm <400)]/10,
                bin_limits = seq(0,800, by =800), 
                outliers = 1865)
#Fult5$plot_KL
Fult6 <- Compute_FultonK(pop_ID = LTcond$Trawl.Id[which(LTcond$tl.mm>100 & LTcond$tl.mm <400)],
                pop_weight = LTcond$weight[which(LTcond$tl.mm>100 & LTcond$tl.mm <400)],
                pop_length = LTcond$tl.mm[which(LTcond$tl.mm>100 & LTcond$tl.mm <400)]/10,
#                bin_limits = c(100,120,150, 190,280,400), 
                bin_limits = c(100,120,150, 220,280,400), 
                outliers = 1865)
#Fult6$plot_KL
#Fult6$plot_WL
grid.arrange(
  Fult5$plot_WL,
  Fult5$plot_WL_log,
  Fult5$plot_KL,
  Fult6$plot_WL,
  Fult6$plot_WL_log,
  Fult6$plot_KL, ncol=3,widths=c(1,1,1.5))

# grid.arrange(
#   Fult5$plot_WL,
#   Fult5$plot_KL,
#   Fult6$plot_WL,
#   Fult6$plot_KL, ncol=2)


```

### Relative condition factor

Get relative condition factor:
```{r use function RelCondLT}
RelCondLT <- RelCond_Fisheries(pop_ID = LTcond$Trawl.Id,
                pop_weight = LTcond$weight,
                pop_length = LTcond$tl.mm/10)
grid.arrange(RelCondLT$plot_WL_log, RelCondLT$plot_KnL, ncol=2, widths=c(1,1.5))

# RelCondLT$Data[which(RelCondLT$Data$Kn>1.6),]
# RelCondLT$a
# RelCondLT$b

```
<br>`r fig_cap("relative cond LT", "Weight:length relationship (log10 scale) and relative condition factor for lake trout collected in Lake Champlain, over the 2016-2018 field seasons")`<br>

### Relative weigth

Get relative weight:
```{r use function RelWeightLT}
RelWeightLT <- RelWeight_Fisheries(pop_ID = LTcond$Trawl.Id,
                pop_weight = LTcond$weight,
                pop_length = LTcond$tl.mm/10,
                a=0.00741,
                b=3.04,
                source="https://www.fishbase.se/Summary/SpeciesSummary.php?ID=248&AT=lake+trout")
RelWeightLT$plot_WrL + geom_hline(yintercept = mean(RelWeightLT$Data$Wr), colour="coral", lty=2) 

```
<br>`r fig_cap("relative weight LT", "Relative weigth for lake trout collected in Lake Champlain, over the 2016-2018 field seasons, compared to growth parameters reported on fishbase for Salvelinus namaycush in North America.")`

a and b parameters have been collected on fishbase, <a href="`r RelWeightLT$source_a_b_param`">link</a>.


## Target catch and bycatch

### Read and explore data {.tabset}

First, import the data. They are all kept in different files, so that need to be processed a little bit. <br> 
[code hidden to save room on the .html] 
```{r read data catch, message=FALSE, warning=FALSE, include=FALSE}
# Read data
# target catch
tg16 <- read.delim(paste0(getpath4data(), "data_from_Pascal/LT_2016_targetcatch.txt"));tg16$notes <- rep(NA, nrow(tg16))
tg17 <- read.delim(paste0(getpath4data(), "data_from_Pascal/LT_2017_targetcatch.txt"))
tg18 <- read.delim(paste0(getpath4data(), "data_from_Pascal/LT_2018_targetcatch.txt"))
# bycatch
byc16 <- read.delim(paste0(getpath4data(),"data_from_Pascal/LT_2016_bycatch.txt"))
byc17 <- read.delim(paste0(getpath4data(),"data_from_Pascal/LT_2017_bycatch.txt"))
byc18 <- read.delim(paste0(getpath4data(),"data_from_Pascal/LT_2018_bycatch.txt"))

# merge dataframe
tg <- merge(t(tg17),t(tg16), by = "row.names", all = T)
  rownames(tg) <- tg[,grep("Row.names", colnames(tg))]
  tg <- tg[,-grep("Row.names", colnames(tg))]
tg <- merge(t(tg18),tg, by = "row.names", all = T)
  rownames(tg) <- tg[,grep("Row.names", colnames(tg))]
  tg <- tg[,-grep("Row.names", colnames(tg))]
tg <- as.data.frame(t(tg))
tg <- mutate_all(tg, tolower)
# Check that we have the correct number of rows - two extra, because rownames were added as columns (and then transformed in rows, so two extra rows)
dim(tg)
sum(nrow(tg16)+nrow(tg17)+nrow(tg18))

tg$fyear <- tg$year
tg$year <- as.numeric(paste(tg$year))
tg$netID2 <- paste(tg$year,as.numeric(paste(tg$netID)),sep="_")

date <- as.POSIXlt(tg$date, format = "%d/%m/%Y")
tg$yday <- date$yday
tg <- tg[order(date),]
head(tg)

# Do the same for bycatch
byc <- merge(t(byc17),t(byc16), by = "row.names", all = T)
rownames(byc) <- byc[,grep("Row.names", colnames(byc))]
byc <- byc[,-grep("Row.names", colnames(byc))]
byc <- merge(t(byc18),byc, by = "row.names", all = T)
rownames(byc) <- byc[,grep("Row.names", colnames(byc))]
byc <- byc[,-grep("Row.names", colnames(byc))]
byc <- as.data.frame(t(byc))
byc <- mutate_all(byc, tolower)
# Check that we have the correct number of rows - two extra, because rownames were added as columns (and then transformed in rows, so two extra rows)
dim(byc)
sum(nrow(byc16)+nrow(byc17)+nrow(byc18))

byc$fyear <- byc$year
byc$year <- as.numeric(paste(byc$year))
byc$netID2 <- paste(byc$year,as.numeric(paste(byc$netID)),sep="_")

byc$date <- as.POSIXlt(byc$date, format = "%d/%m/%Y", tz = "")
byc$yday <- byc$date$yday
byc$date <- as.Date(byc$date )
byc <- byc[order(date),]
head(byc)



```


Summary of the target catch and bycatch. Note that for bycatch, a count doesn't represent one individual necesseraly, because sometimes presence was recorded in tote fullness.

```{r summary target and by catch, message=FALSE, warning=FALSE, include=FALSE}
summ_tg <- with(tg, tapply(rep(1,nrow(tg)),list("species#"=species,"Year#"=year), sum))

summ_by <- with(byc, tapply(rep(1,nrow(byc)),list("species#"=species,"Year#"=year), sum))

```

#### Target catch
```{r view target catch, echo=FALSE}
summ_tg
```

#### Bycatch
```{r view bycatch, echo=FALSE}
summ_by
```

### Look more in details at target catch data

The distribution of length is relatively similar one year to the other, with a spreader distribution in 2017. Most fish caught are less than 50 cm long.  

```{r plot target catch length density, echo=FALSE, message=FALSE, warning=FALSE}
tg$tl_mm <- tg$tl_mm  %>% paste() %>% as.numeric()

# mean 
mu <- ddply(tg, "fyear", summarise, grp.mean=mean(tl_mm, na.rm=T))
# Density plot
p <- ggplot(tg, aes(x=tl_mm, fill=fyear)) +
  geom_density()+
  geom_vline(data=mu, aes(xintercept=grp.mean, color=fyear),
             linetype="dashed") +
  geom_density(alpha=0.2) +
  xlab("total length (mm)") + 
  labs(fill='Year')
 ggplotly(p)

```

The variation in length is linked to the capture day of the year, but probably because some species with really different size were caught only then. Year is also a significant explanatory variable. However, there is a lot of noise (very low R<sup>2</sup>).  
```{r explain variation in max total length, echo=FALSE}
lm4a <- lm(tl_mm ~ yday, data=tg)
lm4b <- lm(tl_mm ~ yday*fyear, data=tg)
lm4c <- lm(tl_mm ~ yday*fyear*species, data=tg)
lm4d <- lm(tl_mm ~ yday*species, data=tg)
AIC(lm4a,lm4b,lm4c,lm4d)[order(AIC(lm4a,lm4b,lm4c,lm4d)$AIC),]

```

All AIC are high. Species explain the most, which doesn't come as a surprise: not all species grow as big as the others. 
We're looking at the results of the first model that doesn't include the species (we do not necesseraly want to see how some species are bigger than other here, the idea is to know whether the sampling day in the season or the year have targetted different catch.
There are no strong trend, if larger species were collected on some days, it may have to do with whe zone of the lake that was surveyed instead of actual in-year variation.
The only species with a real trend is sea lamprey. Average size increases by about 200 mm over the season.

```{r summary on model explaining best total length,  echo=FALSE, message=FALSE, warning=FALSE}
summary(lm4b)

ggplot(tg[tg$species=="lake trout"|tg$species=="alewife"|tg$species=="lake whitefish"|tg$species=="rainbow smelt"|tg$species=="sea lamprey"|tg$species=="burbot",], aes(x=yday,y=tl_mm,color=fyear)) + geom_point() + stat_smooth() + facet_wrap(~species)

```

## Extract mortality for LT from only wild data

```{r try looking at mortality in wild LT, include=FALSE}
# create a dataframe with lake trout wild
ltw <- tg[tg$species == "lake trout",]
ltw <- ltw[ltw$fin_clip == "na" | ltw$fin_clip == "nc" ,]
nrow(ltw)

par(mfrow=c(3,1))
hist(ltw$tl_mm[ltw$year==2016], col=adjustcolor("yellow", alpha.f = .4), xlim=c(0,max(ltw$tl_mm, na.rm = T)), xlab="length (mm)", main="2016")
hist(ltw$tl_mm[ltw$year==2017], col=adjustcolor("grey", alpha.f = .4), xlim=c(0,max(ltw$tl_mm, na.rm = T)), xlab="length (mm)", main="2017")
hist(ltw$tl_mm[ltw$year==2018], col=adjustcolor("pink", alpha.f = .4), xlim=c(0,max(ltw$tl_mm, na.rm = T)), xlab="length (mm)", main="2018")
par(mfrow=c(1,1))



```


## Lake Trout diet analysis

Helping Alex with some code, but he'll do the bulk of it (see other .Rmd on diet analysis).  
An example with the size, but he will do the same to look at stomach content. Here, we learn that 40% of our sample of fish smaller than 100mm were sampled in 2016. (but he will repeat it to learn whether size class impact stomach emptyness)

```{r LT diet analysis create size class, echo=FALSE}

# Create the size class in a new column
tg <- tg  %>% mutate(size_class = case_when(
                      tl_mm <= 100 ~ "[0,100]",
        tl_mm > 100 & tl_mm <= 200 ~ "]100,200]", 
        tl_mm > 200 & tl_mm <= 300 ~ "]200,300]",
        tl_mm > 300 & tl_mm <= 400 ~ "]300,400]",
        tl_mm > 400                ~ "]400,∞]"))

# This is a way around since we're not going to use the histogram function (that deals with counts), but histogram instead (we're getting the count another way). Look up the difference between histogram and barplots and let me know if you don't understand it.
# First step, I'm getting here the number of row that correspond to these two factors. You would want to replace 'Year' by 'empty_stomach'. Note that the two columns (size_class and fyear) are factors.
(summ_sc <- with(tg, tapply(rep(1,nrow(tg)),list("Size class"=size_class, "Year"=fyear), sum)))

# Then, to get the percentage of fish with empty stomach per size class, you would do the following:
(summ_sc <- as.data.frame(summ_sc/rowSums(summ_sc, na.rm=T)))
# Here, we learn that 40% of our sample of fish smaller than 100mm were sampled in 2016.

# You can plot the output in a histogram (here I'm only plotting the proportion that was sampled in 2016, you will only plot the proportion were empty_stomach = F).
ggplot(data=summ_sc, aes(x=rownames(summ_sc),y=summ_sc[,1])) +
  geom_bar(stat="identity") + xlab("Size class") + ylab("Percentage") 

```

### Stomach full (Y/N) per size

```{r LT stomach full Y or N, message=FALSE, warning=FALSE, include=FALSE}
LTdiet <- read.delim(paste0(getpath4data(),"data_from_Pascal/LT_diet_2016-2018.txt"))
LTdiet$Total.Length <- as.numeric(paste(LTdiet$Total.Length..mm.))
LTdiet$Start.Depth <- as.numeric(paste(LTdiet$Start.Depth..m.))
LTdiet$Food.in.Stomach..Y.N.
colnames(LTdiet) <- str_replace(colnames(LTdiet), "Food.in.Stomach..Y.N.", "Food.in.Stomach")
summary(LTdiet$Food.in.Stomach)
LTdiet$Food.in.Stomach[LTdiet$Food.in.Stomach=="no"] <- "N"
LTdiet$Food.in.Stomach[LTdiet$Food.in.Stomach=="yes"|LTdiet$Food.in.Stomach=="T"] <- "Y"
summary(LTdiet$Food.in.Stomach)
LTdiet$stock.wild <- ifelse(LTdiet$Clip.Location == "NC", "Wild", "Stocked")

# Create the size class in a new column
LTdiet <- LTdiet  %>% mutate(size_class = case_when(
  Total.Length <= 100 ~ "[0,100]",
  Total.Length > 100 & Total.Length <= 200 ~ "]100,200]", 
  Total.Length > 200 & Total.Length <= 300 ~ "]200,300]",
  Total.Length > 300 & Total.Length <= 400 ~ "]300,400]",
  Total.Length > 400 & Total.Length <= 500 ~ "]400,500]",
  Total.Length > 500 ~ "]500,∞]"))

# First step, I'm getting here the number of row that correspond to these two factors. 
summ_sc <- with(LTdiet, tapply(rep(1,nrow(LTdiet)),list("Size class"=size_class, "Food"=Food.in.Stomach), sum))
(summ_sc <- summ_sc[,colSums(summ_sc, na.rm = T)>0])
summ_sc2 <- melt(summ_sc[,c('Y','N')],id.vars = 1)

# Then, to get the percentage of fish with empty stomach per size class, you would do the following:
(summ_sc_per <- as.data.frame(summ_sc/rowSums(summ_sc, na.rm=T)))

```

Fish above 400 mm have less food in their stomach but thats also the class with the least catch.

```{r percent fish with food in stomach, echo=FALSE, message=FALSE, warning=FALSE}
# You can plot the output in a histogram (here I'm only plotting the proportion that was sampled in 2016, you will only plot the proportion were empty_stomach = F).
p1 <- ggplot(summ_sc2,aes(x = `Size class`,y = value)) + 
    geom_bar(aes(fill = Food),stat = "identity",position = "dodge") + 
     xlab("Size class") + ylab("Number of fish per size class")  +
    theme(legend.position="bottom")
ggplotly(p1)

p2 <- ggplot(data=summ_sc_per, aes(x=rownames(summ_sc_per),y=summ_sc_per[,"Y"])) +
  geom_bar(stat="identity") + xlab("Size class") + ylab("Percentage of individuals with \nat least some food in their stomach") 
ggplotly(p2)
```


### Stomach full (Y/N) per time of sampling

```{r LT stomach fullness per time of sampling create data, message=FALSE, warning=FALSE, include=FALSE}
head(LTeff)
tail(LTdiet)
#load lubridate to handle several date/time format
LTdiet$Capture.Date2 <- parse_date_time(x = LTdiet$Capture.Date,orders = c("d-b-y", "m/d/y", "m/d/Y"))
# 6 without actual sampling date written as "unknown 2016"
```

Here, we need to link diet data to the sampling info (effort dataset).
Some fish (`r length(LTdiet$Capture.Date2[is.na(LTdiet$Capture.Date2)])
`) don't have the sample date available (e.g., line 451-456, it says "unknown 2016"). I'm removing these from the analysis.  

Here, we could match every fish to the effort, using first day of sampling, then starting depth.

```{r LT stomach fullness per time of sampling, message=FALSE, warning=FALSE, include=FALSE}
# Removing the unknown date we can't link back to the effort
LTdiet <- LTdiet[!is.na(LTdiet$Capture.Date2),]

# Match
LTeff$Capture.Date2 <- parse_date_time(x = LTeff$date,orders = c("%Y-%m-%d"))

LTdiet$Hour.sampled <- rep(NA, nrow(LTdiet))
for (i in 1:nrow(LTdiet)) {
  if(i==1) {n1=0;n2=0}
  narrow2day <- LTeff[LTeff$Capture.Date2==LTdiet$Capture.Date2[i],]
  effortdate <- narrow2day[narrow2day$start.depth.m==LTdiet$Start.Depth[i],]
  if(nrow(effortdate)==1) {
    LTdiet$Hour.sampled[i] <- substr(effortdate$start.time,1,2)
    n1 <- n1+1 # for info message
  } else {
      n <- n2+1 # for info message
      }
  # Info message
  if(i==nrow(LTdiet)) message(paste0(" ✓ Found single sampling event for ", n1," of the individuals","\n ✕ No or several sampling events were found for ", n2, " of the individuals" ))
}

LTdiet$Hour.sampled <- as.numeric(paste(LTdiet$Hour.sampled))

# Create class for hour in the day in a new column
min(LTdiet$Hour.sampled, na.rm=T)
max(LTdiet$Hour.sampled, na.rm=T)
LTdiet <- LTdiet  %>% mutate(hour_class = case_when(
  Hour.sampled >= 5 & Hour.sampled <= 6 ~ "5am-6am", 
  Hour.sampled >= 7 & Hour.sampled <= 8 ~ "7am-8am",
  Hour.sampled >= 9 & Hour.sampled <= 10 ~ "9am-10am",
  Hour.sampled >= 10 & Hour.sampled <= 10 ~ "10am-11am", 
  Hour.sampled >= 12 & Hour.sampled <= 13 ~ "12pm-1pm", 
  Hour.sampled >= 14 & Hour.sampled <= 15 ~ "2pm-3pm", 
  Hour.sampled >= 16 & Hour.sampled <= 17 ~ "4pm-5pm"))

# Actually I won't even do it by hour class but just by hour

# First step, I'm getting here the number of row that correspond to these two factors. 
summ_hc <- with(LTdiet, tapply(rep(1,nrow(LTdiet)),list("Hour class"=Hour.sampled, "Food"=Food.in.Stomach), sum, na.rm=T))
(summ_hc <- summ_hc[,colSums(summ_hc, na.rm = T)>0])

# Then, to get the percentage of fish with empty stomach per size class, you would do the following:
(summ_hc <- as.data.frame(summ_hc/rowSums(summ_hc, na.rm=T)))


```

```{r plot percentage of individuals with food in stomach per time of the day, echo=FALSE, message=FALSE, warning=FALSE}
# You can plot the output in a histogram (here I'm only plotting the proportion that was sampled in 2016, you will only plot the proportion were empty_stomach = F).
p1 <- qplot(LTdiet$Hour.sampled,geom="histogram",binwidth = 1,  main = "Number of observations", xlab = "Hour of the day",col=I("white"))
ggplotly(p1)

p1 <- ggplot(data=summ_hc, aes(x=as.numeric(rownames(summ_hc)),y=summ_hc[,"Y"])) +
  geom_bar(stat="identity") + xlab("Time of the day") + ylab("Percentage of individuals with \nat least some food in their stomach") 
ggplotly(p1)


```


### Stomach contents for all Lake Trout

Here is a distribution of the food items preyed upon by lake trout. Some of the most common food items include alewife, mysus, and daphnia, which make up over 58.3% of their diet. The next sections will break down their diet for each length class. The "other" category contributes over 35.6% of the lake trout's diet, so there's a large portion of their diet that was unidentified.

```{r as numeric for stomach content and visualisation, echo=FALSE, message=FALSE, warning=FALSE}
LTdiet$Smelt <- as.numeric(LTdiet$Smelt)
LTdiet$Smelt.YOY <- as.numeric(LTdiet$Smelt.YOY)
LTdiet$Alewife <- as.numeric(LTdiet$Alewife)
LTdiet$Alewife.YOY <- as.numeric(LTdiet$Alewife.YOY)
LTdiet$Sculpin <- as.numeric(LTdiet$Sculpin)
LTdiet$Sculpin.YOY <- as.numeric(LTdiet$Sculpin.YOY)
LTdiet$YOY <- as.numeric(LTdiet$YOY)
LTdiet$Mysis <- as.numeric(LTdiet$Mysis)
LTdiet$Yellow.Perch <- as.numeric(LTdiet$Yellow.Perch)
LTdiet$Unidentifiable.Fish <- as.numeric(LTdiet$Unidentifiable.Fish)
LTdiet$Daphnia <- as.numeric(LTdiet$Daphnia)
LTdiet$Copepod <- as.numeric(LTdiet$Copepod)
LTdiet$zoops <- as.numeric(LTdiet$zoops)
LTdiet$Spiny.Water.Flea <- as.numeric(LTdiet$Spiny.Water.Flea)
LTdiet$Trout.perch <- as.numeric(LTdiet$Trout.perch)
LTdiet$Tess..Darter <- as.numeric(LTdiet$Tess..Darter)
LTdiet$Macroinvert <- as.numeric(LTdiet$Macroinvert)
LTdiet$fishes <- as.numeric(LTdiet$fishes)
LTdiet$Other <- as.numeric(LTdiet$Other)

sumFoods <- colSums(LTdiet[, 21:39], na.rm = FALSE, dims = 1)
sumFoods <- sumFoods[!is.na(sumFoods)]
contents.all <- as.data.frame(sumFoods)
ID <- rownames(contents.all)
propFoods <- sumFoods / sum(sumFoods) * 100

contents.all <- data.frame(sumFoods, propFoods, ID)

diet.total <- ggplot(data = contents.all, mapping = aes(x = "", y = propFoods, fill = contents.all$ID)) +
  geom_bar(stat = "identity") +
  theme(axis.title.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(y = "Proportion of Total Diet", fill = "Food Item")

ggplotly(diet.total)
```

### Stomach Contents for Each Length Class

I'm creating six different bar plots to show the distribution of feeding patterns for each of the size classes we created earlier. From a quick glance at the outputs, it appears that lake trout of larger size tend to consume more alewife. In addition, longer lake trout tend to utilize smelt more than smaller lake trout. LT of smaller sizes utilize mysis and zooplankton much more than lake trout of larger size as well. It appears their diet shifts from small items such as mysis and zooplankton early on in their life to larger prey items such as smelt and alewife. 

And just a note for all of us, there are much more efficient ways of obtaining what I wanted here. However, I'm not that advanced! Rosalie has created code with a loop that is much more concise and accomplishes the same thing, but for now, this will do.

<span style="color:red">Note from Rosalie: Hey, it's impressive you've learned so much in 7 months! 80% of being a researcher seems to be about not giving up based on my experience.</span>


```{r contents.by.size_class, echo=FALSE}
# I'm first creating column sums for each of the prey items. 
sumFoods_0_100 <- colSums(LTdiet[which(LTdiet$size_class == "[0,100]"), 21:39], na.rm = FALSE, dims = 1)
sumFoods_100_200 <- colSums(LTdiet[which(LTdiet$size_class == "]100,200]"), 21:39], na.rm = FALSE, dims = 1)
sumFoods_200_300 <- colSums(LTdiet[which(LTdiet$size_class == "]200,300]"), 21:39], na.rm = FALSE, dims = 1)
sumFoods_300_400 <- colSums(LTdiet[which(LTdiet$size_class == "]300,400]"), 21:39], na.rm = FALSE, dims = 1)
sumFoods_400_500 <- colSums(LTdiet[which(LTdiet$size_class == "]400,500]"), 21:39], na.rm = FALSE, dims = 1)
sumFoods_500_up <- colSums(LTdiet[which(LTdiet$size_class == "]500,∞]"), 21:39], na.rm = FALSE, dims = 1)

# I'm placing these sums in a data frame for now, so I can obtain row names for the next little code chunk. 
contents.all.SC <- data.frame(sumFoods_0_100, sumFoods_100_200, sumFoods_200_300, sumFoods_300_400, sumFoods_400_500, sumFoods_500_up)

# Now I'm obtaining the prey ID's so I can eventually use them as a filter in my barplots. 
Food.ID <- rownames(contents.all.SC)

# I'm now calculating percentages of each of the prey items for each size class. 
propFoods_0_100 <- sumFoods_0_100 / sum(sumFoods_0_100, na.rm = TRUE) * 100
propFoods_100_200 <- sumFoods_100_200 / sum(sumFoods_100_200, na.rm = TRUE) * 100
propFoods_200_300 <- sumFoods_200_300 / sum(sumFoods_200_300, na.rm = TRUE) * 100
propFoods_300_400 <- sumFoods_300_400 / sum(sumFoods_300_400, na.rm = TRUE) * 100
propFoods_400_500 <- sumFoods_400_500 / sum(sumFoods_400_500, na.rm = TRUE) * 100
propFoods_500_up <- sumFoods_500_up / sum(sumFoods_500_up, na.rm = TRUE) * 100

# Tossing in the proportions as well as prey ID into the data frame. 
contents.all.SC <- data.frame(sumFoods_0_100, propFoods_0_100, sumFoods_100_200, propFoods_100_200, sumFoods_200_300, propFoods_200_300, sumFoods_300_400, propFoods_300_400, sumFoods_400_500, propFoods_400_500, sumFoods_500_up, propFoods_500_up, Food.ID)

# Making sure all of the NAs in the data frame are 0, because ggplot doesn't like creating graphs with NAs.
contents.all.SC[is.na(contents.all.SC)] <- 0

# Barplot for 0-100 size class.
barplot_0_100 <- ggplot(data = contents.all.SC, mapping = aes(x = "", y = propFoods_0_100, fill = contents.all.SC$Food.ID)) +
  geom_bar(stat = "identity") +
  theme(axis.title.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(y = "Proportion of Total Diet", fill = "Food Item", title = "[0-100]")

# Barplot for 101-200 size class.
barplot_100_200 <- ggplot(data = contents.all.SC, mapping = aes(x = "", y = propFoods_100_200, fill = contents.all.SC$Food.ID)) +
  geom_bar(stat = "identity") +
  theme(axis.title.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(y = "Proportion of Total Diet", fill = "Food Item", title = "]100-200]")

# Barplot for 201-300 size class. 
barplot_200_300 <- ggplot(data = contents.all.SC, mapping = aes(x = "", y = propFoods_200_300, fill = contents.all.SC$Food.ID)) +
  geom_bar(stat = "identity") +
  theme(axis.title.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(y = "Proportion of Total Diet", fill = "Food Item", title = "]200-300]")

# Barplot for 301-400 size class. 
barplot_300_400 <- ggplot(data = contents.all.SC, mapping = aes(x = "", y = propFoods_300_400, fill = contents.all.SC$Food.ID)) +
  geom_bar(stat = "identity") +
  theme(axis.title.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(y = "Proportion of Total Diet", fill = "Food Item", title = "]300-400]")

# Barplot for 401-500 size class. 
barplot_400_500 <- ggplot(data = contents.all.SC, mapping = aes(x = "", y = propFoods_400_500, fill = contents.all.SC$Food.ID)) +
  geom_bar(stat = "identity") +
  theme(axis.title.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(y = "Proportion of Total Diet", fill = "Food Item", title = "]400-500]")

# Barplot for 501 and up size class. 
barplot_500_up <- ggplot(data = contents.all.SC, mapping = aes(x = "", y = propFoods_500_up, fill = contents.all.SC$Food.ID)) +
  geom_bar(stat = "identity") +
  theme(axis.title.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(y = "Proportion of Total Diet", fill = "Food Item", title = "]500-∞]")

# Converting all of my ggplot outputs to ggplotly outputs so the users can be interactive with the outputs. 
ggplotly(barplot_0_100)
ggplotly(barplot_100_200)
ggplotly(barplot_200_300)
ggplotly(barplot_300_400)
ggplotly(barplot_400_500)
ggplotly(barplot_500_up)
```


### Stomach Contents in the Main Lake

Share of the diet for main lake. <br>
/!\\ no age class distinction here.

```{r contents.by.location}
# Creating a new variable called Lake.Segment based on the capture location. Segments determined from epa.gov document. Hill Bay and Central Lake, NY locations were unidentified on Google Maps, and were therefore placed in the "Unknown" lake segment. 
LTdiet <- LTdiet %>% mutate(Lake.Segment = case_when(Capture.Location == "Au Sable Point" ~ "Main Lake",
                                    Capture.Location == "Boquet Bay" ~ "Main Lake",
                                    Capture.Location == "Boquet Delta to Essex" ~ "Main Lake",
                                    Capture.Location == "Boquet River" ~ "Main Lake",
                                    Capture.Location == "Boquet River Delta" ~ "Main Lake",
                                    Capture.Location == "Burlington Bay" ~ "Main Lake",
                                    Capture.Location == "Burlington Bay Far" ~ "Main Lake",
                                    Capture.Location == "Burlington Far" ~ "Main Lake",
                                    Capture.Location == "Essex" ~ "Main Lake",
                                    Capture.Location == "Essex  " ~ "Main Lake",
                                    Capture.Location == "Essex to Bouquet Delta" ~ "Main Lake",
                                    Capture.Location == "Essex, NY" ~ "Main Lake",
                                    Capture.Location == "Essex, NY to Whallon" ~ "Main Lake",
                                    Capture.Location == "Jackson Point" ~ "Main Lake",
                                    Capture.Location == "Port Kent" ~ "Main Lake",
                                    Capture.Location == "Providence Island" ~ "Main Lake",
                                    Capture.Location == "Rockwell" ~ "Main Lake",
                                    Capture.Location == "Rockwell Bay" ~ "Main Lake",
                                    Capture.Location == "South Hero- Jackson Pt" ~ "Main Lake",
                                    Capture.Location == "South Hero- Rockwell Bay" ~ "Main Lake",
                                    Capture.Location == "South Hero-Jackson Pt" ~ "Main Lake",
                                    Capture.Location == "Trembleau Point" ~ "Main Lake",
                                    Capture.Location == "Valcour" ~ "Main Lake",
                                    Capture.Location == "Whallon" ~ "Main Lake",
                                    Capture.Location == "Whallon Bay" ~ "Main Lake",
                                    Capture.Location == "Whallon-Essex" ~ "Main Lake",
                                    Capture.Location == "Wilcox" ~ "Main Lake",
                                    Capture.Location == "Willsboro Bay, NY" ~ "Main Lake",
                                    Capture.Location == "Winooski" ~ "Main Lake"))

# Summing up food items for each lake segment.
sumFoods_MainLake <- colSums(LTdiet[which(LTdiet$Lake.Segment == "Main Lake"), 21:39], na.rm = FALSE, dims = 1)

# Converting sums to proportions of total diet.
propFoods_MainLake <- sumFoods_MainLake / sum(sumFoods_MainLake, na.rm = TRUE) * 100

# Creating a data frame with all sums and proportions.
contents.lake.segment <- data.frame(sumFoods_MainLake, propFoods_MainLake)

# Making sure all of my NAs are 0's again.
contents.lake.segment[is.na(contents.lake.segment)] <- 0

# Barplot for diet distribution in Main Lake. 
barplot_MainLake <- ggplot(data = contents.lake.segment, mapping = aes(x = "", y = propFoods_MainLake, fill = contents.all.SC$Food.ID)) +
  geom_bar(stat = "identity") +
  theme(axis.title.x = element_blank(), axis.ticks.x = element_blank()) +
  labs(y = "Proportion of Total Diet", fill = "Food Item", title = "Main Lake")

# Converting ggplot outputs to ggplotly outputs. 
ggplotly(barplot_MainLake)

```

# Atlantic Salmon

# Burbot

Maybe extract data from whole dataset sent by Bernie Pientka?

```{r read gillnet data and extract burbot data then run some early analyses, message=FALSE, warning=FALSE, include=FALSE}
gillnet <- read.delim(paste0(getpath4data(), "data_from_Bernie/Gillnetdata82-97-updated 2-20-20.txt"))
head(gillnet)

summary(gillnet$SPECIES)

burbot <- gillnet[gillnet$SPECIES==493,]
head(burbot)  

ggplot(burbot, aes(YEARSET, LENGTH, col=DAYSET)) + geom_point(alpha=.4) +
  geom_smooth() + facet_wrap(~MESHSIZE, scales="free")
  theme_bw()

summary(as.factor(burbot$MESHSIZE))

burbot$Date <- as.Date(paste(burbot$DAYSET, burbot$MONTHSET, burbot$YEARSET, sep="-"), format = "%d-%m-%y")

summary(as.factor(burbot$YEARSET))

any(is.na(burbot$NET))
any(is.na(burbot$MESHSIZE))



#Just checking whether each net as a different net_size associated
burbot$NET_MESHSIZE <- paste(burbot$NET,burbot$MESHSIZE,sep="_")
other_var <- aggregate(data=burbot, NET_MESHSIZE ~ NET, function(x) length(unique(x)))

head(other_var)
# Yes, because otherwise NET_MESHSIZE ~ NET should be equal to 1 
# Example for NET == 08:
burbot$NET_MESHSIZE[burbot$NET==08]



# Getting metadata, the number of observations per net and per date set.
burbot_mt <- as.data.frame(with(burbot, tapply(rep(1, nrow(burbot)),list("Date"=Date,"Net"=NET_MESHSIZE), sum, na.rm=T)))

# Creating a Year column
burbot_mt$Year <- as.numeric(substr(rownames(burbot_mt),1,4))

# Melt the data
burbot_mt <- cbind("Date"=rep(rownames(burbot_mt, ncol(burbot_mt))),melt(burbot_mt, id.vars  = "Year", variable.name = "Net"))
# Remove NAs: net were never all used at once
burbot_mt <- burbot_mt[!is.na(burbot_mt$value),]
# Reorder by date
burbot_mt <- burbot_mt[order(burbot_mt$Date),]

# Structure of the data: Date, Year, Net, and the number of burbot caught per net.
head(burbot_mt)

summary(as.factor(burbot_mt$Year))
summary(burbot_mt$value)


```


## Number of burbot caught

Data about burbot come from Gillnet surveys, carried out between 19`r paste(min(gillnet$YEARPULL, na.rm=T), max(gillnet$YEARPULL, na.rm=T), sep="-19")`. Species code for burbot is 493.

`r nrow(burbot)` burbot were collected over this period.

There is a column in the dataset called "NET", are these the individual net used? Can I use them to calculate the effort? The number of fish caught per net varies between `r min(burbot_mt$value)` and `r max(burbot_mt$value)`


```{r explore metadata of catch for burbot, echo=FALSE, message=FALSE, warning=FALSE}
# Plot showing the number of burbot per net.
ggplot(burbot_mt, aes(as.factor(Year),value)) + geom_boxplot() +
  labs(x = "Year", y = "Number of burbot per net") +
  theme_bw() + labs(subtitle="Distribution of the number of burbot caught per year and per net. \nFrom 1990, more burbot are caught per net. Have effort and mesh size changed?")

#ggsave(paste0(getwd(),"/Output/Figures/11-Burbot/Number_burbot_per_net_per_year.pdf"), width=6, height=3.7)

```
<br>`r fig_cap("burbot year", caption = "Distribution of the number of burbot caught per year and per net. From 1990, more burbot are caught per net. Have effort and mesh size changed?")`

Look more into details at the net used.

There is a positive, linear relationship, between number of burbot caught and number of net set.

```{r look at number of burbot caught per net set per year et al, echo=FALSE, message=FALSE, warning=FALSE}
# Create a summary of the number of nets set per date
number_nets <- aggregate(data=burbot_mt, Net ~ Date, function(x) length(unique(x)))
number_nets$Year <- as.numeric(substr(number_nets$Date,1,4))
head(number_nets)
# Then summarize per year the number of nets set
number_nets <- aggregate(data=number_nets, Net ~ Year, function(x) sum(x))
colnames(number_nets)[2] <- "Number_net_set_that_year"
head(number_nets)

# Add as variable the total number of fish caught per year
other_var <- aggregate(data=burbot_mt, value ~ Year, function(x) sum(x))
colnames(other_var)[2] <- "Number_burbot_caught"
number_nets <- merge(number_nets, other_var, by="Year", all=TRUE)

# Add as variable the total number of day fished
other_var <- aggregate(data=burbot_mt, Date ~ Year, function(x) length(unique(x)))
colnames(other_var)[2] <- "Number_day_nets_were_set"
number_nets <- merge(number_nets, other_var, by="Year", all=TRUE)

# Add as variable the total number of day fished
other_var <- aggregate(data=burbot_mt, Net ~ Year, function(x) length(unique(x)))
colnames(other_var)[2] <- "Number_different_nets_used_that_year"
number_nets <- merge(number_nets, other_var, by="Year", all=TRUE)

head(number_nets)

number_nets2 <- melt(number_nets, id.vars  = c("Year", "Number_burbot_caught"))
head(number_nets2)

ggplot(number_nets2, aes(value,Number_burbot_caught, color=Year)) + 
  geom_smooth() +
  geom_point() +
  facet_wrap(~variable, scales = "free_x", 
             labeller = as_labeller(c(Number_net_set_that_year = "Number net set", Number_day_nets_were_set = "Number day at least one \nnet was set", Number_different_nets_used_that_year = "Number different nets \nused that year") ) ) +
  xlab(NULL) +
  ylab("Number of burbot caught") +
  geom_text(mapping = aes(value,Number_burbot_caught, label=Year), nudge_y = 40, check_overlap = T)  +
  theme_bw()
#ggsave(paste0(getwd(),"/Output/Figures/11-Burbot/Number_burbot_per_various_params.pdf"), width=9, height=3.7)

```
<br>`r fig_cap("burbot net", caption = "Number of burbot caught over the year as a function of number of net that were use. It does not account.")`


```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(number_nets, aes(Year,Number_burbot_caught/Number_net_set_that_year)) + 
  geom_smooth() +
  geom_point() +
  labs(x = "Year", y = "Number of burbot caught / \nnumber of net set that year", subtitle = "Ratio of number of burbot caught per number of net set") +
  #geom_text(mapping = aes(Net,value, label=Year), nudge_x = 5, check_overlap = T)  +
  theme_bw()
#ggsave(paste0(getwd(),"/Output/Figures/11-Burbot/Number_burbot_caught_per_net_per_year.pdf"), width=4.7, height=3)

```
<br>`r fig_cap("burbot net per year", caption = "Ratio of number of burbot caught per number of net set.")`


## Size of burbot caught

Look at the size distribution of burbot, and compare that with mesh-size.

```{r looking at burbot size and meshsize, echo=FALSE, message=FALSE, warning=FALSE}

p1 <- ggplot(burbot, aes(MESHSIZE, LENGTH)) + geom_point() + 
  labs(x = "Mesh size (mm)", y = "Individual length (mm)",
       subtitle = "a. Individual length per mesh size ") + 
  theme_bw()

p2 <- ggplot(burbot, aes(LENGTH, WEIGHT)) + stat_smooth() +
  geom_point() + 
  labs(x = "Length (mm)", y = "Weight (g) ",
       subtitle=paste0("b. Weight length relationship for n = ", nrow(burbot[!is.na(burbot$WEIGHT) & !is.na(burbot$LENGTH),]), " individuals")) + 
  theme_bw()

p3 <- ggplot(burbot, aes(YEARPULL, LENGTH)) + stat_smooth() +
  geom_point(size=(log(burbot$MESHSIZE)-2.7)*3,
             alpha=.2) + 
  labs(x="Year", y="Length (mm)",subtitle=paste0("c. Length of burbot per year. Size of points \nrefers to mesh size (min = ",min(burbot$MESHSIZE, na.rm=T), " mm, max = ",max(burbot$MESHSIZE, na.rm=T)," mm).")) + 
  theme_bw()

(p1 / p2 / p3)

#ggsave(paste0(getwd(),"/Output/Figures/11-Burbot/Burbot_various_stats.pdf"), width=4.7, height=7)

```
<br>`r fig_cap("various stats burbot", caption = "Various stats for burbot data. (a) Individual length per mesh size. (b) Weight/length relationship for individuals with both data available. (c) Evolution of length over the year.")`

Look at the number of fish caught per mesh size 

```{r same process that for metadata but this time with length}
# Getting metadata, the number of observations per net and per date set.
burbot_mt_length <- as.data.frame(with(burbot, tapply(LENGTH,list("Date"=Date,"Net"=NET_MESHSIZE), mean, na.rm=T)))

# Creating a Year column
burbot_mt_length$Year <- as.numeric(substr(rownames(burbot_mt_length),1,4))

# Melt the data
burbot_mt_length <- cbind("Date"=rep(rownames(burbot_mt_length, ncol(burbot_mt_length))),melt(burbot_mt_length, id.vars  = "Year", variable.name = "Net"))
# Remove NAs: net were never all used at once
burbot_mt_length <- burbot_mt_length[!is.na(burbot_mt_length$value),]
# Reorder by date
burbot_mt_length <- burbot_mt_length[order(burbot_mt_length$Date),]

# Structure of the data: Date, Year, Net, and the number of burbot caught per net.
head(burbot_mt_length)

burbot_mt_length$MESHSIZE <- as.numeric(paste(substr(burbot_mt_length$Net, nchar(as.character(burbot_mt_length$Net))-1,nchar(as.character(burbot_mt_length$Net)))))

summary(as.factor(burbot_mt_length$Year))
summary(burbot_mt_length$value)

ggplot(burbot_mt_length, aes(MESHSIZE, value)) + geom_point()

```


# Lamprey

Note: some data are available in FSAdata -- SLampreyGL: Stock and recruitment data for Sea Lamprey in the Great Lakes, 1997-2007.

```{r read sea lamprey data, include=FALSE}
trap <- read.delim(paste0(getpath4data(), "data_from_Brad_Young/sea_lamprey_trapping_data.txt"))
trap$River[trap$River=="Rea"] <- "Rea  NY"
trap_annual_summ <- read.delim(paste0(getpath4data(), "data_from_Brad_Young/annual_trapping_summary.txt"))
wound <- read.delim(paste0(getpath4data(), "data_from_Brad_Young/wounding_LAT_LAS.txt"))
annual_survey <- read.delim(paste0(getpath4data(), "data_from_Brad_Young/sea_lamprey_survey_data.txt"))
annual_survey[,2] <- as.numeric(paste(annual_survey[,2]))
annual_survey[,3] <- as.numeric(paste(annual_survey[,3]))
annual_survey[,4] <- as.numeric(paste(annual_survey[,4]))
```

```{r comparing summary data given by Brad Young and summury data from trap dataset}
sl_trap_summ <- data.frame("Name"=unique(trap$River))
# Saving which rows have been matched
sl_trap_summ$Row_matched <- rep(NA,nrow(sl_trap_summ))
# Saving the name that have been matched
sl_trap_summ$Name_matched <- rep(NA,nrow(sl_trap_summ))
# Saving the number of matches
sl_trap_summ$Number_matched <- rep(NA,nrow(sl_trap_summ))

unique_name <- seq_along(trap_annual_summ$Name)
for(i in seq_along(sl_trap_summ$Name)) {
  fuzzy_match <- 
    agrep(sl_trap_summ$Name[i],trap_annual_summ$Name,
          max = 3, ignore.case = TRUE)
  #fuzzy_match <- fuzzy_match[-which(fuzzy_match==i)]
  unique_name <- unique_name[!unique_name %in% fuzzy_match]
  if(length(fuzzy_match)>0) {
    sl_trap_summ$Row_matched[i] <- paste(fuzzy_match,collapse="-")
    sl_trap_summ$Name_matched[i] <- paste(trap_annual_summ$Name[fuzzy_match],collapse=", ")
    sl_trap_summ$Number_matched[i] <- length(fuzzy_match)     
  }
}
sl_trap_summ
trap_annual_summ$Name[unique_name]

trap_annual_summ_RB <- as.data.frame(with(trap[!is.na(trap$length),], tapply(rep(1, nrow(trap[!is.na(trap$length),])),list("Year"=Year,"River"=River), sum, na.rm=T)))
rowSums(trap_annual_summ_RB, na.rm=T)
ncol(trap_annual_summ_RB)
colnames(trap_annual_summ_RB)
trap_annual_summ$Name
trap_annual_summ[trap_annual_summ$Name=="Total_Aaron",3:(ncol(trap_annual_summ)-1)] - rowSums(trap_annual_summ_RB, na.rm=T)[rownames(trap_annual_summ_RB)%in%2001:2017]
trap_annual_summ[trap_annual_summ$Name=="TOTAL",3:(ncol(trap_annual_summ)-1)] - rowSums(trap_annual_summ_RB, na.rm=T)[rownames(trap_annual_summ_RB)%in%2001:2017]



```


## Wounding 
Lake Champlain salmonids presented a high rate of woundings which motivated the long-term sea lamprey control program, operated by VTFWS. The figure below shows the evolution of wounding per 100 fish.
```{r wounding by sea lamprey, echo=FALSE, message=FALSE, warning=FALSE}
p <- ggplot(melt(wound, id.vars='Year'), aes(Year, value, fill=variable)) +
  geom_bar(stat="identity", position=position_dodge()) + 
  geom_text(aes(label=value), vjust=1.6, hjust=c(rep(1.3,16), rep(-0.3,16)), color="black", size=2.7) + 
  ylab("Sea Lamprey wounds per 100 fish") + 
  scale_fill_manual(values=c('#999999','#5ab4ac'),name = "Species",  labels = c("Lake Trout \n(533-633 mm)", "Atlantic Salmon \n(432-533 mm)")) +
  theme_bw() +
  scale_x_continuous("Year", labels = as.character(wound$Year), breaks = wound$Year)

p + 
  geom_hline(aes(yintercept = 25, colour = "Lake Trout goal"), color='black', lty=2,show.legend = F) + 
  geom_hline(aes(yintercept = 15, colour = "Atlantic Salmon goal"), color='black', lty=3,show.legend = F) +
  geom_text(aes(x=2003,y=25, label="Lake trout goal"),hjust = 0, vjust=1.2) +
  geom_text(aes(x=2003,y=15, label="Atlantic salmon goal"),hjust = 0, vjust=1.2)

#ggsave(paste0(getwd(),"/Output/Figures/8-SeaLamprey/Wounding_sea_lamprey.pdf"), width=10, height=4.7)

```
<br>`r fig_cap("woundings per salmonid", "Lake Champlain Sea Lamprey Wounds per 100 fish")`



## Management of sea lamprey population
Work on trapping data.
`r fig_cap("total catch vs. number surveys", "Total number of lamprey caught versus the total number of year surveyed. Note that sometimes sites with a same name were sampled twice a year (for example, Lewis Stream was sampled twice in 2005, 2009, 2013. Reach 1: Mouth to falls in North Ferrisburgh, Reach 2: falls to Scott Dam). The actual number of surveys may be higher.", display= FALSE)`

```{r working on trapping data, echo=FALSE}
trap$Date <- as.Date(trap$Date, format="%d-%b-%Y")
summary(trap)

trap_summ <- as.data.frame(with(trap, tapply(rep(1,nrow(trap)),list("Year"=Year, "River"=River), sum, na.rm=T)))


trap_summ2 <- data.frame("Total.catch"=colSums(trap_summ,na.rm = T),
                         "Number.surveys"=sapply(trap_summ, function(x) sum(!is.na(x))))
trap_summ2 <- trap_summ2[order(trap_summ2$Total.catch, decreasing = TRUE),]

ggplot(trap_summ2, aes(rownames(trap_summ2),Total.catch, fill=trap_summ2$Number.surveys)) +
  geom_bar(stat="identity", position=position_dodge()) +  labs(x="Stations", y="Number lamprey caught", fill = "Number of years surveyed") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position="bottom",
        panel.background = element_rect(fill = "white", colour = "grey50"))

```
<br>`r fig_cap("total catch vs. number surveys", display="full")`


Great Chazy river (NY) and Lewis stream (VT) are the two sites with the most lampreys `r fig_cap("total catch vs. number surveys", display="cite")`.

```{r visualize total catch versus number of surveys, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(trap_summ2, aes(Number.surveys, Total.catch)) + 
  labs(x="Total number of years surveyed", y="Total number of lamprey caught") + 
  geom_label(aes(Number.surveys, Total.catch), label=rownames(trap_summ2), nudge_y = -150,alpha=.8) + 
  geom_point(alpha=.5) + 
  theme_classic() 
```
<br>`r fig_cap("total catch vs. number surveys", display="full")`



```{r Visualize number caught per stations per year, echo=FALSE, message=FALSE, warning=FALSE}

trap_annual_summ_plot <- trap_annual_summ[!trap_annual_summ$Name %in% c("POTS", "TOTAL", "Total_Aaron"),-1]
trap_annual_summ_plot <- melt(trap_annual_summ_plot, variable.name = "Year")
trap_annual_summ_plot$Year <- as.numeric(substr(trap_annual_summ_plot$Year,2,5))

p1 <- ggplot(trap_annual_summ_plot, aes(Year, Name)) +
 geom_raster(aes(fill = value)) + theme_light() + xlim(1980,2018) +
  scale_fill_gradient(low = "yellow", high = "tomato", name="Number") + 
  labs(subtitle=paste0("Number of sea lamprey collected per stations,\n", min(trap_annual_summ_plot$Year),"-",max(trap_annual_summ_plot$Year),"\nSummary trap + pot data provided by Brad Yound"), y = "Tributaries") 
p1

trap_annual_summ_RB <- trap_annual_summ_RB[,colSums(trap_annual_summ_RB, na.rm=T)>0]
trap_annual_summ_plot_RB <- cbind("Year"=rep(as.numeric(rownames(trap_annual_summ_RB)),ncol(trap_annual_summ_RB)), melt(trap_annual_summ_RB, variable.name = "Name"))

p2 <- ggplot(trap_annual_summ_plot_RB, aes(Year, Name)) +
 geom_raster(aes(fill = value)) + theme_light() + xlim(1980,2018) +
  scale_fill_gradient(low = "yellow", high = "tomato", name="Number") + 
  labs(subtitle=paste0("Number of sea lamprey collected per stations,\n", min(trap_annual_summ_plot_RB$Year),"-",max(trap_annual_summ_plot_RB$Year),"\nSummary calculated using trap data only. Note \ndifferences in total number."), y = "Tributaries") 
p2

grid.newpage()
grid.draw(rbind(ggplotGrob(p1), ggplotGrob(p2), size = "first"))
```


## Lamprey weigth-length relationship from trap data

### Fit linear model
```{r fit linear model sea lamprey}
par(mar=c(5.1,4.1,4.1,4.1))
hist(trap$length)
trap$logL <- log10(trap$length/10)
trap$logW <- log10(trap$weight)
lm1 <- lm(logW~logL,data = trap)
fitPlot(lm1,xlab="Log total length", ylab = "Log weight", main="")
axis(3, at=log10(c(0:10,seq(10,90,10),seq(100,500,100))), labels = c(0:10,seq(10,90,10),seq(100,500,100)))
mtext("Total length (cm)", side=3, line = 2.5)
axis(4, at=log10(c(0:9,seq(10,100,10),seq(0,1000,100))), labels=c(0:9,seq(10,100,10),seq(0,1000,100)))
mtext("Total weight (g)", side=4, line = 2.5)
summary(lm1)
```
<br>`r fig_cap("lm w l relationship sea lamprey", caption="Weight-length relationship (log scale) for sea lamprey.")`

### Conclusion a and b parameters
To convert them to the initial equation W = aL<sup>b</sup>:  
```{r conclusion a and b parameters for sea lamprey, message = FALSE, warning = FALSE}
(a = 10^(lm1$coefficients[1])) # 0.01726149
(b = lm1$coefficients[2])      # 2.42935
```

Therefore, the initial equation is W = `r as.numeric(a)` x L<sup>`r as.numeric(b)`</sup>

## Survey data

```{r}
head(annual_survey)

ggplot(annual_survey, aes(year_surveyed, num_ammocoetes)) +
  geom_bar(stat="identity", position=position_dodge()) +  labs(x="Stations", y="Number lamprey caught", fill = "Number of years surveyed") + facet_wrap(~river_trib_system) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position="bottom",
        panel.background = element_rect(fill = "white", colour = "grey50"))
```
<br>`r fig_cap("num_ammocoetes per year", caption="Number of ammocoetes caught per year, and per sites")`


## Get biomass for model

The mortality between the ammocoetes and transformers stage is really high, so using the number of ammocoetes per streams may not be the best approach. 
However, trapping of adults is really efficient (~95% said Ellen), so backtracking and estimating the number of individuals at the parasitoid stage. Sea lamprey will spend 12-18 months in the parasitoid stage.


"Estimates of the lake-wide out-migrating transformer population for the 2002 and 2003 parasitic-phase cohorts were 269,139 ± 55,610 (SD) and 111,807 ± 23,511 (SD)" (Howe et al, 2006^[Howe, E.A., Ellen Marsden, J., Bouffard, W., 2006. Movement of Sea Lamprey in the Lake Champlain Basin. Journal of Great Lakes Research 32, 776–787. https://doi.org/10.3394/0380-1330(2006)32[776:MOSLIT]2.0.CO;2]).


Use average weight of trapped individuals (`r round(mean(trap$weight, na.rm=T),1)` g, converted in tons by multiplying by $10^{-6}$), multiply by the estimate of number of lamprey in the lake (average of 2002-2003 cohors), and divide by the area of the lake in $km^2$:

```{r get lamprey biomass based on the several indicators we collected}
w_lamprey = mean(trap$weight, na.rm=T)
w_lamprey_2002_2003 = mean(trap$weight[trap$Year %in% c(2002,2003)], na.rm=T)
n_lamprey = (269139+111807)/2
area_lake = 1127 # km2

w_lamprey_df <- as.data.frame(with(trap, tapply(weight,list("Year"=Year,"River"=River), mean, na.rm=T)))

ggplot(cbind("Year"= rep(as.numeric(rownames(w_lamprey_df)), ncol(w_lamprey_df)),melt(w_lamprey_df)), aes(Year, variable)) +
 geom_raster(aes(fill = value)) + theme_light() + 
  scale_fill_gradient(low = "yellow", high = "tomato", name="Weight (g)") + 
  labs(subtitle="Average weight of sea lamprey collected by tributaries",y="Tributaries") 

# get moving average
w_lamprey_yr <- rowMeans(w_lamprey_df,na.rm = T)
w_lamprey_yr <- w_lamprey_yr[!is.na(w_lamprey_yr)]
w_lamprey_yr <- approx(x=as.numeric(names(w_lamprey_yr)), y = w_lamprey_yr, xout=1980:2017)$y

w_lamprey_3yr <- SMA(w_lamprey_yr, n=3)

w_lamprey_summ <- data.frame("Year" = 1980:2017,
                             "w_yr_interp" = w_lamprey_yr,
                             "w_yr" = rowMeans(w_lamprey_df,na.rm = T),
                             "w_3yr" = w_lamprey_3yr,
                             "se" = rowSds(as.matrix(w_lamprey_df),na.rm = T))

#plot moving average
ggplot(w_lamprey_summ) +
  geom_errorbar(aes(x=Year, ymin=w_yr-se, ymax=w_yr+se), colour="black", width=.3, lwd=.2) +
  geom_line(aes(Year,w_yr_interp), lwd=.2, lty=2) +
  geom_line(aes(Year, w_yr), lwd=.2) + 
  geom_point(aes(Year, w_yr), lwd=.6) + 
  geom_line(aes(Year,w_3yr), col=adjustcolor("tomato", alpha.f = 1), lwd=1) + 
  theme_bw()  + 
  geom_rect(data.frame(x1=2001.5, x2=2003.5, y1=50,y2=300), mapping=aes(xmin=x1, xmax=x2, ymin=y1, ymax=y2), fill="black", alpha=0.2) +
  geom_text(data.frame(x=2004,y=280, t="cohorts with \npopulation \nestimates."), mapping=aes(x, y, label=t),  hjust = 0, cex=3, color="grey8") +
  labs(subtitle="Average weight of sea lamprey collected (black) and running average (red). \nNo data were collected in 2006 and 2007. ",y = "Weight (g)")

#ggsave(paste0(getwd(),"/Output/Figures/8-SeaLamprey/Average_weight__sea_lamprey_over_the_years.pdf"), width=6, height=4)

B_lamprey = n_lamprey*w_lamprey_2002_2003*10^-6/area_lake
B_lamprey
```


# Stocking

## VTFWD long-term data 
Data communicated by Ellen on September 23rd, 2019. She presents them in Marsden et al (2018)^[].

```{r read long term stocking data VT, include=FALSE}
stklkt <- read.delim(paste0(getpath4data(),"data_from_Ellen/LC_LKT_stocking_history_1972_2018.txt"))
head(stklkt)
#stklkt_summ <- read.delim(paste0(getpath4data(),"data_from_Ellen/LC_LKT_stocking_history_1972_2018_summ.txt"))

# create a summary
stklkt_summ <- as.data.frame(with(stklkt, tapply(NB_EQUIV,list("Year"=YEAR,"Stocking_site"=STOCKING_SITE), sum, na.rm=T)))
stklkt_summ$TOTAL <- rowSums(stklkt_summ, na.rm = T)

```

```{r plot stoking lkt data long term, echo=FALSE, message=FALSE, warning=FALSE}
p1 <- ggplot(stklkt_summ, aes(x=as.numeric(paste(rownames(stklkt_summ))),y=TOTAL)) +
  geom_bar(stat="identity") + xlab("Year") + ylab("Number of yearling-equivalent lake trout") + theme_bw()
p1 + scale_y_continuous(labels = comma)
#ggplotly(p1)
```


Lake trout stocking was cut down form an average of `r mean(stklkt_summ$TOTAL[as.numeric(paste(rownames(stklkt_summ)))<1996&as.numeric(paste(rownames(stklkt_summ)))>=1974])` (sd `r sd(stklkt_summ$TOTAL[as.numeric(paste(rownames(stklkt_summ)))<1996&as.numeric(paste(rownames(stklkt_summ)))>=1974])`) (1973-1995) to an average of `r mean(stklkt_summ$TOTAL[as.numeric(paste(rownames(stklkt_summ)))>=1996])` (sd `r sd(stklkt_summ$TOTAL[as.numeric(paste(rownames(stklkt_summ)))>=1996])`) (1996-present)

### Get potential biomass in the system with Rpath
```{r}
library(Rpath)
groups <- c(paste("Lake trout ", 0:30), 'Phytoplankton', 'Detritus', 'Fleet1')
# type 1= primary producer
# type 2= detritus
# type 3= fleet
# type 0= consumer (the rest)
types  <- c(rep(0, length(groups)-3), 1, 2,3)

stgroups <- c(rep(NA, 1), rep('LakeTrout', 3), rep(NA, 15),NA)

REco.params.LC <- create.rpath.params(group = groups, type = types, stgroup = stgroups)
```


## VTFWD online database

### Data

Right now I'm including just data from VT. Work more on all the stocking Rmd before including it to this synthesis.

Stocking data were obtained from the <a href= https://vtfishandwildlife.com/fishvt>VTFWD website</a> by clicking on the link 'Trout Stocking Report'.

```{r read stocking data VTFWD, include=FALSE}
stkvt <- read.delim(paste0(getpath4data(),'Stocking/VTFWD_Stocking_2009-2019.txt'))
nrow(stkvt)
length(stkvt$ACTUAL.NUMBER.STOCKED[!is.na(stkvt$ACTUAL.NUMBER.STOCKED)])
names(stkvt)

stkvt$DATE.STOCKED <- parse_date_time(x = stkvt$DATE.STOCKED,orders = c("m/d/y", "m/d/Y"))
```

Over the `r min(stkvt$Year)`-`r max(stkvt$Year)` period, `r nrow(stkvt)` stocking events were scheduled, and `r length(stkvt$ACTUAL.NUMBER.STOCKED[!is.na(stkvt$ACTUAL.NUMBER.STOCKED)])` stocking events took place.

```{r create summary data vtfws, echo=FALSE, message=FALSE, warning=FALSE}

summ_stkvt <- stkvt %>% group_by(as.factor(Year)) %>%
  summarise(mean=mean(ACTUAL.NUMBER.STOCKED, na.rm=T),
            sum=sum(ACTUAL.NUMBER.STOCKED, na.rm=T),
            scheduled=length(ACTUAL.NUMBER.STOCKED),
            went_through=length(ACTUAL.NUMBER.STOCKED[!is.na(ACTUAL.NUMBER.STOCKED)]),
            percent_done=went_through/scheduled)
summ_stkvt <- as.data.frame(summ_stkvt)

p1 <- ggplot(data=summ_stkvt, aes(x=summ_stkvt[,1],y=as.numeric(summ_stkvt[,2]))) +
  geom_bar(stat="identity") + xlab("Year") + ylab("mean # stocked") 

p2 <- ggplot(data=summ_stkvt, aes(x=summ_stkvt[,1],y=as.numeric(summ_stkvt[,3]))) +
  geom_bar(stat="identity") + xlab("Year") + ylab("sum # stocked") 

## convert plots to gtable objects
g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(p2)
g <- rbind(g1, g2, size="first") # stack the two plots
g$widths <- unit.pmax(g1$widths, g2$widths) # use the largest widths
# center the legend vertically
g$layout[grepl("guide", g$layout$name),c("t","b")] <- c(1,nrow(g))
grid.newpage()
grid.draw(g)

colnames(summ_stkvt) <- c("Year","Mean #fish stocked", "Total #fish stocked", "Schedule events", "Stocking that went through", "% stocking done")
summ_stkvt

```
<br>`r fig_cap("vtfws species stocked number", caption = "Mean and total number of fish stocked by VTFWS from 2009 to 2019.")`


In 2019, there are still many stocking events that were not carried out. We're removing this year from the analysis.

```{r remove 2019 from the dataframe}
stkvt <- stkvt[stkvt$Year!=2019,]
```

### Species stocked

What are the species stocked by VTFWD? We're only looking at the effective stocking now.

```{r look at the species stocked by vtfws, echo=FALSE, message=FALSE, warning=FALSE}

sp_stkvt <- stkvt %>% group_by(as.factor(SPECIES)) %>%
  summarise(mean=mean(ACTUAL.NUMBER.STOCKED, na.rm=T),
            sum=sum(ACTUAL.NUMBER.STOCKED, na.rm=T),
            scheduled=length(ACTUAL.NUMBER.STOCKED),
            went_through=length(ACTUAL.NUMBER.STOCKED[!is.na(ACTUAL.NUMBER.STOCKED)]),
            percent_done=went_through/scheduled)

ggplot(data=stkvt, aes(x=SPECIES,y=ACTUAL.NUMBER.STOCKED, fill=as.factor(Year))) +
  geom_bar(stat="identity") + xlab("Species") + ylab("total # stocked") +
  labs(fill="Year") + ggtitle("All Vermont")

ggplot(data=stkvt[grep("Champ",stkvt$WATER),], aes(x=SPECIES,y=ACTUAL.NUMBER.STOCKED, fill=as.factor(Year))) +
  geom_bar(stat="identity") + xlab("Species") + ylab("total # stocked") +
  labs(fill="Year") + ggtitle("Lake Champlain waters")



```
<br>`r fig_cap("vtfws species stocked", caption = "Species stocked in Lake Champlain waters by VTFWS.")`

## NYDEC online database

### Read data and basic stats

Stocking data were obtained from the <a href= "https://data.ny.gov/Recreation/Fish-Stocking-Lists-Actual-Beginning-2011/9hpx-asd8">NYDEC website</a>.

```{r read the stocking data from nydec, include=FALSE}
stkny <- read.delim(paste0(getpath4data(),"Stocking/NYDEC_Stocking_2011-2019.txt"))
nrow(stkny)
names(stkny)

#QAQC some data
stkny$Town[stkny$Town=="plattsburgh"] <- "Plattsburgh"

```

Over the `r min(stkny$Year)`-`r max(stkny$Year)` period, `r nrow(stkny)` stocking events took place.

```{r summary stocking data nydec, echo=FALSE, message=FALSE, warning=FALSE}

summ_stkny <- stkny %>% group_by(as.factor(Year)) %>%
  summarise(mean=mean(Number, na.rm=T),
            sum=sum(Number, na.rm=T),
            went_through=length(Number))
summ_stkny <- as.data.frame(summ_stkny)

p1 <- ggplot(data=summ_stkny, aes(x=summ_stkny[,1],y=as.numeric(summ_stkny[,2]))) +
  geom_bar(stat="identity") + xlab("Year") + ylab("mean # stocked") 

p2 <- ggplot(data=summ_stkny, aes(x=summ_stkny[,1],y=as.numeric(summ_stkny[,3]))) +
  geom_bar(stat="identity") + xlab("Year") + ylab("sum # stocked") 

## convert plots to gtable objects
g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(p2)
g <- rbind(g1, g2, size="first") # stack the two plots
g$widths <- unit.pmax(g1$widths, g2$widths) # use the largest widths
# center the legend vertically
g$layout[grepl("guide", g$layout$name),c("t","b")] <- c(1,nrow(g))
grid.newpage()
grid.draw(g)

colnames(summ_stkny) <- c("Year","Mean #fish stocked", "Total #fish stocked", "Stocking events")
summ_stkny

```


### Species stocked

What are the species stocked by VTFWD? We're only looking at the effective stocking now.

```{r look at the species stocked by nydec, echo=FALSE, message=FALSE, warning=FALSE}

sp_stkny <- stkny %>% group_by(as.factor(Species)) %>%
  summarise(mean=mean(Number, na.rm=T),
            sum=sum(Number, na.rm=T),
            went_through=length(Number))

ggplot(data=stkny, aes(x=Species,y=Number, fill=as.factor(Year))) +
  geom_bar(stat="identity") + xlab("Species") + ylab("total # stocked") +
  labs(fill="Year") + ggtitle("All NY")

ggplot(data=stkny[grep("Champ",stkny$Waterbody),], aes(x=Species,y=Number, fill=as.factor(Year))) +
  geom_bar(stat="identity") + xlab("Species") + ylab("total # stocked") +
  labs(fill="Year") + ggtitle("Lake Champlain waters")


```


# Summary of data availability

The plot below summarizes which data are available, for which period for Lake Champlain.

```{r coarse summary of data availability, echo=FALSE, message=FALSE, warning=FALSE}
summary_data <- as.data.frame(matrix(
  c(
c("Phytoplankton",        min(year(phyto$VisitDate)), max(year(phyto$VisitDate)), "VTDEC"),
c("Zooplankton",          min(year(zoo$VisitDate)), max(year(zoo$VisitDate)), "VTDEC"),
c("Mysis",                min(mysis$Year), max(mysis$Year), "Stockwell et al."),
c("Benthic invertebrates",NA,NA,NA),
c("Sculpin",              NA,NA,NA),
c("Trout-perch",          min(tps$year), max(tps$year), "Lake trout recruitment survey"),
c("Smelt",                min(smelt$Year), max(smelt$Year), "Forage fish survey"),
c("Whitefish",            min(tps$year), max(tps$year), "Lake trout recruitment survey"),
c("Cisco",                NA,NA,NA),
c("Lake Trout",           min(tps$year), max(tps$year), "Lake trout recruitment survey"),
c("Atlantic Salmon",      NA,NA,NA),
c("Burbot",               NA,NA,"Great Lakes data?"),
c("Sea lamprey",          NA,NA,"VTFWS")
), ncol=4, byrow = T))

colnames(summary_data) <- c("Species","MinYear","MaxYear","Source")
summary_data$MaxYear <- as.numeric(paste(summary_data$MaxYear))
summary_data$MinYear <- as.numeric(paste(summary_data$MinYear))

# color palette
mycol <- wes_palette("Darjeeling1", length(unique(summary_data$Source[!is.na(summary_data$Source)])), type="continuous")
source_data <- unique(summary_data$Source[!is.na(summary_data$Source)])

par(mar=c(5,6,2,2))
plot(c(min(summary_data$MinYear, na.rm = T),max(summary_data$MinYear, na.rm = T)), c(1,length(unique(summary_data$Species))), pch=NA, xlab="Year", ylab="", axes=F, main="Not updated since 09/09/19 - see next plot instead \n (colors refer to different data collection program)")
axis(1, at=1970:2020, labels=NA, lwd = .5); axis(1,at=1970:2020, labels=NA, lwd.ticks = 0)
axis(1)
for (i in 1:length(unique(summary_data$Species))) {
  msubset = summary_data[summary_data$Species==unique(summary_data$Species)[i],]
  for (j in 1:nrow(msubset)) {
    lines(msubset[,c("MinYear","MaxYear")],
        rep(c(i+(j/100)),2), col=mycol[source_data==msubset$Source], lwd=3)
  }
  par(xpd=T)
  text(x=min(summary_data$MinYear, na.rm = T),y=i,msubset$Species[1],pos=2)
  par(xpd=F)
}


```

<br>`r fig_cap("summary biomass coarse", caption = "Data availability -- stopped working on this plot, because at the moment I think the option below conveys more information.")`

```{r better summary of data availability, echo=FALSE, message=FALSE, warning=FALSE}
summary_ls <- list(
  "Phytoplankton" = data.frame("Year"=c(min(dtlcm$Year):max(dtlcm$Year)),"Biovolume" = as.vector(with(dtlcm, tapply(Net.phytoplankton..total.biovolume,list("Year"=year(as.Date(dtlcm$VisitDate, format="%d/%m/%Y"))), mean, na.rm=T)))),
  "Zooplankton" = data.frame("Year"=zoo19_month_Predator$Year, "Biomass"=rowSums(zoo19_month_Predator[,-1], na.rm = T) + rowSums(zoo19_month_Grazer_sm[,-1], na.rm = T) +rowSums(zoo19_month_Grazer_lr[,-1], na.rm = T)),
  "Mysids" = mysis_summ[,c("Year","mean_w")],
  "Zebra mussel veliger" = data.frame("Year"=rownames(ZMvel_summ), "Densities"=ZMvel_summ$STA19),
  "Zebra mussel" = NA,
  "Sculpin" = NA,
  "Trout-perch" = data.frame("Year"=c(2016:2018),"Density"=rep(0.5,length(2016:2018))),
  "Smelt" = data.frame("Year"=smelt_trawl_summ$Year[smelt_trawl_summ$Basin=="Main Lake"], "CPUE"=smelt_trawl_summ$CPUE[smelt_trawl_summ$Basin=="Main Lake"]),
  "Whitefish" = data.frame("Year"=c(1982:1998,2016:2018),"Density"=rep(0.5,length(c(1982:1998,2016:2018)))),
  "Cisco" = data.frame("Year"=cisco$Year,"CPUE"=cisco$JuniperIsland),
  "Alewife" = data.frame("Year"=c(2003:2018),"Density"=rep(0.5,length(c(2003:2018)))),
  "Walleye" = data.frame("Year"=c(2002:2018),"Density"=rep(0.5,length(c(2002:2018)))),
  "Stocked juvenile lake trout" = data.frame("Year"=1972:2016, "Stocked"=as.vector(stklkt_summ[as.numeric(paste(rownames(stklkt_summ))) %in% 1972:2016, "TOTAL"])),
  "Lake trout" = data.frame("Year"=c(1982:1998,2016:2018),"Density"=rep(0.5,length(c(1982:1998,2016:2018)))),
  "Atlantic salmon" = data.frame("Year"=c(1972:2016),"Density"=rep(0.5,length(c(1972:2016)))),
  "Burbot" = data.frame("Year"=c(1982:1997),"Density"=rep(0.5,length(c(1982:1997)))),
  "Sea lamprey" = data.frame("Year"=c(1990:2018),"Density"=rep(0.5,length(1990:2018)))
)

# Replacing NA of phytoplankton by 0.5 because we have the data -- just no estimate of biomass right now
summary_ls$Phytoplankton[is.na(summary_ls$Phytoplankton$Biovolume),2] <- max(summary_ls$Phytoplankton$Biovolume,na.rm=T)

if(!R_U_KNITTING) pdf(paste0(getwd(),"/Output/Figures/5-Summary/summary_biomass2.pdf"),width = 9, height = 5)
layout(matrix(c(1,2), nrow=1), widths=c(3.5,1.2))
par(mar=c(5,10,4,0.5))
plot(c(1971,2019), c(1,length(summary_ls)), pch=NA, xlab="Year", ylab="", axes=F)
axis(1, at=1960:2020, labels=NA, lwd = .5); axis(1,at=1960:2020, labels=NA, lwd.ticks = 0)
axis(1)

axis(3, at=1960:2020, labels=NA, lwd = .5); axis(3,at=1960:2020, labels=NA, lwd.ticks = 0)
axis(3)

for (i in 1:length(summary_ls)) {
  abline(h=i,lty=2, col=adjustcolor("grey", alpha.f = .4))
  msubset = summary_ls[[i]]
  if(any(!is.na(msubset))) {
    # Set which year we actually have all data
    #default
    whichyear= msubset[,1]
    if(names(summary_ls[i])=="Phytoplankton") whichyear= msubset$Year[msubset$Year %in% 2006:2015]
    if(names(summary_ls[i])%in% c("Trout-perch", "Whitefish", "Lake trout", "Sea lamprey","Burbot", "Atlantic salmon", "Walleye", "Alewife")) whichyear= NULL
    if(names(summary_ls[i])=="Smelt") whichyear= msubset$Year[msubset$Year %in% 1998:2015]
#    if(names(summary_ls[i])=="Stocked juvenile lake trout") whichyear=as.numeric(paste(summ_stkvt$Year))
    
    msubset[,1] <- as.numeric(paste(msubset[,1]))
    msubset[,2] <- as.numeric(paste(msubset[,2]))
    # Add rows without data to visualize on the plot
    # If data are continuous already, msubset_2 will just be a copy of msubset
    msubset_2 <- rbind(data.frame("x" = msubset[,1],
                                  "y" = msubset[,2]),
                       data.frame("x" = c(min(msubset[,1]):max(msubset[,1]))[!min(msubset[,1]):max(msubset[,1])%in%msubset[,1]],
                                  "y" = rep(NA,length(which(!min(msubset[,1]):max(msubset[,1])%in%msubset[,1])))))
    msubset_2 <- msubset_2[order(msubset_2$x),]
    lines(msubset_2[,1],ifelse(!is.na(msubset_2[,2]),i,NA), col="grey", lwd=1.5)
    x <- msubset_2[,1]
    w <- msubset_2[,2]/max(msubset_2[,2], na.rm=T)
    w[is.na(w)] <- 0
    polygon(x = c(x,rev(x)), y=c((i+w/2),rev(i-w/2)), border = NA, col=adjustcolor("grey", alpha.f = .7))
    #if(names(summary_ls[i])=="Burbot") TeachingDemos::shadowtext(mean(1982:1998),i, labels = "uncertainties about \ndata availability", col = "black",bg = "white", theta = seq(pi/4, 2 * pi, length.out = 8), r = 0.1, cex=.9)
    x <- msubset_2[msubset_2[,1] %in% whichyear,1]
    w <- msubset_2[msubset_2[,1] %in% whichyear,2]/max(msubset_2[msubset_2[,1] %in% whichyear,2], na.rm=T)
    w[is.na(w)] <- 0
    # if(names(summary_ls[i])%in%c("Alewife", "Zebra Mussel")) {
    #   polygon(x = c(x,rev(x)), y=c((i+w/2),rev(i-w/2)), border = "black", col=adjustcolor("pink", alpha.f = .6))
    # } else {
       polygon(x = c(x,rev(x)), y=c((i+w/2),rev(i-w/2)), border = NA, col=adjustcolor("black", alpha.f = .8))
    # }
    if(names(summary_ls[i])=="Smelt") {
     for (w in 1) {
       if (w==1) whichyear = 1988:1989
       #if (w==2) whichyear = 1984:1985
    x <- msubset_2[msubset_2[,1] %in% whichyear,1]
    w <- msubset_2[msubset_2[,1] %in% whichyear,2]/max(msubset_2[msubset_2[,1] %in% whichyear,2], na.rm=T)
    w[is.na(w)] <- 0
     polygon(x = c(x,rev(x)), y=c((i+w/2),rev(i-w/2)), border = NA, col=adjustcolor("black", alpha.f = .7)) 
     }
    }

  }
  par(xpd=T)
  #text(x=min(summary_data$MinYear, na.rm = T),y=i,names(summary_ls[i]),pos=2)
  TeachingDemos::shadowtext(x=1971,y=i, labels = names(summary_ls[i]), col = "black",bg = "white", theta = seq(pi/4, 2 * pi, length.out = 8), r = 0.1, pos=2)
  par(xpd=F)
  
  # Add a different point if invasion
  if(names(summary_ls[i])=="Alewife") points(2003,i,pch=17, col="red")
  if(names(summary_ls[i])=="Zebra mussel") points(1993,i,pch=17, col="red")
  if(names(summary_ls[i])=="Zooplankton") points(c(2014,2018),rep(i,2),pch=17, col="red")
  
  # Add snapshot data info
  if(names(summary_ls[i])=="Sea lamprey") points(c(2003,2004),c(i,i),pch=16, col=adjustcolor("black", alpha.f = .6), cex=1.3)
  if(names(summary_ls[i])=="Zebra mussel") points(c(2014),c(i),pch=16, col=adjustcolor("black", alpha.f = .6), cex=1.3)
  
  
  # Add comment
  #if(names(summary_ls[i])=="Alewife") TeachingDemos::shadowtext(2004,i, labels = "probably more data available?", col = "black",bg = "white", theta = seq(pi/4, 2 * pi, length.out = 8), r = 0.1, cex=.9, pos=4)
  
  # Add a different point if work still in progress
  if(names(summary_ls[i])%in%c( "Sculpin")) points(max(as.numeric(paste(summary_data[,2])), na.rm = T),i,pch=4, col="red")
}
rect(2000,0.7,2002,i+0.3, lty=2, lwd=.5)

par(mar=c(5,0,2,1))
plot(c(1,10),c(1,10),axes=F,xlab="",ylab="", pch=NA)
legend(x=1,y=9.5, legend = c("Relative biomass","Biomass still \nbeing estimated"),
       fill=c("black",adjustcolor("grey", alpha.f = .7)), bty="n", border = NULL)
legend(x=1,y=7, legend = c("Species invasion", "No data yet", "Snapshot biomass","Period chosen for \nmodel initialization"),
       pch=c(17,4, 16,NA), lty=c(NA,NA, NA,2), col=c("red","red",adjustcolor("black", alpha.f = .6),"black"), bty="n", border = NULL)

if(!R_U_KNITTING) dev.off()
par(mfrow=c(1,1))


```
<br>`r fig_cap("summary biomass", caption = "Species selected for the initial model, and relative evolution of their biomass (width of polygon). We are still collecting data for some species (Burbot, Atlantic Salmon, Sculpin), and converting survey data to biomass (e.g., phytoplankton counts to biovolume before biovolumes started being reported by the state). Asterisks indicate invasive species, and triangles on the timeline indicates the time of invasion.")`

```{r summary of environmental data availability, echo=FALSE, message=FALSE, warning=FALSE}
# Similar figure than before, but with drivers / environmental variables
weather <- read.delim(paste0(getpath4data(), "Weather/allWeatherBTV_join.txt"))
weather$date <- as.Date(weather$date, format="%d/%m/%Y")
weather$Year <- year(weather$date)
weather$Month <- month(weather$date)
# plot(with(weather[weather$Month %in% c(12:3),], tapply(AvgApparentTemperatureCelsius,list("Year"=Year), mean, na.rm=T)), type="b")

summary_env_var <- list(
  "Summer average air temperature (degC)" = data.frame("Year"=unique(weather$Year),"SumAirTemp" = as.vector(with(weather[weather$Month %in% c(6:9),], tapply(AvgApparentTemperatureCelsius,list("Year"=Year), mean, na.rm=T)))),
  
  "Winter average air temperature (degC)" = data.frame("Year"=unique(weather$Year),"WintAirTemp" = as.vector(with(weather[weather$Month %in% c(12,1:3),], tapply(AvgApparentTemperatureCelsius,list("Year"=Year), mean, na.rm=T)))),
  
  "Average air temperature (degC)" = data.frame("Year"=unique(weather$Year),"AvgAirTemp" = as.vector(with(weather, tapply(AvgApparentTemperatureCelsius,list("Year"=Year), mean, na.rm=T)))),
  
  "Water temperature epilimnion (degC)" = data.frame("Year"=c(min(dtlcm$Year):max(dtlcm$Year)),"WatTemp" = as.vector(with(dtlcm[dtlcm$StationID==21 & month(as.Date(dtlcm$VisitDate, format="%d/%m/%Y")) %in% c(4:10),], tapply(Temperature_E,list("Year"=year(as.Date(dtlcm$VisitDate[dtlcm$StationID==21 & month(as.Date(dtlcm$VisitDate, format="%d/%m/%Y")) %in% c(4:10)], format="%d/%m/%Y"))), mean, na.rm=T)))),
  "Dissolved phosphorus epilimnion (mug/l)" = data.frame("Year"=c(min(dtlcm$Year):max(dtlcm$Year)),"DissolvedP" = as.vector(with(dtlcm[dtlcm$StationID==21 & month(as.Date(dtlcm$VisitDate, format="%d/%m/%Y")) %in% c(4:10),], tapply(Dissolved.Phosphorus_E,list("Year"=year(as.Date(dtlcm$VisitDate[dtlcm$StationID==21 & month(as.Date(dtlcm$VisitDate, format="%d/%m/%Y")) %in% c(4:10)], format="%d/%m/%Y"))), mean, na.rm=T)))),
  "Secchi depth (m)" = data.frame("Year"=c(min(dtlcm$Year):max(dtlcm$Year)),"Secchi.Depth" = as.vector(with(dtlcm[dtlcm$StationID==21,], tapply(Secchi.Depth,list("Year"=year(as.Date(dtlcm$VisitDate[dtlcm$StationID==21], format="%d/%m/%Y"))), mean, na.rm=T))))
)


if(!R_U_KNITTING) pdf(paste0(getwd(),"/Output/Figures/5-Summary/summary_env_variables.pdf"),
                      width = 12, height = 8)
layout(matrix(c(1,0,2,0,3,4), nrow=3, byrow = T), widths=c(3.5,1), heights=c(1.2,.8,2.5))
par(mar=c(0,10,5,3.5))
plot(summary_env_var$`Summer average air temperature (degC)`, type="l", xlab="", ylab="Temperature (deg C)", axes=F, xlim=c(1971,2019),
     ylim=c(min(summary_env_var$`Winter average air temperature (degC)`[,2], na.rm=T)-1, max(summary_env_var$`Summer average air temperature (degC)`[,2], na.rm=T)+1))
lines(summary_env_var$`Average air temperature (degC)`,lwd=2)
lines(summary_env_var$`Winter average air temperature (degC)`)
lines(summary_env_var$`Water temperature epilimnion (degC)`[-c(1:3),], col="darkcyan")
TeachingDemos::shadowtext(summary_env_var$`Summer average air temperature (degC)`[3,], labels = "summer (June-September)", col = "black",bg = "white", theta = seq(pi/4, 2 * pi, length.out = 8), r = 0.1, pos=3)
TeachingDemos::shadowtext(summary_env_var$`Winter average air temperature (degC)`[3,], labels = "winter (December-March)", col = "black",bg = "white", theta = seq(pi/4, 2 * pi, length.out = 8), r = 0.1, pos=1)
TeachingDemos::shadowtext(summary_env_var$`Average air temperature (degC)`[1,], labels = "mean annual temperature", col = "black",bg = "white", theta = seq(pi/4, 2 * pi, length.out = 8), r = 0.1, pos=1, font=2)
TeachingDemos::shadowtext(summary_env_var$`Water temperature epilimnion (degC)`[5,], labels = "epilimnion temperature (April-October)", col = "darkcyan",bg = "white", theta = seq(pi/4, 2 * pi, length.out = 8), r = 0.1, pos=1)

axis(3, at=1960:2020, labels=NA, lwd = .5); axis(3,at=1960:2020, labels=NA, lwd.ticks = 0)
axis(3)
axis(2)
axis(2, at=c(-20,30), labels=NA)
mtext("Year", side = 3, line = 2.2)

#2nd plot
par(mar=c(4,10,0,3.5))
plot(summary_env_var$`Dissolved phosphorus epilimnion (mug/l)`, type="l", xlab="Year", ylab="", axes=F, xlim=c(1971,2019), col="darkgreen")
points(summary_env_var$`Dissolved phosphorus epilimnion (mug/l)`,pch=16, col="darkgreen")
axis(1, at=1960:2030, labels=NA, lwd = .5); axis(1,at=1960:2030, labels=NA, lwd.ticks = 0)
axis(1)
axis(4, col="darkgreen", col.ticks = "darkgreen", col.axis = "darkgreen")
axis(4, at=c(0,20), labels=NA, col="darkgreen")
mtext("Dissolved phosphorus\nepilimnion (µg/l)", side = 4, line = 3.2, cex=.7, col="darkgreen")

#3rd plot
par(mar=c(5,10,4,3.5))
plot(c(1971,2019), c(1,length(summary_ls)), pch=NA, xlab="Year", ylab="", axes=F)
axis(1, at=1960:2020, labels=NA, lwd = .5); axis(1,at=1960:2020, labels=NA, lwd.ticks = 0)
axis(1)

axis(3, at=1960:2020, labels=NA, lwd = .5); axis(3,at=1960:2020, labels=NA, lwd.ticks = 0)
axis(3)
par(mar=c(5,10,4,0.5))

for (i in 1:length(summary_ls)) {
  abline(h=i,lty=2, col=adjustcolor("grey", alpha.f = .4))
  msubset = summary_ls[[i]]
  if(any(!is.na(msubset))) {
    # Set which year we actually have all data
    #default
    whichyear= msubset[,1]
    if(names(summary_ls[i])=="Phytoplankton") whichyear= msubset$Year[msubset$Year %in% 2006:2015]
    if(names(summary_ls[i])%in% c("Trout-perch", "Whitefish", "Lake trout", "Sea lamprey","Burbot")) whichyear= NULL
    if(names(summary_ls[i])=="Smelt") whichyear= msubset$Year[msubset$Year %in% 1998:2015]
    if(names(summary_ls[i])=="stocked lake trout") whichyear=as.numeric(paste(summ_stkvt$Year))
    
    msubset[,1] <- as.numeric(paste(msubset[,1]))
    msubset[,2] <- as.numeric(paste(msubset[,2]))
    # Add rows without data to visualize on the plot
    # If data are continuous already, msubset_2 will just be a copy of msubset
    msubset_2 <- rbind(data.frame("x" = msubset[,1],
                                  "y" = msubset[,2]),
                       data.frame("x" = c(min(msubset[,1]):max(msubset[,1]))[!min(msubset[,1]):max(msubset[,1])%in%msubset[,1]],
                                  "y" = rep(NA,length(which(!min(msubset[,1]):max(msubset[,1])%in%msubset[,1])))))
    msubset_2 <- msubset_2[order(msubset_2$x),]
    lines(msubset_2[,1],ifelse(!is.na(msubset_2[,2]),i,NA), col="grey", lwd=1.5)
    x <- msubset_2[,1]
    w <- msubset_2[,2]/max(msubset_2[,2], na.rm=T)
    w[is.na(w)] <- 0
    polygon(x = c(x,rev(x)), y=c((i+w/2),rev(i-w/2)), border = NA, col=adjustcolor("grey", alpha.f = .4))
    if(names(summary_ls[i])=="Burbot") TeachingDemos::shadowtext(mean(1982:1998),i, labels = "uncertainties about \ndata availability", col = "black",bg = "white", theta = seq(pi/4, 2 * pi, length.out = 8), r = 0.1, cex=.9)
    x <- msubset_2[msubset_2[,1] %in% whichyear,1]
    w <- msubset_2[msubset_2[,1] %in% whichyear,2]/max(msubset_2[msubset_2[,1] %in% whichyear,2], na.rm=T)
    w[is.na(w)] <- 0
    if(names(summary_ls[i])%in%c("Alewife", "Zebra Mussel")) {
      polygon(x = c(x,rev(x)), y=c((i+w/2),rev(i-w/2)), border = "black", col=adjustcolor("pink", alpha.f = .6))
    } else {
      polygon(x = c(x,rev(x)), y=c((i+w/2),rev(i-w/2)), border = NA, col=adjustcolor("black", alpha.f = .8))
    }
    if(names(summary_ls[i])=="Smelt") {
     for (w in 1:2) {
       if (w==1) whichyear = 1990:1996
       if (w==2) whichyear = 1984:1985
    x <- msubset_2[msubset_2[,1] %in% whichyear,1]
    w <- msubset_2[msubset_2[,1] %in% whichyear,2]/max(msubset_2[msubset_2[,1] %in% whichyear,2], na.rm=T)
    w[is.na(w)] <- 0
     polygon(x = c(x,rev(x)), y=c((i+w/2),rev(i-w/2)), border = NA, col=adjustcolor("black", alpha.f = .8)) 
     }
    }

  }
  par(xpd=T)
  #text(x=min(summary_data$MinYear, na.rm = T),y=i,names(summary_ls[i]),pos=2)
  TeachingDemos::shadowtext(x=1971,y=i, labels = names(summary_ls[i]), col = "black",bg = "white", theta = seq(pi/4, 2 * pi, length.out = 8), r = 0.1, pos=2)
  par(xpd=F)
  
  # Add a different point if invasion
  if(names(summary_ls[i])=="Alewife") points(2003,i,pch=17, col="red")
  if(names(summary_ls[i])=="Zebra mussel") points(1993,i,pch=17, col="red")
  if(names(summary_ls[i])=="Zooplankton") points(c(2014,2018),rep(i,2),pch=17, col="red")
  
  # Add comment
  if(names(summary_ls[i])=="Alewife") TeachingDemos::shadowtext(2004,i, labels = "probably more data available?", col = "black",bg = "white", theta = seq(pi/4, 2 * pi, length.out = 8), r = 0.1, cex=.9, pos=4)
  
  # Add a different point if work still in progress
  if(names(summary_ls[i])%in%c("Burbot","Atlantic salmon", "Sculpin","Walleye")) points(max(summary_data$MinYear, na.rm = T),i,pch=4, col="red")
}
rect(2000,0.7,2002,i+0.3, lty=2, lwd=.5)

par(mar=c(5,0,2,1))
plot(c(1,10),c(1,10),axes=F,xlab="",ylab="", pch=NA)
legend(x=1,y=9.5, legend = c("Relative biomass","Biomass still \nbeing estimated","Invasive species"),
       fill=c("black",adjustcolor("grey", alpha.f = .4), adjustcolor("pink", alpha.f = .6)), bty="n", border = NULL)
legend(x=1,y=7, legend = c("Species invasion", "No data yet", "Period chosen for \nmodel initialization"),
       pch=c(17,4,NA), lty=c(NA,NA,2), col=c("red","red","black"), bty="n", border = NULL)

if(!R_U_KNITTING) dev.off()
par(mfrow=c(1,1))


```
<br>`r fig_cap("summary biomass and env var", caption = "Upper graph: Environmental parameters (summer, winter, and annual average temperature), epilimnion mean temperature (April-October), and dissolved phosphorus concentration. Lower graph: Species selected for the initial model, and relative evolution of their biomass (width of polygon). We are still collecting data for some species (Burbot, Atlantic Salmon, Sculpin), and converting survey data to biomass (e.g., phytoplankton counts to biovolume before biovolumes started being reported by the state). Asterisks indicate invasive species, and triangles on the timeline indicates the time of invasion.")`


# Get P/B for each group

```{r read growth parameters }
gp <- read.delim(paste0(getpath4data(), "Growth_parameters.txt"))
```


Production rate P/B is defined at steady state as equal to total mortality (Z), the sum of fishing mortality (F) and natural mortality (M) (Pauly et al. 2000^[Pauly, D., Christensen, V., Walters, C., 2000. Ecopath, Ecosim, and Ecospace as tools for evaluating ecosystem impact of fisheries. ICES J. Mar. Sci. 57, 697–706. https://doi.org/10.1006/jmsc.2000.0726]).

In Lake Champlain, fishing mortality is really low (F ~ 0).  M, in fishes, is positively correlated to their value of K (from the von Bertalanffy growth formula), followed by the temperature of their environment, and in a lesser extent, inversely correlated to their asymptotic length (Pauly 1980). We calculated M following the equation below, that was established from 175 marine fish stocks (Pauly 1980^[Pauly, D., 1980. On the interrelationships between natural mortality, growth parameters, and mean environmental temperature in 175 fish stocks. J. Const. int. Explor. Mer 39, 175–192.]).

$log(M)= -0.00066 - 0.279 * log(L_∞) + 0.6543*log(K) + 0.4634*log(T)$

T for now is defined as 14°C because we don't have data for winter in Lake Champlain, so I just need to get a data.

```{r get p/b}
# using some parameters from growth parameter
Tenv = 14

getM <- function(Lasympt, K, Tenv) {
  10^(-0.00066-0.279*log10(Lasympt)+0.6543*log10(K)+0.4634*log10(Tenv))
}
  
gp$Group.name
M_sea_lamprey = getM(Lasympt = 69, K = 0.16, Tenv = Tenv)
M_lake_trout_ad = getM(Lasympt = 74.6, K = 0.232, Tenv = Tenv) # K was obtained from regression done for Lake Champlain fish (Grace and Ellen). L∞=746mm
M_lake_trout_juv = getM(Lasympt = 23, K = 0.232, Tenv = Tenv)
M_lake_trout_stk = getM(Lasympt = 5, K = 0.232, Tenv = Tenv)
M_atlantic_salmon = getM(Lasympt = 150, K = 0.15, Tenv = Tenv)
M_burbot = getM(Lasympt = 117, K = 0.05, Tenv = Tenv)
M_walleye = getM(Lasympt = 107, K = 0.2, Tenv = Tenv)
M_cisco = getM(Lasympt = 57.000, K = 0.16, Tenv = Tenv)
M_whitefish = getM(Lasympt = 79.000, K = 0.12, Tenv = Tenv)
M_trout_perch = getM(Lasympt = 15, K = 0.05, Tenv = Tenv)
M_alewife = getM(Lasympt = 38.100, K = 0.2, Tenv = Tenv)
M_smelt = getM(Lasympt = 33, K = 0.31, Tenv = Tenv)
M_sculpin = getM(Lasympt = 12.7, K = NA, Tenv = Tenv)

M_fish <- data.frame("sea_lamprey"= c(M_sea_lamprey),
            "lake_trout_ad" = M_lake_trout_ad,
            "lake_trout_juv" = M_lake_trout_juv,
            "lake_trout_stk" = M_lake_trout_stk,
            "atlantic_salmon"= M_atlantic_salmon,
            "burbot" = M_burbot,
            "walleye" = M_walleye,
            "cisco" = M_cisco,
            "whitefish" = M_whitefish,
            "trout_perch"= M_trout_perch,
            "alewife"=M_alewife,
            "smelt"=M_smelt,
            "sculpin"=M_sculpin)

if(!R_U_KNITTING) write.table(M_fish, file=paste0(getpath4data(),"EwE_params/M_fish.txt"), sep="\t")

M_fish
```


```{r get P/B for various temperatures, echo=FALSE}
# using some parameters from growth parameter
Tenvt = seq(12,16,by=0.1)

for (i in 1:length(Tenvt)) {
  Tenv <- Tenvt[i]
  
  M_sea_lamprey = getM(Lasympt = 69, K = 0.16, Tenv = Tenv)
  M_lake_trout_ad = getM(Lasympt = 74.6, K = 0.232, Tenv = Tenv) # K was obtained from regression done for Lake Champlain fish (Grace and Ellen). L∞=746mm
  M_lake_trout_juv = getM(Lasympt = 23, K = 0.232, Tenv = Tenv)
  M_lake_trout_stk = getM(Lasympt = 5, K = 0.232, Tenv = Tenv)
  M_atlantic_salmon = getM(Lasympt = 150, K = 0.15, Tenv = Tenv)
  M_burbot = getM(Lasympt = 117, K = 0.05, Tenv = Tenv)
  M_walleye = getM(Lasympt = 107, K = 0.2, Tenv = Tenv)
  M_cisco = getM(Lasympt = 57.000, K = 0.16, Tenv = Tenv)
  M_whitefish = getM(Lasympt = 79.000, K = 0.12, Tenv = Tenv)
  M_trout_perch = getM(Lasympt = 15, K = 0.05, Tenv = Tenv)
  M_alewife = getM(Lasympt = 38.100, K = 0.2, Tenv = Tenv)
  M_smelt = getM(Lasympt = 33, K = 0.31, Tenv = Tenv)
  M_sculpin = getM(Lasympt = 12.7, K = NA, Tenv = Tenv)
  
  if (i==1) M_fish2 <- data.frame("T_env" = Tenv,
              "sea_lamprey"= M_sea_lamprey,
              "lake_trout_ad" = M_lake_trout_ad,
              "lake_trout_juv" = M_lake_trout_juv,
              "lake_trout_stk" = M_lake_trout_stk,
              "atlantic_salmon"= M_atlantic_salmon,
              "burbot" = M_burbot,
              "walleye" = M_walleye,
              "cisco" = M_cisco,
              "whitefish" = M_whitefish,
              "trout_perch"= M_trout_perch,
              "alewife"=M_alewife,
              "smelt"=M_smelt,
              "sculpin"=M_sculpin) else
                 M_fish2 <- rbind(M_fish2,
                                c(Tenv,M_sea_lamprey,M_lake_trout_ad, M_lake_trout_juv, M_lake_trout_stk, M_atlantic_salmon,M_burbot, M_walleye,M_cisco,M_whitefish,M_trout_perch,M_alewife, M_smelt,M_sculpin))

}

M_fish3 <- cbind("T_env"=M_fish2[,1],data.frame(lapply(M_fish2[,-1], function(X) X/X[1])))

if(!R_U_KNITTING) {
  ggplot(M_fish2, aes(T_env, lake_trout_ad/REco2$BB[REco2$Group=="Adult lake trout"])) + geom_point() +
  geom_point(aes(T_env, alewife/REco2$BB[REco2$Group=="Alewife"]), col="blue") +
  geom_point(aes(T_env, atlantic_salmon/REco2$BB[REco2$Group=="Atlantic salmon"]), col="pink") + labs(x="T environment",y="Mortality/Biomass") + theme_bw()
}


```
<br>`r fig_cap("varying T env impact on PB fish", caption="Mortality (pondered by biomass) as a function of water temperature, for 3 groups in the food web.")`

## P/B for zooplankton (Stockwell and Johannsson 1997^[Stockwell, J.D., Johannsson, O.E., 1997. Temperature-dependent allometric models to estimate zooplankton production in temperate freshwater lakes. Can. J. Fish. Aquat. Sci. 54, 2350–2360. https://doi.org/10.1139/f97-141])

Found the method to get a better estimate of P/B in the supplementary materials B of Zhang et al 2016 paper on Lake Erie^[Zhang, H., Rutherford, E.S., Mason, D.M., Breck, J.T., Wittmann, M.E., Cooke, R.M., Lodge, D.M., Rothlisberger, J.D., Zhu, X., Johnson, T.B., 2016. Forecasting the Impacts of Silver and Bighead Carp on the Lake Erie Food Web. Transactions of the American Fisheries Society 145, 136–162. https://doi.org/10.1080/00028487.2015.1069211].

To quote them:
"P/B values were calculated based on published relationships between temperature and production (Shuter and Ing 1997; Stockwell and Johannsson 1997). Specifically, for non-predatory cladocerans, P/B=0.162/d when temperature was >10°C, and 0.042/d when temperature was <10°C (Stockwell and Johannsson 1997); for predatory cladocerans, P/B is a function of body weight and water temperature:
$log(dailyP/B) = -0.23*log(dry_{wt}(µg))-0.73$, when mean seasonal temperature > 10, and $log(dailyP/B) = -0.26*log(dry_{wt}(µg))-1.36$ when mean seasonal temperature < 10  ̊C. For copepods and rotifer, P/B is calculated as: $log(median_{daily}P/B) = A + 0.04336*(medianTemperature(°C))$, where A = -1.844 for cyclopoids, -2.294 for calanoids, and -1.631 for rotifers (Shuter and Ing 1997). We used water temperature values provided from output of a 1-dimensional model of Lake Erie water temperature by Rucinski et al. (2010). Q/B values were calculated based on gross growth efficiency reported by Straile (1997). Diet for most zooplankton groups was obtained from Vanderploeg (1994), but for Bythotrephes spp was obtained from Vanderploeg et al. (1993)."

```{r get P/B for for zooplankton}
dailyPB <- function(drywt, mean_seasonal_temperature) {
  # dry weight in µg
  # mean seasonal temperature in °C
  if(mean_seasonal_temperature>10) {
    return(10^(-0.23*log10(drywt)-0.73))
    } else {
    return(10^(-0.26*log10(drywt)-1.36))
  }
}

dailyPB_test <- data.frame("drywt" = seq(0.01,2,0.01),
                           "temp11"= dailyPB(seq(0.01,2,0.01),11),
                           "temp9" = dailyPB(seq(0.01,2,0.01),9)) 
ggplot(dailyPB_test) + 
  geom_line(aes(drywt,temp11, colour=">10"), show.legend = T) +
  geom_line(aes(drywt,temp9, colour="<=10"), show.legend = T) +
  labs(x="Dry weight (µg)", y="daily P/B", title = "Variation in zooplankton P/B", 
       subtitle = "(Stockwell and Johannsson, 1997)") +
  theme_bw() + 
  theme(
    legend.position = c(.95, .95),
    legend.justification = c("right", "top"),
    legend.box.just = "right",
    legend.margin = margin(6, 6, 6, 6)
    ) +
  scale_colour_manual(name="Mean seasonal temperature (°C)", values=c(">10"="coral1", "<=10"="black"))


```
<br>`r fig_cap("P/Bzoo_conceptual", caption="Variation in zooplankton P/B (equations in Stockwell and Johannsson, 1997)")`



## Export P/B

```{r export P/B}
# if(!R_U_KNITTING) write.table(x, file=paste0(getpath4data(),"EwE_params/P_B.txt"), sep="\t")
```


# Get Q/B for each group


Consumption rate Q/B is a function of the asymptotic length (W∞, g), the mean annual temperature of the water body (T’=1000/T, with T in Kelvin, Tcelsius + 273.15), the aspect ratio of the caudal fin (A), h and d. <br>

$log(Q⁄B)= 7.964-0.204 log(W_∞ )-1.065 T'+0.0873 A+0.532 h + 0.398 d$ <br>
with $A=  h^2⁄s$ <br>
and $T'=  1000⁄(Tcelsius+273.15)$ <br>


A is an approximation of the swimming and metabolic activity of the fish (Palomares and Pauly 1998^[Palomares, M.L.D., Pauly, D., 1998. Predicting food consumption of fish populations as functions of mortality, food type, morphometrics, temperature and salinity. Mar. Freshwater Res. 49, 447. https://doi.org/10.1071/MF98015]).

<a href="https://www.fishbase.se/manual/fishbasethe_swimming_and_speed_tables.htm">About aspect ratio</a>.

```{r get q/b}
# using some parameters from growth parameter
Tk = 1000/(Tenv+273.15)


getQB <- function(Wasympt, Tk, A, h, d) {
  7.964-0.204 * log(Wasympt)-1.065 * Tk + 0.0873 * A+0.532 *h+0.398*d
}
  
gp$Group.name
QB_sea_lamprey = getQB(Wasympt = 2.5, Tk=Tk, A = 0.81, h = 0, d = 0)
QB_lake_trout_ad = getQB(Wasympt = 32, Tk=Tk, A = 2.11, h =0, d =  0)
QB_lake_trout_juv = getQB(Wasympt = 1.2, Tk=Tk, A = 2.11, h =0, d = 0)
QB_lake_trout_stk = getQB(Wasympt = 0.2, Tk=Tk, A = 2.11, h =0, d = 0)
QB_atlantic_salmon = getQB(Wasympt = 35, Tk=Tk, A = 2.02, h =0, d =0)
QB_walleye = getQB(Wasympt = 11.3, Tk=Tk, A = 1.29, h = 0, d = 0)
QB_burbot = getQB(Wasympt = 34, Tk=Tk, A = 0.73, h = 0, d = 0)
QB_cisco = getQB(Wasympt = 3.6, Tk=Tk, A = 2.73, h = 0, d = 0)
QB_whitefish = getQB(Wasympt = 19, Tk=Tk, A = 1.80, h = 0, d = 0)
QB_trout_perch = getQB(Wasympt = .058, Tk=Tk, A = 1.35, h = 0, d = 0)
QB_alewife = getQB(Wasympt = 0.2, Tk=Tk, A = 1.76, h = 0, d = 0)
QB_smelt = getQB(Wasympt = 0.363, Tk=Tk, A = 2.34, h = 0, d = 0)
QB_sculpin = getQB(Wasympt = 0.029, Tk=Tk, A = 0.89, h = 0, d = 0)

QB_fish <- data.frame("sea_lamprey"= c(QB_sea_lamprey),
            "lake_trout_ad" = QB_lake_trout_ad,
            "lake_trout_juv" = QB_lake_trout_juv,
            "lake_trout_stk" = QB_lake_trout_stk,
            "atlantic_salmon"= QB_atlantic_salmon,
            "burbot" = QB_burbot,
            "walleye" = QB_walleye,
            "cisco" = QB_cisco,
            "whitefish" = QB_whitefish,
            "trout_perch"= QB_trout_perch,
            "alewife"=QB_alewife,
            "smelt"=QB_smelt,
            "sculpin"=QB_sculpin)

if(!R_U_KNITTING) write.table(QB_fish, file=paste0(getpath4data(),"EwE_params/QB_fish.txt"), sep="\t")

QB_fish
```



